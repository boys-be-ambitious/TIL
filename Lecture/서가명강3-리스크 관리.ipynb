{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obj : 빅데이터는 Value를 만들기 위해\n",
    "- Method : 어떻게 뽑아내느냐?\n",
    "\n",
    "# 5. Risk Management\n",
    "## 5.1. 조기 퇴사 예측\n",
    "### 사례 1. Xerox\n",
    "#### (기존) 콜센터 직원 선발 기준 : \"경험\"\n",
    "    - 조기퇴사\n",
    "    - 훈련교육비 손실, 1인당  5,000 달러\n",
    "    - 나가는 사람의 특징이 무엇이냐? -> Insight\n",
    "        - 사전에 방지 (선제대응)\n",
    "        \n",
    "    - 데이터 : 이력서(Resume) + 성격 검사(Personality Test) => 한정적\n",
    "    \n",
    "#### 조기 퇴사의 유형 (인과관계 X, 상관관계 O)\n",
    "    - 회사에서 멀리 거주하며,\n",
    "    - 확실한 교통 수단이 없고,\n",
    "    - 외톨이거나 5개 이상의 소셜 네트워크 관련하고\n",
    "    - 궁금한 것이 너무 많고 (Inquisitive)\n",
    "    - 공감을 너무 잘 하거나\n",
    "    - 창의력이 부족하거나\n",
    "    \n",
    "    - + @ (잠재 원인, 숨어있는 원인)\n",
    "    \n",
    "    - 빅데이터는 인과관계 일 수도 있고, 아닐 수도 있다. 상관관계를 찾는 것!\n",
    "    \n",
    "#### \"증거\" 기반 의사결정\n",
    "- 고용 기준 변경 결정\n",
    "    - \"조기 퇴작자\" 특성의 지원자는 선발 제외\n",
    "    - 연 48,700명 고용 결정은 알고리즘이\n",
    "    \n",
    "- 결과\n",
    "    - 6개월 후 (조기 퇴사한 사람들의) 퇴사율 20% 감소!\n",
    "    - 왜 20%만?\n",
    "        - 데이터에 없는 (잠재 원인)데이터 때문에...\n",
    "            - 신변의 변화 혹은 다양한 요인들...\n",
    "\n",
    "#### Q1. 알고리즘의 역할 : 조기 퇴사할 것 같은 사람들을 분류해내서 제외할 것. 나머지 사람들 또한 알고리즘이 결정?\n",
    "- 인사이트는 근본적으로 데이터가 가지고 있는 것 안에서만 발견\n",
    "\n",
    "\n",
    "## 5.2. 업무 능력 예측\n",
    "### 수 많은 지원자 가운데 누굴 뽑아야 하는가?\n",
    "#### 국내 제조기업 17,000명 대상\n",
    "    - 지역, 부서\n",
    "        - 평가기준 : 관리자가 모든 사람을 등급(A/B/C)으로 나눴고, A를 받은 사람들의 특징을 뽑음(인사고과 X, 연구용).\n",
    "        - 입사 당시의 정보와 5년 후의 퍼포먼스(등급)로 나눔\n",
    "            - 1-2-4 (R&D) : 대전/충청 지역의 사람들이 현역으로 나온 사람들이 A등급을 받음.\n",
    "            - 2-8-22\n",
    "            - 3-3-5/9 (영업)\n",
    "            \n",
    "            \n",
    "#### 서울대\n",
    "    - 성적(퍼포먼스)이 좋은 학생\n",
    "    \n",
    "## 5.3. 신용카드 사기 탐지\n",
    "### 사기 카드 거래 탐지 시스템 (Score)\n",
    "- 시간, 금액, 나라 등의 정보를 가지고 판정\n",
    "    - 신종 사기가 등장하면 사람도, AI도 못잡는다.\n",
    "        - 과거의 데이터로 학습, 완전 새로운 유형의 이벤트는 잡기 어렵다.\n",
    "        \n",
    "## 5.4. 피싱 탐지\n",
    "### 키스트로크 다이나믹스\n",
    "\n",
    "\n",
    "## 5.5. 민원 고객 예측\n",
    "### 민원 접수 가능성\n",
    "- 저 사람이 민원을 낼지 안 낼지 사전에 예측하는 게 초유의 관심사\n",
    "    - 찜찜한 사람 : 찜찜 표시 -> 상담원의 주관적 판단... 곤란함\n",
    "    \n",
    "- 금감원 민원 : 접수 건수를 가지고... 혼을 냄... 엉터리 민원이 많음. 무조건 건수를 줄이는 게 중요함.\n",
    "    - 고객이 말 한 단어를 가지고 민원을 ㅐㄴㄹ지 안 낼지 \n",
    "    - 음성을 분석해서 \n",
    "    - 민원을 많이 내는 직업군이 있다.\n",
    "        - 특정 직업군이 민원을 많이 냄.\n",
    "    \n",
    "    \n",
    "    - 민원 접수 가능 Score\n",
    "\n",
    "#### Q2. 어떤 직업군이 민원을 많이낼까?\n",
    "\n",
    "    \n",
    "# 6. 금융\n",
    "## 6.1. 기업 분류\n",
    "### 기업 사업보고서 분석\n",
    "- 어떤 기업하고 어떤 기업이 비슷하다고 묶어서 분류 (유형화, 전자/화학/서비스/기계)\n",
    "- 10K 서류 등장 단어 기준 기업 분류\n",
    "    - NLP\n",
    "    - TF - IDF\n",
    "    - Wordcloud\n",
    "    \n",
    "- 분류하는 이유 : 포트폴리오를 만들기 위해서\n",
    "    - 전자/식음료 회사가 누군지 알고 투자를 해야하니까.\n",
    "\n",
    "#### Q3. NLP 한글은 어렵지 않을까?\n",
    "\n",
    "## 6.2. 세계 경제 모니터링\n",
    "\n",
    "#### BIS\n",
    "- http://www.bis.org/list/cbspeeches/index.htm\n",
    "- 기간 : 2001.01.01 ~ 2013.09.30\n",
    "- 연설문 수 : 8,868개\n",
    "- 작년 대비 많이 쓰는 단어 찾기\n",
    "    - 그냥 너무 흔하게 많이 쓰는 단어는 의미가 없다(정보량 X).\n",
    "    \n",
    "    - 나라마다 관심이나 처한 상황에 따라 쓰는 단어가 다르다.\n",
    "        - 2004\n",
    "            - 일본은 QE : 양적 완화(= 정부가 돈 살포, 경기가 안 좋아서)\n",
    "            - 독일 : 재정 적자\n",
    "            - 미국 : 기업에 대한 지배권에 대한 스캔들 이슈\n",
    "            - common : 유지 가능하냐\n",
    "        \n",
    "        - 2007\n",
    "            - Subprime-Mortgage\n",
    "                - 금융위기는 2008년 9월... 리먼브라더스 망함\n",
    "                - 중앙은행 총재는 2007년 부터 말하고 다녔다.\n",
    "                - 이런 게 인사이트. 선제적 대응\n",
    "            - Foreclosures : 계약이 미리 닫히는 것(파산)\n",
    "\n",
    "        - 2010\n",
    "            - Recovery Reform : 회복\n",
    "                - 주가가 원상복귀 된 때가 2011년\n",
    "                - 이 사람의 연설문은 누구나 들을 수 있다.\n",
    "                \n",
    "                - 한국은행 의뢰를 받아서 보고 있음\n",
    "                - 한국은행의 문제는... 1년에 600~700건, 주요국가 300건\n",
    "                    - 하루에 1건씩 나오는데 1명이 보고 있음.\n",
    "                    \n",
    "        - 2013년 이맘때 분석...\n",
    "        \n",
    "        - 인사이트를 보고 어떤 액션을 취할 것이냐?\n",
    "\n",
    "#### Q4. Pdf 파일 - 스크래이핑.\n",
    "- 리스트 ... 8000개\n",
    "    - 미국, 유럽, 영국, 독일, 일본\n",
    "        - PDF or Scraping ?\n",
    "            - 논문 형식으로 파일만 올라와 있는 경우가 있다.\n",
    "            \n",
    "        - 8,000여개의 텍스트를 어떻게 분석했는지?\n",
    "            - 단순 빈도 분석?\n",
    "            - TF-IDF\n",
    "    \n",
    "\n",
    "## 6.3. 실적 컨퍼런스 콜 분석\n",
    "\n",
    "\n",
    "# 결론 : Data Insight Value\n",
    "\n",
    "(어떤) Value (를 만들 것인가) -> Insight(를 발견)\n",
    "\n",
    "## 새로운 인사이트의 적용 시 리스크 관리\n",
    "    - 단계별 접근\n",
    "    - 전체 적용하지 말고, 처음에 20% 적용 (시범)\n",
    "    - 피드백 확인 후, 점차 확대 적용\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅데이터를 인사이트로\n",
    "## 인공지능 AI\n",
    "\n",
    "지식 = 명제\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
