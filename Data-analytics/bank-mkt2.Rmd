---
title: "bank-mkt2"
author: "Andrew Jang"
date: "11/24/2018"
output:
  html_document:

    toc: TRUE
    
    toc_float: true

    fig_height: 4

    fig_width: 7

    code_folding: hide

    theme: simplex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Introduction {.tabset}

<img src = "http://thevaultzmag.com/wp-content/uploads/2018/02/bank.jpg">

## 1.1. Intelligent Targeting {-}

**- What is Marketing?**

"The process by which companies create value for customers and build strong customer relationships in order to capture value from customers in return(기업이 **고객을 위해 가치를 창출하고, 고객 관계를 구축하여, 고객의 가치를 보상하는 프로세스**)." - __Kotler and Armstrong (2010)__

  - (본인이 생각하는) 마케팅이란 가치 교환의 과정이라고 생각한다. 고객과 기업이 만들어내는 각각의 가치를 어떻게 교환할 것인지, 그 과정을 만들어내는 걸 마케팅이라고한다. 더 간단하게 요약하자면, **'고객의 행동을 이끌어 내는** 것이라고 말 할 수 있다. 짧게 요약했지만, 그 안에는 무수히; 많은 과정과 노력이 필요하다. 가치 교환의 과정에서 모든 행동의 주체는 기업이다. 물론 고객의 관점에서 마케팅을 수행해야하지만 기업이 주체가 되어서 해야할 일을 하는 것이 마케팅이다. 



**- The 4P's:**

마케팅 캠페인은 고객의 요구 사항과 전반적인 만족도에 중점을 둔다. 그럼에도 불구하고 마케팅 캠페인의 성공 여부를 결정하는 다양한 변수가 있다. 캠페인을 할 때 고려해야 할 몇 가지 변수가 있다.

1) Segment of the __Population__
        - "마케팅 캠페인이 집단의 어느 대상에 이루어지며 그 이유는 무엇인가?" 이러한 측면은 인구 중 어느 부분이 메시지를 받을 가능성이 가장 높은지를 알려주기 때문에 매우 중요하다.

2) Distribution channel to reach the customer's __place__
        - 캠페인을 최대한 활용하려면 가장 효과적인 전략을 구현해야한다. 인구 중 어느 집단을 다루고, 기업의 메시지를 전달하기 위해 어떤 도구를 사용해야하는가? (예 : 전화, 라디오, TV, 소셜 미디어 등)

3) __Price__
        - 잠재 고객에게 제공할 수 있는 가장 좋은 가격은 얼마인가? (은행의 경우, 그들의 주요 관심사는 잠재 고객이 정기예금 계좌를 개설하여 은행의 운영 활동을 계속할 수 있도록 하기 위한 것이므로 필요하지 않다.)

4) __Promotional__ Strategy
        - 전략이 구현되고 잠재 고객이 어떻게 대응할 것인가이다. 이것은 이전에 했던 실수에 대해 배우고 마케팅 캠페인을 훨씬 효과적으로 만드는 방법을 결정하기 위해 (가능하면)이전 캠페인에 대한 철저한 분석이 있어야 하기 때문에 마케팅 캠페인 분석의 마지막 부분이어야 한다.


**- What is a Term Deposit?**

정기 예탁(Deposit)은 특정 시점(만기)에 돈이 반환되는 고정 금리(예 : 예금 계좌보다 나은)로 은행이나 금융 기관이 제공하는 예금이다. [more](https://www.investopedia.com/terms/t/termdeposit.asp)

## 1.2. Aim {-}
**1) Data Analysis**

    - 은행의 고객 데이터를 바탕으로 고객 특성을 분석

**2) Data Analytics**
    
    - 나이, 직업, 결혼 여부 등의 고객 정보 및 마케팅 이력을 통해 고객의 정기예금 가입 여부를 예측 (Yes / No)
        - 고객의 과거 이력과 유사한 고객군들의 데이터를 기반으로 해당 고객이 가입할지 예측
    

## 1.3. Data Description {-}

**- bank client data:**

1 - __age__: (numeric)<br>
2 - __job__: type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')<br>
3 - __marital__: marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)<br>
4 - __education__: (categorical: primary, secondary, tertiary and unknown)<br>
5 - __default__: has credit in default? (categorical: 'no','yes','unknown')<br>
6 - __housing__: has housing loan? (categorical: 'no','yes','unknown')<br>
7 - __loan__: has personal loan? (categorical: 'no','yes','unknown')<br>
8 - __balance__: Balance of the individual.<br>

**- Related with the last contact of the current campaign:**

8 - __contact__: contact communication type (categorical: 'cellular','telephone')<br>
9 - __month__: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')<br>
10 - __day__: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')<br>
11 - __duration__: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.<br>

**- other attributes: **

12 - __campaign__: number of contacts performed during this campaign and for this client (numeric, includes last contact)<br>
13 - __pdays__: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)<br>
14 - __previous__: number of contacts performed before this campaign and for this client (numeric)<br>
15 - __poutcome__: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')<br>

**- Output variable (desired target):**

16 - __deposit__ : has the client subscribed a term deposit? (binary: 'yes','no')

# 2. Preprocessing {.tabset}
## 2.1. Import library & Load data {-}

**- Libraries : **
```{r, message=F, warning=F, fig.height=6, fig.width=12}

suppressPackageStartupMessages({
library(data.table)
library(dplyr)
library(tidyr)
library(lubridate)
library(DT)
library(ggplot2)
library(corrplot)
library(ggthemes)
library(sqldf)

library(readr)
    
library(caret)
library(ROCR)
library(C50)
library(e1071)
library(pROC)
    
library(rattle)
library(rpart.plot)
library(RColorBrewer)
    
library(rpart)
library(randomForest)
  
library(forecast)
library(zoo)
library(DescTools)
library(knitr)
library(VIM)
library(mice)
library(psych)
library(gmodels)
library(gridExtra)
library(caTools)
library(class) # knn
library(DMwR)
library(ipred) # bagging
library(adabag) # boosting

library(Epi)
library(mlbench)
})

fillColor = "#FFA07A"
fillColor2 = "#F1C40F"
```

**- Load data: **
```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank <- read.csv("./input/bank.csv", na.string = c("", " "))
```

## 2.2. Peek into the Data {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(bank, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

## 2.3. Number of Numeric & Factor Variables {-}

- 7 numeric variables
- 10 factor variables

```{r, message=F, warning=F, fig.height=6, fig.width=12}
# number of numeric & factor variables
numeric_var <- sapply(bank, is.numeric)
factor_var <- sapply(bank, is.factor)

bank_numeric <- bank[, numeric_var]
bank_factor <- bank[, factor_var]
```

## 2.4. Data cleaning {.tabset}
### 2.4.1. Missing values {-}
**- Missing values : No missing values**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
# 변수 별로 missing data의 개수 확인
colSums(is.na(bank))
```

### 2.4.2. Outliers {-}
**- Outlier : Boxplot을 활용한 이상치 판별 및 제거**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
boxplot(bank)
```

**- Outlier : Age**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
summary(bank$age)
b_age <- boxplot(bank$age, main = "Age") # Boxplot of age variable
```

**- Outlier capping : Age **
```{r, message=F, warning=F, fig.height=6, fig.width=12}
upper_side_outliers_age <- quantile(bank$age, 0.75) + 1.5*IQR(bank$age)
bank[bank$age > round(upper_side_outliers_age), "age"] <- round(upper_side_outliers_age)

#min(bank$age)
#max(bank$age)

bank$ages <- trunc(bank$age/10) * 10

bank$age_2 <- ifelse(bank$age >= 18 & bank$age < 40, "adult",
                     ifelse(bank$age >= 40 & bank$age < 60, "middle age",
                            ifelse(bank$age >= 60, "older", "child")))

bank$age_2 <- as.factor(bank$age_2)

table(bank$age_2)
boxplot(bank$age, main = "Age")
```

**- Outlier : Duration**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
b_duration <- boxplot(bank$duration/60, main = "Duration") # Boxplot of duration variable
```

**- Outlier capping : Duration **
```{r, message=F, warning=F, fig.height=6, fig.width=12}
upper_side_outliers_duration <- quantile(bank$duration, 0.75) + 1.5*IQR(bank$duration)
bank[bank$duration > round(upper_side_outliers_duration), "duration"] <- round(upper_side_outliers_duration)

#min(bank$duration)
#max(bank$duration)

boxplot(bank$duration, main = "Duration")


bank$duration<-ifelse(bank$duration<5 ,"1",ifelse(bank$duration>=5 & bank$duration<10,"2",
               ifelse(bank$duration>=10 & bank$duration<15,"3","4")))

bank$duration<-as.factor(bank$duration)

table(bank$duration)
```

### 2.4.3. Month {-}
**- Convert data type**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$month <- ifelse(bank$month == 'apr', 4,
                ifelse(bank$month == 'aug', 8,
                ifelse(bank$month == 'dec', 12,
                ifelse(bank$month == 'feb', 2,
                ifelse(bank$month == 'jan', 1,
                ifelse(bank$month == 'jul', 7,
                ifelse(bank$month == 'jun', 6,
                ifelse(bank$month == 'mar', 3,
                ifelse(bank$month == 'may', 5,
                ifelse(bank$month == 'dec', 12,
                ifelse(bank$month == 'oct', 10,
                ifelse(bank$month == 'nov', 11, 9))))))))))))

table(bank$month)
```

# 3. Exploratory Data Analysis {.tabset}
**은행의 고객 데이터를 바탕으로 고객 특성을 분석 **

## EDA 1 : Deposit rate {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}

deposit_summary <- bank %>%
  group_by(deposit) %>%
  summarise(cnt = n()) %>%
  mutate(prob = cnt / sum(cnt))

crude_deporate <- deposit_summary$prob[deposit_summary$deposit=="yes"]

kable(deposit_summary, caption="2x2 Contingency Table on Deposit.", format="markdown")

ggplot(data =deposit_summary, aes(x = deposit, y = prob)) +
  geom_bar(stat = "identity", fill = fillColor2) +
  geom_text(aes(x = deposit, y = 0.05, label = paste0("(",round(prob,2)*100, "%)",sep="")),
            hjust=0.5, vjust=.5, size = 4, colour = 'black',
            fontface = 'bold') +
  labs(x = 'Deposit', 
       y = 'Prob', 
       title = 'Deposit rate') +
  theme_minimal()
``` 
    
## EDA 2 : Age and Deposit {-}

**- Summary : Age**

    비율로 보면 노년층이 예금 가입률(76.92%)이 가장 높지만 그들이 차지하는 비중이 적기 때문에 노년 가입자를 늘리기 위한 맞춤형 전략을 세우거나, 청년과 중년층을 집중 공략하는 것이 좋다. 30, 40, 50, 20대 순으로 많다. 그말인 즉슨, 아직 20대에 더 많은 잠재고객이 있다는 뜻이기도 하다. 미래의 잠재 고객을 확보해서 장기적으로 관계(거래)를 유지하는 것이 은행의 이익에 도움이 되기 때문에 그들을 유입하기 위해서는 청년들이 많이 모이는 공간(대학 캠퍼스나 페스티벌, 번화가)에서 마케팅 캠페인을 벌이는 것도 좋은 방법이 될 것 같다.

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
ages_freq <- sqldf("
select
    ages
    , count(*) as freq
from bank
group by 1")

age_2_deposit <- sqldf("
select
    age_2
    , deposit_tot
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from (
       select
            age_2
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by age_2
)") 

ages_deposit <- sqldf("
select
    ages
    , deposit_tot
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from(
       select
            ages
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by ages
);")


ages_deposit_vis <- sqldf("
select
    a.ages
    , deposit
    , round(100. * freq / tot_freq, 2) as prob
from (
    select
        ages
        , deposit
        , count(*) as freq
    from bank
    group by 1, 2
    ) as a, (

    select
        ages
        , count(*) as tot_freq
    from bank
    group by 1
    ) b
where a.ages = b.ages
;")
```
```{r echo = FALSE, results = 'asis'}
#kable(ages_freq, caption = "Customers ages and deposit.")
#kable(age_2_deposit, caption = "Customers age group and deposit.")
#kable(ages_deposit, caption = "Customers ages and deposit.")
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(ages_freq, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(age_2_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(ages_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```


**- Visualization**

```{r, message=F, warning=F, fig.height=6, fig.width=12}
ggplot(bank,aes(age,fill=deposit)) +
  geom_bar() +
  ggtitle("Deposit by Age") +
  theme_economist() -> p1
p1

#ggplot(bank,aes(age_2,fill=deposit)) + geom_bar() +
#  ggtitle("Age vs Deposit") +
#  theme_economist() -> p2
#p2

ggplot(bank, aes(age_2, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Age") + 
  theme_minimal() -> p2
p2


ggplot(bank, aes(age_2, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
  ggtitle("Deposit rate by Age") + 
  theme_minimal() -> p3
p3

ggplot(data = ages_freq, aes(x = ages, y = freq)) +
  geom_bar(stat="identity", colour="white", fill = fillColor2) +
  geom_text(aes(x = ages, y = 1, label = paste0("(",freq,")",sep="")),
            hjust=0, vjust=.5, size = 4, colour = 'black',
            fontface = 'bold') +
  labs(x = 'Ages', 
       y = 'Freq',
       title = "Ages Distribution (Deposit 'Y')") +
  coord_flip() +
  theme_minimal() -> p4
p4


ggplot(age_2_deposit, aes(x = "", y = deposit_y, fill = factor(age_2))) +
  geom_bar(width = 1, stat = "identity") +
  theme(axis.line = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  labs(fill = "age", x = NULL, y = NULL,
       title = "Deposit 'Y' Contribution") +
  coord_polar(theta = "y", start = 0) +
  theme_economist() -> p5
p5
```


## EDA 3 : Job and Deposit {-}
**- Summary**

    비율이나 빈도로 보면 은퇴자들이 예금 상품에 가장 많이 가입한 것을 확인할 수 있다. 은퇴를 앞둔 사람들을 대상으로 금융 상품을 설계해서 맞춤형으로 다가가면 더 많은 모객을 할 수 있을 것으로 예상된다. 기업가와 생산직 노동자, 기술자, 서비스 종사자의 가입률이 낮은데 ROI를 계산해서 접근하면 좋을 것 같다. 관리직에 있는 사람들의 가입률은 50%에 달하는데 고정적으로 수입이 있기 때문에 그들을 자사의 고객으로 가입시키면서 장기적인 관계를 유지하는 전략을 취하는 것이 좋겠다(추후에 머신러닝으로 모형을 만들어서 그들이 가입할만한 상품을 권유한다면 회사에 장기적인 이익을 극대화할 수 있을 것이다).

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
job_deposit <- sqldf("
select
    job
    , deposit_tot
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from(
       select
            job
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by 1
) a
")

job_deposit_vis <- sqldf("
select
    a.job
    , deposit
    , round(100. * freq / tot_freq, 2) as prob
from (
    select
        job
        , deposit
        , count(*) as freq
    from bank
    group by 1, 2

    ) as a, (
    
    select
        job
        , count(*) as tot_freq
    from bank
    group by  1
    ) as b
where a.job = b.job
")
```

```{r echo = FALSE, results = 'asis'}
#kable(job_deposit, caption = "Job and Deposit.")
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(job_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#ggplot(bank,aes(job,fill=deposit))+geom_bar()+
#  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
#  ggtitle("Job vs Deposit") +
#  theme_economist() -> p5
#p5

#ggplot(data = job_deposit_vis, aes(x = job, y = prob, fill = deposit)) +
#  geom_bar(stat = "identity") + 
#  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
#  ggtitle("Job vs Deposit") +
#  theme_economist() -> p6
#p6

ggplot(bank, aes(job, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Jobs") + 
  theme_minimal() -> p5
p5

ggplot(bank, aes(job, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
  ggtitle("Deposit rate by Jobs") + 
  theme_minimal() -> p6
p6
```

## EDA 4 : Marital and Deposit {-}
**- Summary**

    결혼한 사람들의 가입자 수가 많지만, 비율은 오히려 이혼했거나 미혼일 경우가 더 많다. 가입자의 지역까지 알 수 있다면 지역 인구의 분포를 고려해서 지역별, 고객별 세분화된 마케팅(맞춤형 상품 추천)이 가능할 것 같다.

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
marital_deposit <- sqldf("
select
    marital
    , deposit_tot
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from(
       select
            marital
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by 1
)")

marital_deposit_vis <- sqldf("
select
    a.marital
    , deposit
    , round(100. * freq / tot_freq ,2) as prob
from (
       select
            marital
            , deposit
            , count(*) as freq
       from bank
       group by 1, 2
    ) as a, (
    select
        marital
        , count(*) as tot_freq
    from bank
    group by 1
    ) as b
where a.marital = b.marital
;
")
```
```{r echo = FALSE, results = 'asis'}
#kable(marital_deposit, caption = "Deposit by Marital")
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(marital_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#ggplot(bank, aes(marital, fill=deposit)) + geom_bar() +
#  ggtitle("Marital vs Depsoit") +
#  theme_economist() -> p7
#p7

#ggplot(data = marital_deposit_vis, aes(x = marital, y = prob, fill = deposit)) +
#  geom_bar(stat = "identity") +
#  ggtitle("Marital vs Depsoit") +
#  theme_economist() -> p8
#p8


ggplot(bank, aes(marital, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Jobs") + 
  theme_minimal() -> p7
p7

ggplot(bank, aes(marital, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
  ggtitle("Deposit rate by Marital") + 
  theme_minimal() -> p8
p8
```

## EDA 5 : Education and Deposit {-}
**- Summary**
    
    중등 교육을 받은 사람들의 예금 가입자가 많고 고등 교육을 받은 사람들이 그 뒤를 따르고 있다. 허나 비율로 보면 고등 교육을 받은 사람들의 가입률이 가장 높기 때문에 잠재 고객의 대상으로 그들을 공략하는 것이 효율적이다.

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
education_deposit <- sqldf("
select
    education
    , deposit_tot
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from(
       select
            education
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by 1)
")


education_deposit_vis <- sqldf("
select
    a.education
    , deposit
    , round(100. * freq / tot_freq ,2) as prob
from (
       select
            education
            , deposit
            , count(*) as freq
       from bank
       group by 1, 2
    ) as a, (
        select
            education
            , count(*) as tot_freq
        from bank
        group by 1
    ) as b
where a.education = b.education
")
```
```{r echo = FALSE, results = 'asis'}
#kable(education_deposit, caption = "Deposit by Education")
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(education_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#ggplot(bank,aes(education,fill=deposit))+geom_bar() +
#  ggtitle("Education vs Deposit") +
#  theme_economist() -> p9
#p9

#ggplot(data = education_deposit_vis, aes(x = education, y = prob, fill = deposit)) +
#  geom_bar(stat = "identity") +
#  ggtitle("Education vs Deposit") +
#  theme_economist() -> p10
#p10


ggplot(bank, aes(education, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Education") + 
  theme_minimal() -> p9
p9

ggplot(bank, aes(education, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
  ggtitle("Deposit rate by Education") + 
  theme_minimal() -> p10
p10
```

## EDA 6 : Defalut and Deposit {-}
**- Summary**
    
    돈을 사용하지 않고 저축한다는 의미는 소득을 전부 소비해야하는 사람들에 비해 여유롭다는 뜻이기도 하다. 대출이나 연체 이력이 있는 사람들에 비해 상대적으로 여유 자금이 있다거나 돈을 저축할 여력이 있다는 것을 의미하기 때문에 재정적으로 건전한 고객을 대상으로 마케팅을 벌이는 것이 좋겠다.
    
**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#ggplot(bank,aes(default,fill=deposit))+geom_bar() +
#  ggtitle("Default vs Deposit") +
#  theme_economist() -> p11
#p11

ggplot(bank, aes(default, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Default") + 
  theme_minimal() -> p11
p11

ggplot(bank, aes(default, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
  ggtitle("Deposit rate by Default") + 
  theme_minimal() -> p12
p12

```

## EDA 7 : Balance and Deposit {-}
**- Summary**

    잔고의 분포를 살펴보면 평균액은 1,529달러 이며 중앙값은 550달러 정도이다. 최대 금액은 81,204 달러이다.

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
summary(bank$balance)
Desc(bank$balance)
```

**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
ggplot(bank,aes(balance))+geom_histogram(aes(fill=deposit),color="black")+
  ggtitle("Balance vs Deposit") +
  theme_economist() -> p13
p13


#ggplot(bank, aes(balance, fill=deposit)) +
#  geom_bar(position="stack") +
#  scale_fill_brewer(palette="Set1") +
#  #scale_y_continuous(labels=comma) +
#  ylab("Customers") +
#  ggtitle("Deposit by Balance") + 
#  theme_minimal() -> p13
#p13

ggplot(data = bank, aes(x = deposit, y = balance)) +
  geom_point(stat = "identity") +
  theme_minimal() +
  coord_flip() -> p14
p14

#ggplot(bank, aes(balance, fill=deposit)) +
#  geom_bar(position="fill") +
#  scale_fill_brewer(palette="Set1") +
#  #scale_y_continuous(labels=percent) +
#  ylab("Conversion rate") +
#  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
#  ggtitle("Deposit rate by Balance") + 
#  theme_minimal() -> p14
#p14

boxplot(bank$balance) -> p15
p15

#ggplot(bank, aes(balance)) +
#  geom_boxplot(stat = "identity") +
#  ggtitle("Balance Distribution") +
#  theme_economist() -> p122
#p122
```

## EDA 8 : Housing and Deposit {-}

**- Summary**
    
    주택 융자가 없는 사람들은 보유한 사람들보다 예금 가입자 수와 가입률 모두 높다. 내 집 마련으로 주머니에서 나가는 돈이 없기 때문에 여유자금으로 적금 상품에 가입하는 것 같다. 

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
housing_deposit <- sqldf("
select
    housing
    , deposit_tot
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from(
       select
            housing
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by 1
) ")


housing_deposit_vis <- sqldf("
select
    a.housing
    , deposit
    , round(100. * freq / tot_freq ,2) as prob
from(
       select
            housing
            , deposit
            , count(*) as freq
       from bank
       group by 1, 2
    ) as a , (
        select
            housing
            , count(*) as tot_freq
        from bank
        group by 1
    ) as b
where a.housing = b.housing
")
```
```{r echo = FALSE, results = 'asis'}
#kable(housing_deposit, caption = "Deposit by Housing")
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(housing_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#ggplot(bank,aes(housing,fill=deposit)) + geom_bar() +
#  ggtitle("Housing vs Deposit") +
#  theme_economist() -> p16
#p16

#ggplot(data = housing_deposit_vis, aes(x = housing, y = prob, fill = deposit)) +
#  geom_bar(stat = "identity") +
#  ggtitle("Housing vs Deposit") +
#  theme_economist() -> p17
#p17


ggplot(bank, aes(housing, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Housing") + 
  theme_minimal() -> p16
p16

ggplot(bank, aes(housing, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
  ggtitle("Deposit rate by Housing") + 
  theme_minimal() -> p17
p17
```

## EDA 9 : Loan and Deposit {-}

**- Summary**
    
    개인 신용 대출을 받은 사람들보다 대출을 받지 않은 사람들의 적금 가입률과 빈도 모두 높다. 전반적으로 경제적인 여유가 생겨야 자금을 운용(적금 가입) 한다는 것을 확인할 수 있기 때문에 그들을 대상으로 타겟팅을 하는 것이 좋겠다.

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
loan_deposit <- sqldf("
select
    loan
    , deposit_tot
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from(
       select
            loan
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by 1
) ")

loan_deposit_vis <- sqldf("
select
    a.loan
    , deposit
    , round(100. * freq / tot_freq, 2) as prob
from(
       select
            loan
            , deposit
            , count(*) as freq
       from bank
       group by 1, 2
    ) as a, (
        select
            loan
            , count(*) as tot_freq
        from bank
        group by 1
    ) as b
where a.loan = b.loan
")
```
```{r echo = FALSE, results = 'asis'}
#kable(loan_deposit, caption = "Deposit by Loan")
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(loan_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#ggplot(bank, aes(loan, fill = deposit)) + geom_bar() +
#  ggtitle("Loan vs Deposit") +
#  theme_economist() -> p18
#p18

#ggplot(data = loan_deposit_vis, aes(x = loan, y = prob, fill = deposit)) +
#  geom_bar(stat = "identity") +
#  ggtitle("Loan vs Deposit") +
#  theme_economist() -> p19
#p19


ggplot(bank, aes(loan, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Loan") + 
  theme_minimal() -> p18
p18

ggplot(bank, aes(loan, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
  ggtitle("Deposit rate by Loan") + 
  theme_minimal() -> p19
p19
```

## EDA 10 : Contact and Deposit {-}
**- Summary**
    
    등록된 연락처 유형이 스마트폰인 경우가 압도적으로 많기 때문에 모바일 퍼스트 전략으로 접근하는 마케팅 캠페인을 벌이는 것이 잠재 고객의 유입률을 높이는데 기여할 것이다.

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
contact_deposit <- sqldf("
select
    contact
    , deposit_tot
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from(
       select
            contact
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by 1
)")

contact_deposit_vis <- sqldf("
select
    a.contact
    , deposit
    , round(100. * freq / tot_freq ,2) as prob

from (
    select
        contact
        , deposit
        , count(*) as freq
    from bank
    group by 1, 2
    
    ) as a, (
       select
            contact
            , count(*) as tot_freq
       from bank
       group by 1
    ) as b

where a.contact = b.contact
")

```
```{r echo = FALSE, results = 'asis'}
#kable(contact_deposit, caption = "Deposit by Contact")
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(contact_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#ggplot(bank, aes(contact, fill = deposit)) + geom_bar() +
#  ggtitle("Contact vs Deposit") +
#  theme_economist() -> p20
#p20

#ggplot(data = contact_deposit_vis, aes(x = contact, y = prob, fill = deposit)) +
#  geom_bar(stat = "identity") +
#  ggtitle("Contact vs Deposit") +
#  theme_economist() -> p21
#p21


ggplot(bank, aes(contact, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Contact") + 
  theme_minimal() -> p20
p20

ggplot(bank, aes(contact, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
  ggtitle("Deposit rate by Contact") + 
  theme_minimal() -> p21
p21
```

## EDA 11 : Month and Deposit {-}
**- Summary**
  
    3, 4, 9, 10월의 가입률이 더 높으나 빈도는 작기 때문에 그 기간에 집중적으로 캠페인을 벌이면 성공률과 수치가 높아질 것이다. 추가적으로 시계열 데이터가 있으면 시계열 분석도 하면 좋을 것 같다.

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
month_deposit <- sqldf("
select
    month
    , deposit_tot
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from(
       select
            month
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by 1)
order by 5 desc")

month_deposit_vis <- sqldf("
select
    a.month
    , deposit
    , round(100. * freq / tot_freq ,2) as prob

from (
       select
            month
            , deposit
            , count(*) as freq
       from bank
       group by 1, 2
    ) as a, (
        select
            month
            , count(*) as tot_freq
        from
            bank
        group by 1
    ) as b

where a.month = b.month
")
```
```{r echo = FALSE, results = 'asis'}
#kable(month_deposit, caption = "Deposit by Month")
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(month_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#ggplot(bank, aes(reorder(month, deposit), fill = deposit)) + geom_bar() +
  #aes(x = reorder(task1b$sub_category, sales), y = sales, label = sales)) 
#  ggtitle("Month vs Deposit") +
#  theme_economist() -> p22
#p22

#ggplot(data = month_deposit_vis, aes(x = reorder(month, prob), y = prob, fill = deposit)) +
#  geom_bar(stat = "identity") +
#  ggtitle("Month vs Deposit") +
#  theme_economist() -> p23
#p23

bank$month <- factor(bank$month)
  
ggplot(bank, aes(month, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Month") + 
  theme_minimal() -> p22
p22

ggplot(bank, aes(month, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
  ggtitle("Deposit rate by Month") + 
  theme_minimal() -> p23
p23
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}

#month_summary <- bank %>%
#                    group_by(deposit, month) %>%
#                    summarise(count = mean(deposit))

month_summary <- bank %>%
  group_by(deposit, month) %>%
  summarise(cnt = n()) %>%
  mutate(prob = cnt / sum(cnt))

ggplot(bank, aes(x = month, y = prob, colour = deposit)) +
  geom_point(data = month_summary, aes(group = deposit)) +
  geom_line(data = month_summary, aes(group = deposit)) +
  scale_x_discrete("month") +
  scale_y_continuous("Count of deposit") +
  theme_minimal() +
  ggtitle("Line chart of deposit") + 
  theme(plot.title=element_text(size=18)) +
  theme_economist() -> p24
p24
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(month_summary, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```


## EDA 12 : Campaign and Deposit {-}
**- Summary**
    
    마케팅을 5회 미안으로 진행하는 것이 가입률이 높았다. 지나친 광고 마케팅은 잠재적 고객에게 소음으로 비춰지면서 회사에 부정적인 인식을 줄 수 있으므로 마이크로 타게팅이 필요하다.

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
campaign_deposit <- sqldf("
select
    campaign
    , campaign
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from(
       select
            campaign
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by 1
)")

campaign_deposit_vis <- sqldf("
select
    a.campaign
    , deposit
    , round(100. * freq / tot_freq, 2) as prob
from (
       select
            campaign
            , deposit
            , count(*) as freq
       from bank
       group by 1, 2
    ) as a, (
        select
            campaign
            , count(*) as tot_freq
        from bank
        group by 1
    ) as b
where a.campaign = b.campaign
")

```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(campaign_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#ggplot(bank,aes(campaign)) + geom_histogram(aes(fill = deposit), color = "black", binwidth = 5) +
#  ggtitle("Campaign vs Deposit") +
#  theme_economist() -> p25
#p25

#ggplot(data = campaign_deposit_vis, aes(x = campaign, y = prob, fill = deposit)) +
#  geom_bar(stat = "identity") +
#  ggtitle("Campaign vs Deposit") +
#  theme_economist() -> p26
#p26


ggplot(bank, aes(campaign, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Campaign") + 
  theme_minimal() -> p25
p25

ggplot(bank, aes(campaign, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="brown", lty=2, size=2) +
  ggtitle("Deposit rate by Campaign") + 
  theme_minimal() -> p26
p26
```

## EDA 13 : Duration and Deposit {-}
**- Summary**
    
    4분 이상 통화를 한 사람만이 가입률이 높은데, 짧은 시간 통화한 사람들은 가입 의사가 없다고 생각할 수 있다.

**- Report**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
duration_deposit <- sqldf("
select
    duration
    , deposit_tot
    , deposit_y
    , deposit_n
    , round(100. * deposit_y / deposit_tot ,2) as deposit_y_ratio
    , round(100. * deposit_n / deposit_tot, 2) as deposit_n_ratio
from(
       select
            duration
            , count(*) as deposit_tot
            , sum(case when deposit = 'yes' then 1 else 0 end) as deposit_y
            , sum(case when deposit = 'no' then 1 else 0 end) as deposit_n
       from bank
       group by 1
)")

duration_deposit_vis <- sqldf("
select
    a.duration
    , deposit
    , round(100. * freq / tot_freq ,2) as prob
from (
       select
            duration
            , deposit
            , count(*) as freq
       from bank
       group by 1, 2
    ) as a, (
        select
            duration
            , count(*) as tot_freq
        from bank
        group by 1
    ) as b
where a.duration = b.duration
")

```
```{r echo = FALSE, results = 'asis'}
#kable(duration_deposit, caption = "Deposit by Duration")
```
```{r, message=F, warning=F, fig.height=6, fig.width=12}
datatable(duration_deposit, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

**- Visualization**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
ggplot(bank, aes(duration, fill=deposit)) +
  geom_bar(position="stack") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=comma) +
  ylab("Customers") +
  ggtitle("Deposit by Duration") + 
  theme_minimal() -> p27
p27

ggplot(bank, aes(duration, fill=deposit)) +
  geom_bar(position="fill") +
  scale_fill_brewer(palette="Set1") +
  #scale_y_continuous(labels=percent) +
  ylab("Conversion rate") +
  geom_hline(yintercept=crude_deporate, col="white", lty=2, size=2) +
  ggtitle("Deposit rate by Duration") + 
  theme_minimal() -> p28
p28
```

## Summary : Visualization {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
grid.arrange(p1,p2,p3,p4)->g1
g1
grid.arrange(p5,p6)->g2
g2
grid.arrange(p7,p8)->g3
g3
grid.arrange(p9,p10)->g4
g4
grid.arrange(p11,p12)->g5
g5
grid.arrange(p13, p14)->g6
g6
grid.arrange(p16,p17)->g7
g7
grid.arrange(p18,p19)->g8
g8
grid.arrange(p20,p21)->g9
g9
grid.arrange(p22,p23)->g10
g10
grid.arrange(p25,p26)->g11
g11
grid.arrange(p27,p28)->g12
g12

```


# 4. Feature Engineering {.tabset}
**- 전처리 요소들**

    – 데이터 정제 (Data cleaning)
      • 결측값(Missing value)
      • 이상치(Outlier)
      • 잡음(Noise)
      • 중복값(Duplicate value)
      
    – 데이터분할/병합
    
    – 표본 추출(Sampling)
    
    – 데이터 이산화 및 이진화(Discretization and binalization)
    
    – 데이터 표준화(Standardization)
    
    – 차원 축소(Dimensionality reduction)
    
    – 특징 선택 및 추출(Variable selection and feature extraction)

## 4.1.Bank Client Categorical Treatment{.tabset}
### Job {-}

**- feature vector map :**

    - admin., management : 0
    - blue-collar, technician : 1
    - entrepreneur, self-employed : 2
    - housemaid, services : 3  
    - retired : 4
    - student : 5
    - unemployed : 6
    - unknown : 7

```{r, message=F, warning=F, echo=F}
bank <- read.csv("./input/bank.csv", na.string = c("", " "))
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$job <- ifelse(bank$job == 'admin.' | bank$job == 'management', 0,
                   ifelse(bank$job == 'blue-collar' | bank$job == 'technician', 1,
                          ifelse(bank$job == 'entrepreneur' | bank$job == 'self-employed', 2,
                                 ifelse(bank$job == 'housemaid' | bank$job == 'services', 3,
                                        ifelse(bank$job == 'retired', 4,
                                               ifelse(bank$job == 'student', 5,
                                                      ifelse(bank$job == 'unemployed', 6, 7)))))))

table(bank$job)
```

### Marital {-}
**- feature vector map :**

    - divorced : 0
    - married : 1
    - single : 2

```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$marital <- ifelse(bank$marital == 'divorced', 0,
                   ifelse(bank$marital == 'married', 1, 2))
table(bank$marital)
```

### Education {-}
**- feature vector map :**

    - primary : 0
    - secondary : 1
    - tertiary : 2
    - unknown : 3

```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$education <- ifelse(bank$education == 'primary', 0,
                   ifelse(bank$education == 'secondary', 1,
                          ifelse(bank$education == 'tertiary', 2, 3)))

table(bank$education)
```

### Default {-}
**- feature vector map :**

    - no : 0
    - yes : 1

```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$default <- ifelse(bank$default == 'no', 0, 1)
table(bank$default)
```

### Housing {-}
**- feature vector map :**

    - no : 0
    - yes : 1
    
```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$housing <- ifelse(bank$housing == 'no', 0, 1)
table(bank$housing)
```

### Loan {-}
**- feature vector map :**

    - no : 0
    - yes : 1
    
```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$loan <- ifelse(bank$loan == 'no', 0, 1)
table(bank$loan)
```

### Age {-}
**- feature vector map :**

    - 10~20 : 0
    - 30~40 : 1
    - 50~60 : 2
    - 60~   : 3
    
```{r, message=F, warning=F, fig.height=6, fig.width=12}
boxplot(bank['age'])
summary(bank['age'])

bank$age <- trunc(bank$age/10) * 10
table(bank$age)

bank$age <- ifelse(bank$age == 10 | bank$age == 20, 0,
                     ifelse(bank$age == 30 | bank$age == 40, 1,
                            ifelse(bank$age == 50 | bank$age == 60, 2, 3)))


table(bank$age)
```

### Balance {-}
**- feature vector map :**

    - -6847~122  : 0
    - 122~550    : 1
    - 550~1708   : 2
    - 1708~81204 : 3

```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$balance <- ifelse(bank$balance >= -6847 & bank$balance < 122, 0,
                       ifelse(bank$balance >= 122 & bank$balance < 550, 1,
                              ifelse(bank$balance >= 550 & bank$balance < 1708, 2, 3)))

table(bank$balance)
```

## 4.2. Other Attribute Treatment {.tabset}
### Contact {-}
**- feature vector map :**

    - cellular : 0
    - telephone : 1
    - unknown : 2
    
```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$contact <- ifelse(bank$contact == 'cellular', 0,
                   ifelse(bank$contact == 'telephone', 1, 2))
table(bank$contact)
```

### Month {-}
**- pass: already convert**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$month <- ifelse(bank$month == 'apr', 4,
                ifelse(bank$month == 'aug', 8,
                ifelse(bank$month == 'dec', 12,
                ifelse(bank$month == 'feb', 2,
                ifelse(bank$month == 'jan', 1,
                ifelse(bank$month == 'jul', 7,
                ifelse(bank$month == 'jun', 6,
                ifelse(bank$month == 'mar', 3,
                ifelse(bank$month == 'may', 5,
                ifelse(bank$month == 'dec', 12,
                ifelse(bank$month == 'oct', 10,
                ifelse(bank$month == 'nov', 11, 9))))))))))))

table(bank$month)
```

### Duration {-}
**- pass: already convert**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$duration<-ifelse(bank$duration < 5 , "1",
                      ifelse(bank$duration >= 5 & bank$duration < 10, "2",
                             ifelse(bank$duration >= 10 & bank$duration < 15, "3", "4")))

bank$duration <- as.factor(bank$duration)
bank$duration <- as.integer(bank$duration)
table(bank$duration)
```

### Poutcome {-}
**- feature vector map :**

    - other & unknown : 0
    - failure : 1
    - success : 2
    
```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$poutcome <- ifelse(bank$poutcome == 'other', 0,
                        ifelse(bank$poutcome == 'unknown', 0,
                               ifelse(bank$poutcome == 'failure', 1, 2)))

table(bank$poutcome)
```

### Deposit {-}
**- feature vector map :**

    - no : 0
    - yes : 1
    
```{r, message=F, warning=F, fig.height=6, fig.width=12}
bank$deposit <- ifelse(bank$deposit == 'no', 0, 1)
#bank$deposit <- as.factor(bank$deposit)
table(bank$deposit)
```


# 5. Modeling {.tabset}
## 5.1. Setting {-}
**- Split the data:**
    
    - 80:20의 비율로 샘플링
    - set.seed : 1004
    
```{r, message=F, warning=F, fig.height=10, fig.width=15}
set.seed(1004)
flag <- sample(c("tr", "te"), size = nrow(bank), c(8, 2), replace = T)
train <- bank[which(flag == "tr"), ]
test <- bank[which(flag == "te"), ]

str(train)
str(test)

prop.table(table(bank$deposit))
```

## 5.2. Correlation Analysis {-}
```{r, message=F, warning=F, fig.height=10, fig.width=15}
data_corr <- bank

for(i in 1:ncol(data_corr)){
  
  data_corr[,i]<- as.integer(data_corr[,i])
}

corrplot(cor(data_corr), order="hclust", title="Correlation", addrect=3); #visualization
# pdays, previous and duration are highly correlated variables
```


## 5.3. K-Nearest Neighbor {.tabset}
### Setting {-}
**- Load & Split the data**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#bank <- read.csv("./input/bank.csv")

# train / test set
#set.seed(1004)
#flag <- sample(c("tr", "te"), size = nrow(bank), c(8, 2), replace = T) 
#k_train <- bank[which(flag == "tr"), ]
#k_test <- bank[which(flag == "te"), ]
#prop.table(table(bank$deposit))
```

**- Dummy label**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#bank$deposit <- ifelse(bank$deposit=="yes", 1, 0)
```

**- Preprocessing**

    – 결측치 처리,중복 데이터 제거,수치형 데이터 추출
      - Bining : age, balance, duration
      - dummy : job, marital, education, default, housing, loan, contact, poutcome, deposit
    – training set / validation set / test set (6:2:2) 구성 → k의 개수 결정
    – 독립변수 표준화
  
```{r, message=F, warning=F, fig.height=6, fig.width=12}
# NA 데이터 제거
#bank2 <- bank2[!is.na(bank2$time_spend_company), ] # tm__변수가 NA값을 가지는 데이터를 제거
#summary(bank2)

# NA 값 대치
#bank2 <- knnImputation(bank2, k = 2)
#summary(bank2)
str(bank)
```

**- Split the Data (train / validation / test set)**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
# 수치형 데이터 추출
bank_num <- bank[,sapply(bank, is.numeric) ] # 수치형 데이터만 추출

set.seed(1004)
flag <- sample(c("tr", "va", "te"), size = nrow(bank_num), c(6, 2, 2), replace = T)
k_train <- bank_num[which(flag == "tr"), ]
k_valid <- bank_num[which(flag == "va"), ]
k_test <- bank_num[which(flag == "te"), ]

prop.table(table(k_train$deposit))
prop.table(table(k_valid$deposit))
prop.table(table(k_test$deposit))

str(k_train)
str(k_valid)
str(k_test)
```

### Standardization {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
k_pp_model <- preProcess(k_train[, -17], method = c("center", "scale"))
k_tr_x <- predict(k_pp_model, k_train[, -17])
k_va_x <- predict(k_pp_model, k_valid[, -17])
k_te_x <- predict(k_pp_model, k_test[, -17])

k_tr_y <- as.factor(k_train[, 17])
k_va_y <- as.factor(k_valid[, 17])
k_te_y <- as.factor(k_test[, 17])

boxplot(k_train)
boxplot(k_tr_x)
```

### Training a model on the data (k = 5) {-}
**- Training**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
m_knn <- knn(k_tr_x, k_va_x, cl = k_tr_y, k = 5) # k = 5일 때 validation set의 예측값 
##m_knn
```

**- Predicted result table**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
t <- table(m_knn, k_va_y) # 실제 y 값과 예측된 y값의 confusion matrix 생성 
t

acc <- sum(diag(t)) / sum(t) # accuracy 계산
acc
### Confusion matrix
confusionMatrix(m_knn, k_va_y) # confusion matrix 함수 사용
```

### Find optimal k {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
acc_k <- NULL # accuracy를 누적할 NULL 벡터 생성

for(i in 1:30){
   m_knn <- knn(k_tr_x, k_va_x, cl = k_tr_y, k = i) # k = 1부터 30까지 바꿔가며 knn algorithm 학습
   t <- table(k_va_y, m_knn) 
   acc <- sum(diag(t)) / sum(t)
   acc_k <- c(acc_k, acc) # k = i의 accuracy를 acc_k 벡터에 누적
}

plot(acc_k, type ="l", xlab = "Threshold (k)", ylab = "Train accuracy")
abline(v = which.max(acc_k), col = "red", lty = 2)
points(which.max(acc_k), max(acc_k), pch = 19, col = "red")
text(which.max(acc_k), max(acc_k), pos =4, labels = round(max(acc_k), 2), col = "red", cex = 0.8)


which.max(acc_k) # 최대 accuracy를 나타내는 optimal k
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}
m_knn <- knn(k_tr_x, k_va_x, cl = k_tr_y, k = 16)
t <- table(m_knn, k_va_y)
confusionMatrix(m_knn, k_va_y)
```

### Evaluating model performance {-}
**- Test accuracy:**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
final_knn <- knn(k_tr_x, k_te_x, cl = k_tr_y, k = which.max(acc_k)) # accuracy max값을 가지는 k값을 이용하여 test set 예측
t <- table(k_te_y, final_knn)
t

acc <- sum(diag(t)) / sum(t)
acc # 최종 accuracy
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}

```

## 5.3. Logistic Regression {.tabset}
### Setting {-}
**- Load & Split the data**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#bank <- read.csv("./input/bank.csv")

# train / test set
#set.seed(1004)
#flag <- sample(c("tr", "te"), size = nrow(bank), c(8, 2), replace = T) 
#train <- bank[which(flag == "tr"), ]
#test <- bank[which(flag == "te"), ]
#prop.table(table(bank$deposit))
```

**- Dummy label**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#bank$deposit <- ifelse(bank$deposit=="yes", 1, 0)
```

### Training a model on the data {-}
**- Training a model:**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
m_logis <- glm(deposit ~ ., data=train, family=binomial(link='logit'))
summary(m_logis)
```

**- coefficients**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
exp(coef(m_logis))
```

**- train set prediction:**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
pred_tr_logit <- predict(m_logis, train, type="response", na.action = na.pass)

t <- table(train$deposit, pred_tr_logit > 0.5)

# train set accuracy
acc <- sum(diag(t)) / sum(t)
acc

pred_tr_logit <- ifelse(pred_tr_logit > 0.5, 1, 0) # YES, NO

confusionMatrix(table(train$deposit, pred_tr_logit), positive = '1')

ROC(pred_tr_logit, train$deposit)
```

**- test set prediction:**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
pred_te_logit <- predict(m_logis, test, type="response", na.action = na.pass)

t <- table(test$deposit, pred_te_logit > 0.5)

# test set accuracy
acc <- sum(diag(t)) / sum(t)
acc

pred_te_logit <- ifelse(pred_te_logit > 0.5, 1, 0) # YES, NO
confusionMatrix(table(test$deposit, pred_te_logit), positive = '1')
```

### Area under the curve (ROC-AUC) {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
ROC(pred_tr_logit, train$deposit)
ROC(pred_te_logit, test$deposit) # also try adding plot="sp"
a1=ROC(form=deposit~., data=train, plot="ROC")
a1=ROC(form=deposit~., data=test, plot="ROC")
```

### Cross validation {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}

ctrl1 <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)

mod_fit1 <- train(deposit ~.,  data=bank, method="glm", family="binomial",
                 trControl = ctrl1, tuneLength = 5)

summary(mod_fit1)

pred_cross1 = predict(mod_fit1, newdata=test)
pred_cross1<-ifelse(pred_cross1 > 0.5, 1, 0)
# accuracy 81
```

### Variable importance {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
varImp(m_logis, scale=FALSE)
```

### Stepwise logistic regression {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
full_m <- glm(deposit~., data = train, family = "binomial")
null_m <- glm(deposit~1., data = train, family = "binomial")
m_logis_step <- step(null_m, direction = "both", trace = F, scope = list(lower = null_m, upper = full_m))
m_logis_step
summary(m_logis_step)
```

**- training data class prediction**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
pred_tr <- predict(m_logis_step, type = "response")
```

**- trainig set classification 성능**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
t <- table(train$deposit, pred_tr > 0.5) # threshold = 0.5기준으로 confusion matrix
t
acc_tr <- sum(diag(t)) / sum(t) # training accuracy
acc_tr
```

**- test dataset classification 성능**
```{r, message=F, warning=F, fig.height=6, fig.width=12}

pred_te <- predict(m_logis_step, test, type = "response") # class prediction


t_te <- table(test$deposit, pred_te >0.5) # confusion matrix
t_te
acc_te <- sum(diag(t_te)) / sum(t_te) # test accuracy
acc_te
```

### Grid Search {-}

**- 가장 높은 accuracy를 보여주는 threshold 탐색**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
acc_th <- NULL
threshold <- seq(0.1, 0.9, by = 0.1) # threshold 범위: 0.1~0.9 범위에서 0.1씩 증가시키면서 탐색
for(i in threshold){
  pred_te <- predict(m_logis_step, test, type = "response") # class prediction

  t_te <- table(test$deposit, pred_te > i) # confusion matrix
  t_te
  acc_te <- sum(diag(t_te)) / sum(t_te) # test accuracy
  acc_te # test accuracy
  
  acc_th <- c(acc_th, acc_te)
}

# plotting
plot(threshold, acc_th, type = "l", xlab = "Threshold", ylab = "Test accuracy")
abline(v = threshold[which.max(acc_th)], col = "red", lty = 2)
points(threshold[which.max(acc_th)], max(acc_th), pch = 19, col = "red")
text(threshold[which.max(acc_th)], max(acc_th), pos =4, labels = round(max(acc_th), 2), col = "red", cex = 0.8)
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}
##### threshold = 0.6 test result
t_te <- table(test$deposit, pred_te > 0.5) # confusion matrix
t_te

acc_te <- sum(diag(t_te)) / sum(t_te) # test accuracy
acc_te # test accuracy
```

**- result plot**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
plot(pred_te, col = as.factor(test$deposit), pch = 19, ylim = c(0, 1), ylab = "Predicted class")
abline(h = 0.6, lty = 2)
```

## 5.4. Decision Tree : CART {.tabset}
### Training a model on the data {-}
- cp(Complexity Parameter) : cp 값을 작게 줄수록 복잡도가 올라감<br>
- rpart 함수에서 조절 가능한 parameter <br>
    - minsplit : min of observations (20)<br>
    - xval : of closs validation (10)<br>
    - maxdepth : max depth of any node (30)<br>
```{r, message=F, warning=F, fig.height=6, fig.width=12}
set.seed(1004)
## Training
dt <- rpart(as.factor(deposit)~., data = train, cp = 0.1^20) # 모든 변수 사용, Full tree 생성

xerror_min_which <- which.min(dt$cptable[, "xerror"])
xerror_min <- min(dt$cptable[, "xerror"])
```

### Cross Validation: Pruning {-}
- Training Set을 이용하여 Cross Validation 수행 <br>
    - 이유 : training할 때, 포함되지 않았던 data로 error를 측정해서 성능을 검증하기 위해서 <br>
- validation Error가 증가하는 시점에서 가지치기
```{r, message=F, warning=F, fig.height=6, fig.width=12}
printcp(dt) # cptable 출력
plotcp(dt) # cpplot 출력

abline(v = xerror_min_which, lty = 2, col = "red")
text(xerror_min_which, xerror_min, labels = round(xerror_min_which, 2), pos = 3, col = "red")

# pruning
dt_prune <- prune(dt, cp = dt$cptable[which.min(dt$cptable[, "xerror"]), "CP"])
```

### Evaluating model performance {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
# training accuracy
pred_tr_dt <- predict(dt_prune, train, type = "prob", na.action = na.pass) # prob(확률), class(범주형)으로 예측
pred_tr_dt <- ifelse(pred_tr_dt > 0.5, 1, 0) # yes, no
pred_tr_dt <- pred_tr_dt[,2]

confusionMatrix(table(train$deposit, pred_tr_dt), positive = '1')

ROC(pred_tr_dt, train$deposit)

# test accuracy
pred_te_dt <- predict(dt_prune, test, type = "prob", na.action = na.pass)
pred_te_dt <- ifelse(pred_te_dt > 0.5, 1, 0) # yes, no
pred_te_dt <- pred_te_dt[, 2]

confusionMatrix(table(test$deposit, pred_te_dt), positive = "1")
ROC(pred_te_dt, test$deposit)
```

### Summary : Visualization {-}
```{r, message=F, warning=F, fig.height=15, fig.width=23}
# plotting
plot(dt_prune, margin = 0.1)
text(dt_prune, use.n = T)

dt_prune$variable.importance

barplot(dt_prune$variable.importance, ylim = c(0, 400))

fancyRpartPlot(dt_prune, cex = 1, palettes = c("Greys","RdPu")) #fancy tree
```

## 5.5. Decision Tree : C5.0 {.tabset}
### Training a model on the data {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
set.seed(1004)
# build the simplest decision tree
dt_c5 <- C5.0(as.factor(deposit)~., data = train)

# display simple facts about the tree
dt_c5
```

```{r, message=F, warning=F, fig.height=15, fig.width=20}
plot(dt_c5, main="Decision Tree Plot (C5.0)")
```

### Evaluating model performance {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
## Evaluating model performance
# create a factor vector of predictions on test data
pred_tr_dt_c5 <- predict(dt_c5, train, type = "prob")

pred_tr_dt_c5 <- ifelse(pred_tr_dt_c5 > 0.5, 1, 0) # yes, no
pred_tr_dt_c5 <- pred_tr_dt_c5[, 2]

ROC(pred_tr_dt_c5, train$deposit)
confusionMatrix(table(train$deposit, pred_tr_dt_c5), positive = "1")
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}

pred_te_dt_c5 <- predict(dt_c5, test, type = "prob")

pred_te_dt_c5 <- ifelse(pred_te_dt_c5 > 0.5, 1, 0) # yes, no
pred_te_dt_c5 <- pred_te_dt_c5[, 2]

ROC(pred_te_dt_c5, test$deposit)
confusionMatrix(table(test$deposit, pred_te_dt_c5), positive = "1")
```


### Improving model performance {-}
**Boosting the accuracy of decision trees (의사결정 트리의 정확도 향상)**

- C5.0 알고리즘이 C4.5 알고리즘을 개선한 방법 중 하나는 적응형 부스팅(AdaBoost)을 추가한 것이다. 이 방법은 **여러 개의 의사결정 트리를 만들어서 각 예시에 대해 최고 클래스를 투표하게 만드는 과정**이다.

- 부스팅은 성능이 약한 여러 학습자를 결헙함으로써 어느 한 학습자 **혼자보다 훨씬 강한 팀**을 만들 수 있다는 생각에 뿌리를 두고 있다. 각 모델은 각자의 유일한 강점과 약점을 찾으며, 특정 문제를 풀 때 더 좋거나 더 나쁠 수 있다. 그러므로 상호 보완적인 장점과 단점을 갖는 여러 학습자를 조합해 분류기의 정확도를 극적으로 향상시킬 수 있다.

- 부스팅 팀에 사용할 독립적인 의사결정 트리의 개수를 나타내는 **trials 파라미터**를 간단히 추가한다. trials 파라미터는 상한선을 설정한다. 추가 시행이 정확도를 향상시키지 못할 것으로 보이면 알고리즘은 더 이상 트리를 추가하지 않는다.

- 10회 시행으로 시작할 것인데, 연구에 따르면 **10회 시행 시 테스트 데이터에 대한 오류율이 약 25% 정도 줄기**때문에 이 숫자는 사실상 표준이 된 상태다.

```{r, message=F, warning=F, fig.height=6, fig.width=12}
## Improving model performance
## Boosting the accuracy of decision trees
# boosted decision tree with 10 trials
data_boost10 <- C5.0(as.factor(deposit)~., data = train, trials = 10)
data_boost10

summary(data_boost10)
```


    ## Evaluation on training data (8931 cases):
    ## 
    ## Trial        Decision Tree   
    ## -----      ----------------  
    ##    Size      Errors  
    ## 
    ##    0    205 1960(21.9%)
    ##    1     49 2401(26.9%)
    ##    2     84 2870(32.1%)
    ##    3     86 2478(27.7%)
    ##    4     67 3118(34.9%)
    ##    5     64 2809(31.5%)
    ##    6     88 3003(33.6%)
    ##    7    113 2298(25.7%)
    ##    8    123 2285(25.6%)
    ##    9     99 2231(25.0%)
    ## boost           1724(19.3%)   <<
    ## 
    ## 
    ##     (a)   (b)    <-classified as
    ##    ----  ----
    ##    4111   588    (a): class 1
    ##    1136  3096    (b): class 2 
 

10회의 반복을 통해 트리의 크기가 줄어들었다.

```{r, message=F, warning=F, fig.height=6, fig.width=12}
pred_boost10 <- predict(data_boost10, test, type = "prob")
pred_boost10 <- ifelse(pred_boost10 > 0.5, 1, 0) # yes, no
pred_boost10 <- pred_boost10[, 2]

ROC(pred_boost10, test$deposit)
confusionMatrix(table(test$deposit, pred_boost10), positive = "1")
```

### Improving Model Performance (성능 개선을 위한 모델 튜닝) {-}
**- Finding Tuning parameter**

    - 파라미터는 최대 p^3개의 후보 모델로 테스트를 진행한다.
      - Decision Tree의 튜닝은 model, trials, winoow 설정에 대해 12개의 조합의 그리드로 이뤄진 후보 모델을 비교한다.
        - 3^3 = 27개가 되어야 하지만, model과 winnow 파라미터가 두 개의 값(각각 tree, rules와 TRUE, FALSE)만 취할 수 있기 때문에
        - 그리드 크기는 3 * 2 * 2 = 12가 된다.
```{r, message=F, warning=F, fig.height=6, fig.width=12}
modelLookup("C5.0")
```


**- Creating a simple tuned model**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
# automated parameter tuning of C5.0 decision tree 
set.seed(1004) # 시뮬레이션할 때, 동일한 결과를 반복하기 위해 난수 고정

tune_m <- train(as.factor(deposit) ~ ., data = train, method = "C5.0")
# summary of tuning results
tune_m

# apply the best C5.0 candidate model to make predictions
p <- predict(tune_m, train)
table(p, train$deposit)

# obtain predicted classes (default: type = "raw", probabilities: type = "prob")
head(predict(tune_m, train))
```


```{r, message=F, warning=F, fig.height=6, fig.width=12}
pred_tr_tune <- predict(tune_m, train, type = "prob")
pred_tr_tune <- ifelse(pred_tr_tune > 0.5, 1, 0) # yes, no
pred_tr_tune <- pred_tr_tune[, 2]

ROC(pred_tr_tune, train$deposit)
confusionMatrix(table(train$deposit, pred_tr_tune), positive = "1")
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}
pred_te_tune <- predict(tune_m, test, type = "prob")
pred_te_tune <- ifelse(pred_te_tune > 0.5, 1, 0) # yes, no
pred_te_tune <- pred_te_tune[, 2]

ROC(pred_te_tune, test$deposit)
confusionMatrix(table(test$deposit, pred_te_tune), positive = "1")
```

**- Customizing the tuning process**

디폴트 설정을 사용하면 최적화된 모델을 쉽게 만들 수 있다. 하지만 디폴트 설정을 학습 작업에 좀 더 특화된 설정으로 변경하게 되면 성능을 높은 수준으로 올리는 데 도움이 된다. 파라미터를 최적화하기 위해 10-fold 교차검증(10-Fold C.V)를 이용해서 카파 통계량을 추정하고 반영할 것이다.

trainControl() 함수는 제어 객체로 알려진 설정 옵션 집합을 생성하기 위해 사용된다. 제어 객체는 train()함수를 이끈다. 이 옵션들을 통해 모델의 평가 기준을 관리할 수 있으며, 리샘플링 전략과 최고 모델을 선택하는 데 사용되는 척도 같은 것들이 해당된다. 이 함수는 튜닝 실험의 거의 모든 측면을 수정하는 데 사용할 수 있지만, 지금은 주요 파라미터인 method와 selectionFunction에 집중할 것이다.

trainControl() 함수의 경우 method parameter를 홀드아웃 샘플링 또는 k-fold 교차 검증과 같은 리샘플링 방법을 설정하는 데 사용할 수 있다.

selectionFunction 파라미터는 다양한 후보 중에 최적의 모델을 선택하는 함수를 지정하는데 사용한다. 그런 함수는 세 개가 있다. best 함수는 단순히 명시된 성능 척도에 대해 최고 값을 갖는 후보를 선택한다. 이 함수가 디폴트로 사용된다. 다른 두 함수는 최고 모델의 특정한 성능 임계치 내에 있는 가장 인색하거나 가장 단순한 모델을 선택하기 위해 사용된다. oneSE 함수는 최고 성능의 1표준 오차 내에 가장 단순한 후보를 선택하며, tolerance는 사용자 지정 비율 내에 가장 단순한 후보를 사용한다.

```{r, message=F, warning=F, fig.height=6, fig.width=12}
## use trainControl() to alter resampling strategy
## 10-fold Cross Validation과 oneSE 선택 함수를 사용해 ctrl이란 이름의 제어 객체를 생성
ctrl <- trainControl(method = "cv", number = 10,
                     selectionFunction = "oneSE")
```

최적화할 파라미터의 그리드 생성. 
그리드의 열은 희망하는 모델의 파라미터 이름으로 구성된다. 그리드의 행은 원하는 파라미터 값의 조합으로 구성된다.
지금은 C5.0 의사결정 트리를 사용하기 때문에 .model, .trials, .winnow라는 이름으로 열이 만들어진다.

```{r, message=F, warning=F, fig.height=6, fig.width=12}
# use expand.grid() to create grid of tuning parameters
# 상수 model = "tree"와 winnow = "FALSE"를 유지하면서 8 종류의 trials를 검색
grid <- expand.grid(.model = "tree",
                    .trials = c(1, 5, 10, 15, 20, 25, 30, 35),
                    .winnow = FALSE)

# look at the result of expand.grid()
grid
```

train() 함수는 각 행의 모델 파라미터 조합을 이용해서 평가를 위한 후보 모델을 구축할 것이다.

직전에 생성된 검색 그리드와 제어 리스트가 있으므로 train() 실험을 철저히 맞춤화해서 시행할 준비가 됐다. 
이전에 했던 것처럼 반복 가능한 결과를 보장하기 위해 시드를 임의의 값으로 설정한다. 
하지만 이번에는 파라미터 metric = “Kappa”를 추가하면서 제어 객체와 튜닝 그리드를 전달할 것이다. 
이 경우 모델 평가 함수(이 경우 “oneSE”)가 카파 통계량을 사용한다는 것을 말한다. 


```{r, message=F, warning=F, fig.height=6, fig.width=12}
# customize train() with the control list and grid of parameters 
set.seed(1004)
tune_m2 <- train(as.factor(deposit) ~ ., data = train, method = "C5.0",
           trControl = ctrl,
           tuneGrid = grid)
```

### Summary {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
tune_m2
```

- 출력의 대부분이 자동 튜닝 모델과 비슷하지만 몇 가지 눈에 띄는 차이점이 있다.
    - 10-fold cross validation이 사용되기 떄문에 후보 모델을 만들기 위한 샘플 크기는 부트스트랩에 사용된 8,931이 아닌 8,038으로 줄었다.
    - 요청했던 것처럼 8개의 후보 모델이 테스트됐다.
    - 또한 model과 winnow는 상수로 유지되고 있기 때문에 값이 더 이상 결과에 나타나지 않고 대신 각주에 나열됐다.
- 최고 모델 또한 이전의 시행과 차이를 보인다. 성능으로만 보면 최고 모델은 trials = 25을 선택해야하지만, 여기서는 trials = 20을 선택했다.  best 규칙이 아닌 oneSE 규칙을 사용했기에 선택된 것이다. Kappa에 따르면 25-trials model이 최고의 원시 성능을 제공하지만, 20-trials model은 단순한 형태로 비슷한 성능을 제공한다. 단순한 모델이 계산적으로 좀 더 효율적일 뿐 아니라 훈련 데이터에 과적합될 가능성을 줄여준다.

**- Accuracy was used to select the optimal model using  the one SE rule.**

||model|winnow|trials|Accuracy|Kappa|비고|
|--|--|--|--|--|--|--|
|1|rules|FALSE|20|0.8557756|0.7123245|이전에 시행했던 최고 성능 모델|
|2|tree|FALSE|20|0.8612698|0.7221875|성능을 개선한 모델 중 선택된 모형|
|3|tree|FALSE|25|0.8630603|0.7259894|성능을 개선한 모델 중 가장 성능이 좋은 모형|


## 5.6. Bagging {.tabset}
### Training a model on the data {-}
**- Training a model: **
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#m_bag <- bagging(as.factor(deposit) ~ ., data = train, nbagg = 25)

#pred_tr_bag <- predict(m_bag, train, type = "prob")
#pred_tr_bag <- ifelse(pred_tr_bag > 0.5, 1, 0) # yes, no
#pred_tr_bag <- pred_tr_bag[, 2]

#ROC(pred_tr_bag, train$deposit)
#confusionMatrix(table(train$deposit, pred_tr_bag), positive = "1")
```

### Evaluating model performance {-}
**- Evaluating model performance:**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#pred_te_bag <- predict(m_bag, test, type = "prob")
#pred_te_bag <- ifelse(pred_te_bag > 0.5, 1, 0) # yes, no
#pred_te_bag <- pred_te_bag[, 2]

#ROC(pred_te_bag, test$deposit)
#confusionMatrix(table(test$deposit, pred_te_bag), positive = "1")
```

### Cross Validation {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#set.seed(1004)
#ctrl <- trainControl(method = "cv", number = 10)
#train(as.factor(deposit)~., data = train, method = "treebag",
#      trControl = ctrl)
```

## 5.7. AdaBoost {.tabset}
### Training a model on the data {-}
**- Training a model:**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#set.seed(1004)

#m_ada <- boosting(as.factor(deposit) ~ ., data = train)
#p_ada <- predict(m_ada, train)
#p_ada$confusion

#pred_tr_ada <- predict(m_ada, train, type = "prob")
#pred_tr_ada <- ifelse(pred_tr_ada > 0.5, 1, 0) # yes, no
#pred_tr_ada <- pred_tr_ada[, 2]

#ROC(pred_tr_ada, train$deposit)
#confusionMatrix(table(train$deposit, pred_tr_ada), positive = "1")
```

### Evaluating model performance {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#pred_te_ada <- predict(m_ada, test, type = "prob")
#pred_te_ada <- ifelse(pred_te_ada > 0.5, 1, 0) # yes, no
#pred_te_ada <- pred_te_ada[, 2]

#ROC(pred_te_ada, test$deposit)
#confusionMatrix(table(test$deposit, pred_te_ada), positive = "1")
```

### Cross Validation {-}
`````{r, message=F, warning=F, fig.height=6, fig.width=12}
#set.seed(1004)
#cv_ada <- boosting.cv(as.factor(deposit) ~., data = train)
#cv_ada$confusion

#round((3980 + 3628) / (3980 + 3628 + 604 + 719), 2)
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}
#cv_ada <- boosting.cv(as.factor(deposit) ~., data = train)

#pred_cv_ada <- predict(cv_ada, train, type = "prob")
#pred_cv_ada <- ifelse(pred_cv_ada > 0.5, 1, 0) # yes, no
#pred_cv_ada <- pred_cv_ada[, 2]

#ROC(pred_cv_ada, train$deposit)
#confusionMatrix(table(train$deposit, pred_cv_ada), positive = "1")
```


```{r, message=F, warning=F, fig.height=6, fig.width=12}
#pred_cv_te_ada <- predict(cv_ada, test, type = "prob")
#pred_cv_te_ada <- ifelse(pred_cv_te_ada > 0.5, 1, 0) # yes, no
#pred_cv_te_ada <- pred_cv_te_ada[, 2]

#ROC(pred_cv_te_ada, test$deposit)
#confusionMatrix(table(test$deposit, pred_cv_te_ada), positive = "1")
```

## 5.8. Random Forest {.tabset}
### Training a model on the data {-}

**- Feature Selection: **
```{r, message=F, warning=F, fig.height=6, fig.width=12}
# extractFeatures <- function(data) {
#   features <- c("season",
#                 "holiday",
#                 "workingday",
#                 "weather",
#                 "temp",
#                 "atemp",
#                 "humidity",
#                 "windspeed",
#                 "hour",
#                 "weekday",
#                 "quarter",
#                 "month",
#                 "date"
#                 )
#   data$hour <- hour(ymd_hms(data$datetime))
#   return(data[,features])
# }

# trainFea <- extractFeatures(train)
# testFea  <- extractFeatures(test)
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}
#submission <- data.frame(datetime=test$datetime, count=NA)

# We only use past data to make predictions on the test set, 
# so we train a new model for each test set cutoff point
#for (i_year in unique(year(ymd_hms(test$datetime)))) {
#  for (i_month in unique(month(ymd_hms(test$datetime)))) {
#    cat("Year: ", i_year, "\tMonth: ", i_month, "\n")
#    testLocs   <- year(ymd_hms(test$datetime))==i_year & month(ymd_hms(test$datetime))==i_month
#    testSubset <- test[testLocs,]
#    trainLocs  <- ymd_hms(train$datetime) <= min(ymd_hms(testSubset$datetime))
#    rf <- randomForest(extractFeatures(train[trainLocs,]), train[trainLocs,"count"], ntree=100)
#    submission[testLocs, "count"] <- predict(rf, extractFeatures(testSubset))
#  }
#}

#write.csv(submission, file = "./1_random_forest_submission.csv", row.names=FALSE)
```

**- Train a model**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
# Train a model across all the training data and plot the variable importance
# tr_rf <- randomForest(train[,-17], train[,17], ntree=1000, importance=TRUE)
# te_rf <- randomForest(test[,-17], test[,17], ntree=1000, importance=TRUE)

rf <- randomForest(as.factor(deposit)~., data=train, ntree=3000, importance=TRUE)

imp <- importance(rf, type=1)
featureImportance <- data.frame(Feature=row.names(imp), Importance=imp[,1])

rf
```

### Evaluating model performance {-}
**- Train Accuracy: **
```{r, message=F, warning=F, fig.height=6, fig.width=12}
pred_tr_rf <- predict(rf, type = "class")
confusionMatrix(table(train$deposit, pred_tr_rf), positive = "1")
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}
pred_tr_rf <- predict(rf, train, type = "prob")
pred_tr_rf <- ifelse(pred_tr_rf > 0.5, 1, 0) # yes, no
pred_tr_rf <- pred_tr_rf[, 2]


ROC(pred_tr_rf, train$deposit)
confusionMatrix(table(train$deposit, pred_tr_rf), positive = "1")
```

**- Test Accuracy: **
```{r, message=F, warning=F, fig.height=6, fig.width=12}
pred_te_rf <- predict(rf, test, type = "class")
#confusionMatrix(test$deposit, pred_te_rf)
confusionMatrix(table(test$deposit, pred_te_rf), positive = "1")
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}
pred_te_rf <- predict(rf, test, type = "prob")
pred_te_rf <- ifelse(pred_te_rf > 0.5, 1, 0) # yes, no
pred_te_rf <- pred_te_rf[, 2]


ROC(pred_te_rf, test$deposit)
confusionMatrix(table(test$deposit, pred_te_rf), positive = "1")
```

### Cross Validation {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
ctrl <- trainControl(method = "cv", number = 10)

grid_rf <- expand.grid(.mtry = c(2, 4, 8, 16))

set.seed(1004)
m_rf <- train(as.factor(deposit) ~ ., data = train, method = "rf",
              trControl = ctrl, tuneGrid = grid_rf)

grid_c50 <- expand.grid(.model = "tree",
                        .trials = c(10, 20, 30, 40),
                        .winnow = 'FALSE')

set.seed(1004)
m_c50 <- train(as.factor(deposit) ~ ., data = train, method = "C5.0",
               trControl = ctrl, tuneGrid = grid_c50)


m_rf

m_c50
```

### Hyper Parameter Tuning {-}
```{r, message=F, warning=F, fig.height=6, fig.width=12}
x <- train[,1:16]
y <- train[,17]

# Create model with default paramters
control <- trainControl(method="repeatedcv", number=10, repeats=3)
seed <- 1004

metric <- "Accuracy"
set.seed(seed)
mtry <- sqrt(ncol(x))
tunegrid <- expand.grid(.mtry=mtry)

rf_default <- train(as.factor(deposit)~., data=train, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
print(rf_default)
```

**- Random Search:**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
# Random Search
#control <- trainControl(method="repeatedcv", number=10, repeats=3, search="random")
#set.seed(seed)
#mtry <- sqrt(ncol(x))
#rf_random <- train(as.factor(deposit)~., data=train, method="rf", metric=metric, tuneLength=15, trControl=control)
#print(rf_random)
#plot(rf_random)
```

**- Grid Search:**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
## Grid Search
#control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")

#set.seed(seed)
#tunegrid <- expand.grid(.mtry=c(1:15))
#rf_gridsearch <- train(as.factor(deposit)~., data=train, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)

#print(rf_gridsearch)
#plot(rf_gridsearch)
```

**- Algorithm Tune (tuneRF):**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
# Algorithm Tune (tuneRF)
#set.seed(seed)
#bestmtry <- tuneRF(x, y, stepFactor=1.5, improve=1e-5, ntree=500)
#print(bestmtry)
```

**- Manual Search:**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
## Manual Search
#control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
#tunegrid <- expand.grid(.mtry=c(sqrt(ncol(x))))

#modellist <- list()
#for (ntree in c(1000, 1500, 2000, 2500)) {
#    set.seed(seed)
#    fit <- train(as.factor(deposit)~., data=train, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control, ntree=ntree)
#    key <- toString(ntree)
#    modellist[[key]] <- fit
#}
## compare results
#results <- resamples(modellist)
#summary(results)
#dotplot(results)
```

**- Extend Caret:**
```{r, message=F, warning=F, fig.height=6, fig.width=12}
#customRF <- list(type = "Classification", library = "randomForest", loop = NULL)

#customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))

#customRF$grid <- function(x, y, len = NULL, search = "grid") {}

#customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
#  randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
#}

#customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
#   predict(modelFit, newdata)

#customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
#   predict(modelFit, newdata, type = "prob")

#customRF$sort <- function(x) x[order(x[,1]),]
#customRF$levels <- function(x) x$classes
```

```{r, message=F, warning=F, fig.height=6, fig.width=12}
## train model
#control <- trainControl(method="repeatedcv", number=10, repeats=3)
#tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(1000, 1500, 2000, 2500))
#set.seed(seed)

#custom <- train(as.factor(deposit)~., data=train, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
#summary(custom)
#plot(custom)
```


### Visualiztion : Feature Importance {-}
**- Feature Importance: **
```{r, message=F, warning=F, fig.height=6, fig.width=12}
featureImportance

varImpPlot(rf, scale=TRUE)

round(rf$importance, 3)

p <- ggplot(featureImportance, aes(x=reorder(Feature, Importance), y=Importance)) +
     geom_bar(stat="identity", fill="#53cfff") +
     coord_flip() + 
     theme_light(base_size=20) +
     xlab("Importance") +
     ylab("") + 
     ggtitle("Random Forest Feature Importance\n") +
     theme(plot.title=element_text(size=18))

p
```

