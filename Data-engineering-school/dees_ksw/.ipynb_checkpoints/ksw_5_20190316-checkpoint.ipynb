{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apache Spark MLib: computer 1대로 처리하기 어려운 대용량을 다루기 위해 나옴.\n",
    "- 요즘 ML은 컴퓨터 1대로 돌아가는 경향이 있다. 큰 회사들은 데이터가 당연히 넘어버린다.\n",
    "- data size를 줄여서 modeling을 한 다음에 spark로 대용량으로 처리할 수 있게끔 만든다든가 그렇게 처리함.\n",
    "\n",
    "\n",
    "- Transformations, Action: 실제 계산이 수행되지 않고, 액션이 수행될 때만 실제 계산이 수행된다.\n",
    "- Lineage : 작업이 실패해도 데이터 복구할 수 있게 계보를 갖고 있음\n",
    "- Lazy Execution : 액션이 수행되는 시점에 데이터를 읽어들여 계싼을 시작\n",
    "\n",
    "---\n",
    "# Socar Issue\n",
    "## 타다의 차량 배치 문제\n",
    "- 차량의 효율성 증대\n",
    "    - 수요 예측 : 사용자가 언제 어디에서 많이 부르는지를 예측해서 배치하기\n",
    "    - 어떤 이점이 있나? : 경제적인 낭비 줄이기\n",
    "        - 사람을 태우러 가는 시간에 돈을 받지 않기 때문에 길면 경제적인 낭비가 있다.\n",
    "        - 짧으면 경제적인 낭비가 없고, 고객에게는 고객 경험을 긍정적인 방향으로 증대시킬 수 있다.\n",
    "    \n",
    "- Simple Process\n",
    "    - 1. 수요 예측을 잘해야 한다.\n",
    "        - 과거 데이터 기반 학습\n",
    "    - 2. 예측된 수요에 맞게 차량 배치를 잘 해야 한다.\n",
    "- [kepler](http://kepler.gl)\n",
    "    - 현재 어떤 상태에 있는 차가 어떠한지 알 수 있음\n",
    "    - 수요가 어디에서 일어나는지 알 수 있음\n",
    "    - (시각화를 통해) 수요가 많은데 왜 차가 적게 들어와 있지? -> 현재 알고리즘을 분석해서 고치기 ... 효율이 올라가서 돈을 범\n",
    "    - 타다의 연 매출 : 1,500억원.\n",
    "    - 올 한 해, 운행 효율 10% 올리기(150억원) ... 타다팀이 4명인데 150억 정도 만들 수 있으면 훌륭하다! ... 그래서 데이터 분야가 유망하다.\n",
    "    \n",
    "    - 효율성 증대 외에도 다른 일도 많이 할 수 있기 때문에, 가치 창출이 더 크다.\n",
    "\n",
    "---\n",
    "### tar\n",
    "```\n",
    "# 압축 해제\n",
    "- tar --help\n",
    "- -xf : Extract \n",
    "- -v Verbose : log\n",
    "- 명령어 : tar -xvf spark-2.4.0-bin-hadoop2.7\n",
    "\n",
    "---\n",
    "\n",
    "- pwd : present working directory\n",
    "- bin : binary\n",
    "\n",
    "- ./pyspark : 실행\n",
    "- ./ : 현재 디렉토리\n",
    "- ../ : 상위 디렉토리\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "https://stackoverflow.com/questions/30518362/how-do-i-set-the-drivers-python-version-in-spark\n",
    "\n",
    "```Python\n",
    "# terminal\n",
    "which python\n",
    "\n",
    "export PYSPARK_PYTHON=/Library/Frameworks/Python.framework/Versions/3.6/bin/python3\n",
    "\n",
    "env\n",
    "\n",
    "cd Downloads\n",
    "cd spark-2.4.0-bin-hadoop2.7\n",
    "\n",
    "./pyspark\n",
    "\n",
    "# pyspark\n",
    "text = sc.textFile(\"README.md\")\n",
    "text.first() # 에러 메시지 출력됨\n",
    "\n",
    "# 에러 메시지\n",
    "err msg : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/Users/mac/Downloads/spark-2.4.0-bin-hadoop2.7/bin/README.md\n",
    "\n",
    "# flapMap을 활용해 문장을 단어로 분리하기\n",
    "text = sc.textFile(\"../README.md\")\n",
    "text.first()\n",
    "text.take(3)\n",
    "\n",
    "text.map(lambda s:s.split(' ')).take(3)\n",
    "words = text.flatMap(lambda s:s.split(' '))\n",
    "words.take(10)\n",
    "\n",
    "# mapreduce\n",
    "words.map(lambda w: (w, 1)) # reduce하려면 key, value 형식으로 만들어 놓고, 정해진 형식으로 합치는 operation하기 위해 규칙을 맞춤.\n",
    "words.map(lambda w: (w, 1)).take(10) # key, value 이런 식으로 맞추어짐\n",
    "wordscount = words.map(lambda w: (w, 1)).reduceByKey(lambda a,b: a+b) # key로 묶은 다음에 value부분에 대해서 reduce 함수를 사용(여기에서는 더하기)\n",
    "\n",
    "wordscount.sortBy(lambda x:x[0]).take(10) # key : 알파벳순\n",
    "wordscount.sortBy(lambda x:x[1], False).take(10) # value : 빈도 역순\n",
    "```\n",
    "\n",
    "## Scala와 Python의 차이\n",
    "- [Example 1](http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html)\n",
    "```Python\n",
    "val z = sc.parallelize(List(1,2,3,4,5,6), 2) # Scala\n",
    "z = sc.parallelize(List(1,2,3,4,5,6), 2) # python\n",
    "# 2번째 인자의 '2'는 뭘까?\n",
    "```\n",
    "\n",
    "### Q. 2번째 인자의 '2'는 뭘까?\n",
    "- 핵심 역량 : 직접 소스코드 보고 분석하기\n",
    "    - [1. Spark Documents](https://spark.apache.org/docs/latest/rdd-programming-guide.html#parallelized-collections)\n",
    "    - [2. API Docs : Scala](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.package)\n",
    "    - [3. API Docs : Python](https://spark.apache.org/docs/latest/api/python/index.html)\n",
    "\n",
    "```Python\n",
    "# Scala              \n",
    "val a = sc.parallelize(List(\"dog\", \"tiger\", \"lion\", \"cat\", \"panther\", \"eagle\"), 2)\n",
    "val b = a.map(x => (x.length, x))\n",
    "b.reduceByKey(_+_).collect\n",
    "              \n",
    "# Python\n",
    "a = sc.parallelize(List(\"dog\", \"cat\", \"owl\", \"gnu\", \"ant\"), 2)\n",
    "b = a.map(lambda x: (len(x))\n",
    "b.reduceByKey(lambda a,b: a+b).collect()\n",
    "```\n",
    "\n",
    "## Spark 실습 - Narrow & Wide Dependency\n",
    "p. 148\n",
    "```Python\n",
    "# Narrow dependency - 효율적으로 처리하는 Operation\n",
    "a = sc.parallelize(range(1, 10000000)).map(lambda x: (x,x))\n",
    "a.filter(lambda x: x[1] < 100).count()\n",
    "\n",
    "# Wide dependency - 속도가 느려지는 Operation\n",
    "a = sc.parallelize(range(1, 10000000)).map(lambda x: (x,x))\n",
    "b = sc.parallelize(range(1, 10000)).map(lambda x: (x,x))\n",
    "a.join(b).count()\n",
    "\n",
    "# Join with partition (Narrow dependency)\n",
    "from pyspark.rdd import portable_hash\n",
    "p = portable_hash(10)\n",
    "a = sc.parallelize(range(1, 10000000)).map(lambda x: (x,x)).partitionBy(p)\n",
    "b = sc.parallelize(range(1, 1000)).map(lambda x: (x,x)).partitionBy(p)\n",
    "a.join(b).count()\n",
    "```\n",
    "\n",
    "## Spark 실습 - Caching\n",
    "p. 149\n",
    "```Python\n",
    "a = sc.parallelize(range(1, 1000000000)) // 큰 RDD 정의 a.count() // 시간이 어느정도 걸림\n",
    "b = a.filter(lambda x: x < 100000) // 필터링된 작은 RDD 정 의\n",
    "b.count() // 연산 시간이 꽤 걸림\n",
    "b.count() // 다시 해봐도 연산 시간이 꽤 걸림 b.persist() // 캐싱\n",
    "b.count() // 연산을 다시 하면서, 결과를 캐싱 함 b.count() // 순식간에 수행됨\n",
    "```\n",
    "\n",
    "## Spark SQL & DataFrame\n",
    "p.152\n",
    "### SQL을 원하는 이유\n",
    "- 익숙한 언어인 SQL로 데이터를 분석하고 싶다\n",
    "- 예전에 짜놓은 SQL 분석 코드들을 재활용하고싶다\n",
    "- 맵리듀스 프로그래밍보다 SQL이 빠르고 편하다\n",
    "- 정형화된 데이터의 경우 정형화된 방법으로 분석하면 더 높은 수준의 최적화를 구현할 수 있다.\n",
    "\n",
    "- 해야할 일이 정형적일 수록(자유도가 떨어질 수록) 성능을 올릴 여지가 많아진다.\n",
    "- 자유도가 높으면 미리 어떻게 세팅을 할 지 예측할 수 없어서 성능을 올릴 여지가 적다.\n",
    "\n",
    "### Hive\n",
    "- SQL을 작성하면 MapReduce로 컨버팅\n",
    "- 오버헤드가 크기때문에 응답이 느리고 사용하기 답답하다.\n",
    "- SQL 코드를 MR 코드로 변환 -> 맵리듀스 작업을 jar로 패키징 -> 하둡 클러스터에 전송 -> 압축 해제 및 실행...\n",
    "- 아무리 복잡한 쿼리라도 안정적으로 돌아가는것은 큰 장점\n",
    "    - 며칠, 몇주가 걸릴 수도 있다는것은 문제\n",
    "- 아직까지도 많이 쓰이고 있음\n",
    "- 느린 속도를 개선하기 위해 Presto, Spark SQL 같은 경쟁 프로젝트 들이 나옴\n",
    "\n",
    "\n",
    "### Spark SQL\n",
    "- Spark의 뛰어난 엔진을 이용하여 응답속도와 처리속도를 개선\n",
    "- 처음에는 Shark 프로젝트 - Spark SQL로 이름이 바뀜\n",
    "- Spark 2.0은 Spark SQL을 위한 업데이트\n",
    "    - Spark SQL 관련 많은 부분이 바뀌고 많은 개선이 이루어짐\n",
    "    - DataFrame, DataSet API\n",
    "    - 더 많은 쿼리와 파일포맷 지원 강화\n",
    "- 현재는 Low-level API인 RDD와 공존, 앞으로는 DataSet API 쪽으 로 무게가 실릴 가능성 높음\n",
    "- 머신러닝은 정형화된 데이터셋을 주로 다루므로 DataFrame API로 다시 쓰여짐\n",
    "\n",
    "### Spark DataSet, DataFrame API\n",
    "- Spark SQL 등에서 사용하기 위해 구조화된 형태의 데이터가 필요\n",
    "    - 여러 언어에서도 동일하게 사용 가능\n",
    "- Dataset[Row] = DataFrame\n",
    "- Json파일 등에서 자동으로 스키마를 읽어들여 DataFrame을 만들수 있고, 직접 스키마를 만들수도 있음\n",
    "- RDD를 DS, DF로 변환 가능\n",
    "- MLlib 에서도 구조화된 데이터를 다루며, 언어별 통일성 등의 장점을 취하기 위해 DataFrame을 사용\n",
    "\n",
    "---\n",
    "\n",
    "- SparkContext vs SparkSession\n",
    "\n",
    "        sc.textFile(\"...\")\n",
    "        spark.read.csv(\"...\")\n",
    "    \n",
    "- Schema\n",
    "\n",
    "        df.printSchema()\n",
    "        df.show()\n",
    "        \n",
    "- Transformations\n",
    "\n",
    "        df.select(), filter(), groupBy()..\n",
    "- SQL\n",
    "\n",
    "        df.createOrReplaceTempView(\"table_name\")\n",
    "        spark.sql(\"SELECT * FROM table_name\").show()\n",
    "\n",
    "----\n",
    "### 왕좌의 게임\n",
    "\n",
    "```Python\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"/Users/mac/Downloads/game-of-thrones/character-deaths.csv\")\n",
    "df.show()\n",
    "df.count()\n",
    "df.filter(df['Death Year'].isNull()).count()\n",
    "\n",
    "condition = df['Death Year'].isNull()\n",
    "df.where(condition).count()\n",
    "df.select(\"Name\").show()\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "df.select(length(\"Name\")).show()\n",
    "\n",
    "column = df['Death Year']\n",
    "column.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Allegiances</th>\n",
       "      <th>Death Year</th>\n",
       "      <th>Book of Death</th>\n",
       "      <th>Death Chapter</th>\n",
       "      <th>Book Intro Chapter</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nobility</th>\n",
       "      <th>GoT</th>\n",
       "      <th>CoK</th>\n",
       "      <th>SoS</th>\n",
       "      <th>FfC</th>\n",
       "      <th>DwD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addam Marbrand</td>\n",
       "      <td>Lannister</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aegon Frey (Jinglebell)</td>\n",
       "      <td>None</td>\n",
       "      <td>299.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aegon Targaryen</td>\n",
       "      <td>House Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adrack Humble</td>\n",
       "      <td>House Greyjoy</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aemon Costayne</td>\n",
       "      <td>Lannister</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name      Allegiances  Death Year  Book of Death  \\\n",
       "0           Addam Marbrand        Lannister         NaN            NaN   \n",
       "1  Aegon Frey (Jinglebell)             None       299.0            3.0   \n",
       "2          Aegon Targaryen  House Targaryen         NaN            NaN   \n",
       "3            Adrack Humble    House Greyjoy       300.0            5.0   \n",
       "4           Aemon Costayne        Lannister         NaN            NaN   \n",
       "\n",
       "   Death Chapter  Book Intro Chapter  Gender  Nobility  GoT  CoK  SoS  FfC  \\\n",
       "0            NaN                56.0       1         1    1    1    1    1   \n",
       "1           51.0                49.0       1         1    0    0    1    0   \n",
       "2            NaN                 5.0       1         1    0    0    0    0   \n",
       "3           20.0                20.0       1         1    0    0    0    0   \n",
       "4            NaN                 NaN       1         1    0    0    1    0   \n",
       "\n",
       "   DwD  \n",
       "0    0  \n",
       "1    0  \n",
       "2    1  \n",
       "3    1  \n",
       "4    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../Downloads/game-of-thrones/character-deaths.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nobility : 귀족 여부\n",
    "- GoT : 책 1권에 나왔는지 여부\n",
    "- CoK : 책 2권에 나왔는지 여부\n",
    "- SoS : 책 3권에 나왔는지 여부\n",
    "- FfC : 책 4권에 나왔는지 여부\n",
    "- DwD : 책 5권에 나왔는지 여부\n",
    "---\n",
    "#### Q1. 몇 명의 주인공이 죽고 살았는지?\n",
    "- Death Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  917\n",
       "Allegiances           917\n",
       "Death Year            305\n",
       "Book of Death         307\n",
       "Death Chapter         299\n",
       "Book Intro Chapter    905\n",
       "Gender                917\n",
       "Nobility              917\n",
       "GoT                   917\n",
       "CoK                   917\n",
       "SoS                   917\n",
       "FfC                   917\n",
       "DwD                   917\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "917\n",
      "305\n",
      "612\n"
     ]
    }
   ],
   "source": [
    "print(df['Death Year'].isnull().count())\n",
    "print(df['Death Year'].count())\n",
    "print(df['Death Year'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                  612\n",
      "Allegiances           612\n",
      "Death Year              0\n",
      "Book of Death           2\n",
      "Death Chapter           4\n",
      "Book Intro Chapter    605\n",
      "Gender                612\n",
      "Nobility              612\n",
      "GoT                   612\n",
      "CoK                   612\n",
      "SoS                   612\n",
      "FfC                   612\n",
      "DwD                   612\n",
      "dtype: int64\n",
      "Death Year                0.0\n",
      "Book of Death             7.0\n",
      "Death Chapter           122.0\n",
      "Book Intro Chapter    17322.0\n",
      "Gender                  491.0\n",
      "Nobility                312.0\n",
      "GoT                     142.0\n",
      "CoK                     192.0\n",
      "SoS                     257.0\n",
      "FfC                     219.0\n",
      "DwD                     208.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "condition = df['Death Year'].isnull()\n",
    "print(df.where(condition).count())\n",
    "print(df.where(condition).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.select of 0                         Addam Marbrand\n",
       "1                Aegon Frey (Jinglebell)\n",
       "2                        Aegon Targaryen\n",
       "3                          Adrack Humble\n",
       "4                         Aemon Costayne\n",
       "5                        Aemon Estermont\n",
       "6      Aemon Targaryen (son of Maekar I)\n",
       "7                             Aenys Frey\n",
       "8                          Aeron Greyjoy\n",
       "9                                 Aethan\n",
       "10                                 Aggar\n",
       "11                                  Aggo\n",
       "12                         Alan of Rosby\n",
       "13                               Alayaya\n",
       "14                           Albar Royce\n",
       "15                                Albett\n",
       "16                              Alebelly\n",
       "17                      Alerie Hightower\n",
       "18                    Alesander Staedmon\n",
       "19                       Alester Florent\n",
       "20                       Alia of Braavos\n",
       "21                           Alla Tyrell\n",
       "22                       Allard Seaworth\n",
       "23                        Alliser Thorne\n",
       "24                                  Alyn\n",
       "25                          Alyn Ambrose\n",
       "26                        Alyn Estermont\n",
       "27                       Alyn Stackspear\n",
       "28                         Alys Karstark\n",
       "29                       Alysane Mormont\n",
       "                     ...                \n",
       "887                               Willit\n",
       "888                     Willow Witch-eye\n",
       "889                               Willum\n",
       "890                                 Woth\n",
       "891                                Wulfe\n",
       "892                  Wun Weg Wun Dar Wun\n",
       "893                          Wyl (guard)\n",
       "894                     Wyl the Whittler\n",
       "895                       Wylis Manderly\n",
       "896                       Wylla Manderly\n",
       "897                       Wyman Manderly\n",
       "898                    Wynafryd Manderly\n",
       "899                         Wynton Stout\n",
       "900                     Xaro Xhoan Daxos\n",
       "901                               Xhondo\n",
       "902                               Yandry\n",
       "903                          Yellow Dick\n",
       "904                         Ygon Farwynd\n",
       "905                              Ygritte\n",
       "906                         Yohn Farwynd\n",
       "907                           Yohn Royce\n",
       "908                                Yoren\n",
       "909                          Young Henly\n",
       "910                               Ysilla\n",
       "911                                  Zei\n",
       "912                                Zollo\n",
       "913                    Yurkhaz zo Yunzak\n",
       "914                     Yezzan Zo Qaggaz\n",
       "915                     Torwynd the Tame\n",
       "916                        Talbert Serry\n",
       "Name: Name, Length: 917, dtype: object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'].select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
