# Statistics for Data Analytics

<img align = "center" src = "https://yourlistingexpert.com/wp-content/uploads/2018/01/seo-statistics-1170x659.jpg">

[![HitCount](http://hits.dwyl.io/boys-be-ambitious//Statistics.svg)](http://hits.dwyl.io/boys-be-ambitious//Statistics)


## Index
## 1. 데이터 분석에 앞서
    1.1. 분석의 목적
    1.2. 요구 조건 정의
    1.3. 신호와 소음
    1.4. 데이터 예측, 맛보기

## 2. 통계의 기초
    2.1. 평균과 표준편차
        2.1.1. 대표값
        2.1.2. 모집단과 표본
        2.1.3. Random Sampling
        
    2.2. 기술통계 추론통계
        2.2.1. 기술통계
        2.2.2. 추론통계
        
    2.3. EDA
        2.3.1. Visualization
        2.3.2. 중심극한정리

    2.4. 점추정과 구간추정
        2.4.1. 점추정
        2.4.2. 구간추정
        
    2.5. Outlier (이상치)
    
    2.6. Missing Valiue (결측치)
    
    
## 3. 분석의 종류

    3.1. '차이'를 보는 분석
        3.1.1. T-test
        3.1.2. Anova

    3.2. '관계'를 보는 분석
        3.2.1. Regression
        
    3.3. '연관'을 보는 분석
        3.3.1. 독립성 검정
        3.3.2. 연관성 분석
        
## 4. 가설검정
    4.1. Hyprothesis
    
    4.2. 1종 오류와 2종 오류
    
    4.3. 유의수준/유의확률
    
    4.4. 가설검정 (0가설검정)
    
    4.5. 우리가 이렇게 삽질하는 이유
    
    4.6. 정리
    
    4.7. 퀴즈
    
    
## 5. 집단간 차이 검증하기 (Z, T, F)
    5.1. 표준화와 Z분포
        5.1. 표준화 (Standardization)
        5.2. Z분포
        5.3. 신뢰구간
        
    5.2. T분포
    
    5.3. F검정


## 6. 상관과 회귀
    6.1. 데이터의 유사성은 어떻게 따지는가?
    6.2. 예측은 어떻게 하는가?

## 7. 변수척도
    7.1. Discrete
        7.1.1. 명목형 변수
        7.1.2. 순서형 변수
        
    7.2. Continuous
        7.2.1. 연속형 변수
        
    7.3. 요리와 데이터
    7.4. Trade-Off
    7.5. Random Variable (확률변수)
    

## 8. 기본 제약 과정
    8.1. 목적
    8.2. 세 가지의 기본 원칙
        8.1.1 정규성
        8.1.2. 등분산성
        8.1.3. 독립성
        
## 9. 분포
    9.1. Z분포
    9.2. T분포
    9.3. F검증
    9.4. 이산형 확률분포
    9.5. 연속형 확률분포
    9.6. 지수분포


## 10. 정규화와 표준화

## 11. 변환의 사다리

## 12. 모수적 방법론과 비모수적 방법론
    12.1. 모수적 방법론(Parametric Method)
    12.2. 비모수적 방법론 (Non-Parametric Method)

## 13. MSE

## 14. 수집에서의 '적합성', 분석에서의 '타당성'


## 15. 기계학습(Machine Learning)
    15.1. 머신러닝 정의
    
    15.2. 머신러닝 분류
        15.2.1 Label 유무에 따른 분류
            - 지도학습
            - 비지도학습
            
        15.2.2 강화학습

    15.3. 머신러닝 알고리즘
        15.3.1 Regression(회귀)

            15.3.1.1 Linear Regression (선형 회귀)
                15.3.1.1.1 단순 선형 회귀 (Simple Linear Regression)
                
                15.3.1.1.2. 다중 선형 회귀 (Multiple Linear Regression)
                    15.3.1.1.2.1. 다중공선성(Multicollinearity)
                    15.3.1.1.2.2. 회귀 모형의 타당성
                    15.3.1.1.2.3. Subset Selection (변수 선택법)
                    15.3.1.1.2.4. 변수 중요도


            15.3.1.2 Shrinkage Method
                15.3.1.2.1. Ridge Regression
                15.3.1.2.2. Lasso Regression

            15.3.1.3. k-NN (k-Nearest Neighbors)

            15.3.1.4. Regression Tree

            15.3.1.5. ANN (Artificial Neural Network)

            15.3.1.6. SVM (Support Vector Machine)


        15.3.2. Classification (분류)
            15.3.2.1. k-NN (k-Nearest Neighbors)
            15.3.2.2. Decision Tree
            15.3.2.3. ANN (Artificial Neural Network)
            15.3.2.4. SVM (Support Vector Machine)       
            15.3.2.5. Losistic Regerssion

        15.3.3. Ensemble

- - -

# Contents
## 1. 데이터 분석에 앞서
### 1.1. 분석의 목적
    비즈니스적인 관점에서 보면 조직의 목표를 효율적(최소비용 최대효과, 선택과 집중)으로 달성하기 위해 데이터 분석을 한다.
    즉, '이익(Profit)'을 위해서 분석을 한다. 조금 더 상세한 내용은 아래와 같다.

    - 1) 매출 증대
        - 규모의 경제 (시장의 파이는 한정되어 있고, 경쟁자는 많기)때문에 매출 증대에는 한계가 있다.
    
    - 2) 비용 감소
        - 인건비, 재료비, 마케팅 비용 등 회사에서 나가는 모든 비용을 효율적으로 관리할 수 있다
        
### 1.2. 분석 전에 생각해봐야 할 것들
    - 1) 분석의 목적
    - 2) 요구 조건 정의
        - 통계와 분석에 대한 이해가 낮은 상사는 목표를 추상적으로 던져주는 경우가 많다(난감 그 자체).
        - 이해관계자와 커뮤니케이션을 통해 구체적으로 쪼개고 쪼개서 요구 조건(KPI)을 상세하게 정의한다(눈물이...).
    
### 1.3. 신호와 소음
    - Garbage in garbage out.
        - 품질이 좋지 않은 (input)데이터로 분석을 하면, 분석 결과(output)의 질이 좋지 않다.
        - '노이즈'를 제거해야 한다(데이터 정합성).
            - Noise : Outlier(이상치), Missing value(결측치), Dupliceted values(중복값)

### 1.4. (예측 프로세스) 맛보기 - 분류 알고리즘을 머릿 속으로 만들어 보기
#### 1.4.1. 개와 고양이 구분하기
    - 가정
        - 1. 개와 고양이 사진이 500장씩 있다.
        - 2. 어린 아이는 틀렸다와 맞았는 걸 알고 있다.
        - 3. 틀린 횟수를 줄이려고 끊잆없이 노력한다.

    - 이러한 문제는 이진 분류(남/녀, 개/고양이)의 대표적인 케이스이다.
    - 기존에는 규칙을 기반으로 feature를 넣었다. 허나 이러한 접근 방법은 문제가 많다(경우의 수가 무한대이기 때문에, 인간의 손으로 발전 시키기엔 한계가 존재).
    
    - 해결 방안
        - 1. 활용하는 알고리즘에 따라 data를 2~3등분(train/test or train/validation/test) 한다.
            - 3등분할 경우의 비율 : 60:20:20, 50:25:25
            - 2등분할 경우의 비율 : 70:30, 80:20, 90:10
            
        - 2. Training
            - 피드백을 준다.
            
        - 3. Validation
            - 피드백을 준다.
            
        - 4. Test
            - 피드백을 주지 않는다.
            
    - 주의할 점
        - 분류하려는 label 데이터의 비율을 맞춰야 한다.
            - 1,000장의 사진으로 학습한다면 고양이 500장, 개 500장으로 맞춰줘야 한다.
            - 학습하는 데이터의 양이 드라마틱하게 차이난다면, 알고리즘에서 내리는 정답은 극단 값으로 갈 수밖에 없다.
                - ex) 구글의 이미지 인식 프로그램이 '흑인' 사진을 보고, '고릴라'로 분류한 게 대표적인 케이스
                

#### 1.4.2. 영상 추천하기
    - 가정
        - 1. 영상 URL, 각 사용자들이 특정 영상을 조회한 횟수, 조회를 한 시점(시각), 사용자 기본 정보(id, 성별, 나이)
        - 2. 성능: 속도, 비용 무제한 -> 오로지 '정확도 높은 추천'에 관심

    - 추천 알고리즘
        - 1. CF
            - Item-based
            - User-based
                - 사용자 기반 Matrix
                - 패턴 : 영상을 본 순서 (본 순서대로 사용자의 패턴을 정의하고 추천)
                - 장점 : 아이템 속성의 한계를 뛰어 넘었다.
                - 예) 철수가 0 -> 3 -> 4를 보았는데, 영희가 0 -> 3을 보았다면, 그 다음의 영상으로 4번을 추천함
                - 단점 : Cost가 많이 든다.

            - 2. Contents-based
                - 단점
                    - Item(Contents) 속성의 한계에서 벗어날 수 없다.
                    - 즉, 소비한 콘텐츠의 한계에서 벗언라 수 없다.
                    
    - Cold start
        - 선호에 대한 정보가 없는 경우
            - 방법이 없다. 그렇기 때문에 Facebook에서 개인 정보 수집에 열을 올리는 것이다.
            - Watcha나 Netflix도 처음 가입한 사람에게 선호도를 물어본다.
            - 순서대로 한 사람씩 매치한다.
        
    - 우리 주변에서 볼 수 있는 인공지능
        - 페이스북의 친구 추천
        - 월마트 맥주와 기저귀 사례(장바구니 분석)
            - 금요일 저녁, 부인이 남편한테 기저귀 부탁 + 남편이 맥주를 사지 않았을까 하는 추측
        - 넷플릭스 영화 추천
        - 유투브 영상 추천
- [CF Algorithm](http://khanrc.tistory.com/entry/%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9CRecommendation-System)


## 2. 통계의 기초
### 2.1. 평균과 표준편차
#### 2.1.1. 대표값
    - 평균값(Mean), 중앙값(Median), 최빈값(Mode)
    - 최소값, 최대값
    
#### 2.1.2. 모집단과 표본
    - 모집단(Population)
        - 우리가 알고 싶은 것, 허나 모집단은 (현실적으로) 측정할 수 없다.

- 모평균 : <img src="http://latex.codecogs.com/svg.latex?\mu" border="0"/>
- 모표준편차 : <img src="http://latex.codecogs.com/svg.latex?\sigma^2" border="0"/>
- 표준편차 : <img src="http://latex.codecogs.com/svg.latex?\sigma" border="0"/>,
<img 
src="http://latex.codecogs.com/svg.latex?\sqrt{\sigma^2}" border="0"/>

    - 표본 (Sample)
        - 그래서 Samplig(표본 추출)하는 것이다.
        - 고려할 수 있는 부분(성별, 지역, 연령 등)을 다 고려해서 Random Sampling(무작위 추출)을 해야한다.
        - Bias(편향)를 고려하고 Sampling해야 한다. Bias된 데이터는 오염되었다.
        - 허나, 100% 완벽한 통계는 없다.

- 표본 평균 : <img src="http://latex.codecogs.com/svg.latex?\overline{x} " border="0"/>


- 표본 분산 : <img src="http://latex.codecogs.com/svg.latex?s^2" border="0"/>

- 표본 표준 편차 : <img src="http://latex.codecogs.com/svg.latex?s" border="0"/>, <img src="http://latex.codecogs.com/svg.latex?\sqrt{s^2}" border="0"/>

### 2.2. 기술통계와 추론통계
#### 2.2.1. 기술통계
    - 공식으로 나올 수 있는 통계
    - 모집단을 알고 있을 경우

#### 2.2.2. 추론통계
    - 표본으로 모집단을 추론

### 2.3. EDA(탐색적 데이터 분석, Exploratory Data Analysis)
    - 목적
        - 현황 파악(분석)을 하기 위해 진행한다.

    - 기술 통계
        - 평균, 중앙값, 최빈값, 최소값, 최대값, 편차, 분산, 표준편차가 있다.
#### 2.3.1. Visualization
    - 데이터가 분포된 모양을 파악하고 결정
        - Boxplot, Scatter Plot, Histogram, Barplot

#### 2.3.2. 중심극한정리
    - 표본의 수가 충분히 많으면 모든 확률 분포는 정규분포에 수렴하며, 평균은 실제 평균에 점점 가까워진다.
        - 그래서 (질 좋은)'Big' data가 중요하다.
    - 통계에서는 정규분포를 따른다고 가정하고 문제를 푼다.
    
<img src="https://t1.daumcdn.net/cfile/tistory/26096850584796AC02">

- 출처 : [나부랭이 수학 블로그](http://math7.tistory.com/16)

### 2.4. 점추정과 구간추정
    - 추정에는 두 가지 방법이 있다.
    
#### 2.4.1. 점추정
    - point to point(표본 <-> 모집단)
    - 표본에서 얻은 값을 모집단 값이라고 추정한다.
    
#### 2.4.2. 구간추정
    - 점추정을 기반으로 한다.
    - 평균이 어떠한 구간 사이에 있다고 추정한다.

<img src="https://t1.daumcdn.net/cfile/tistory/2265A54B54CB52C50B">

- 이미지 출처 : [나부랭이 수학 블로그](http://math7.tistory.com/120)

### 2.5. Outlier (이상치)
    - Boxplot을 통해 살펴본다.
    - 이상치를 포함하여 분석할 경우 결과를 왜곡하기 때문에 처리 후에 분석한다.
    
    - 이상치 처리 방법
        - A. 정상 범위를 넘어가는 이상치를 결측 처리 후 제거 후 분석
        - B. 정상 범위를 넘어가는 이상치를 최소/최대값으로 변환 후 분석 

    - 처리 기준

|종류|예시|해결 방법|
|---|---|---|
|존재할 수 없는 값|성별 변수에 3|결측처리|
|극단적인 값|몸무게 변수에 200|정상 범위 기준 정해서 결측 처리|
    

    - 정상범위 기준
        - 1Q - (1.5 * IQR) ~ 3Q + (1.5 * IQR)

            
    - 고민
        - (실수로 입력된 이상치는 제거하는 게 맞지만 그게 아닌) 이상치는 이상치가 아닐 수 있다.
        
            - 현실은 이상치에 주목하는데 그걸 날려버릴 필요가 있을까?
            - 통계분석을 하지 않는 이상 굳이 할 필요가 있을까?
            - Logistic Regression을 시행할 때는 필요
             
    
### 2.6. Missing value (결측치)
    - 언어별 분석 방법
        - Python
            - missing no : 결측치를 시각화해서 보여주는 라이브러리
            - data.isnull().sum() : 결측치를 계산해서 보여주는 함수
        - R
            - VIM : 결측치를 시각화해서 보여주는 라이브러리
            - colSums(is.na(data)) : 결측치를 계산해서 보여주는 함수
            
    - 해결 방안
        - 1) Deletion (삭제)
            - 결측치가 들어간 Row(데이터) 제거
            - 60% 이상의 결측치가 존재한다면 해당 Column(변수) 제거

        - 2) Imputation (대체)
            - a) knnout
            - b) 대표값
                - 최빈값
                - 평균값


## 3. 분석의 종류
### 3.1. '차이'를 보는 분석
#### 3.1.1. T-test
    - 두 집단의 (평균) 차이 비교

#### 3.1.2. Anova
    - 두 집단 이상의 그룹에 대한 (분산)차이 비교

### 3.2. '관계'를 보는 분석
#### 3.2.1. Regression (회귀)
    - 예측

### 3.3. '연관'을 보는 분석
#### 3.3.1. 독립성 검정
    - ex) 지방선거 : 명목형 변수(지역, 성별)끼리 연관이 있는지 확인
    
#### 3.3.2. 연관성 분석
    - Correlation Analysis
        - 변수들끼리의 상관관계가 있는지 분석
    - ex) Correlation Matrix, Association Analysis(연관성 분석, 장바구니 분석)


## 4. 가설검정
### 4.1. Hypothesis
    - 귀무가설 (Null Hypothesis, H0)
        - 기존에 연구나 조사가 되어진 사실, 알려진 사실
        - key point : 같은가?(의미x)
        
    - 대립가설 (Alternative Hypothesis, H1)
        - 연구자가 새롭게 주장하고 싶은 가설, 알고 싶은 것
        - key point : 다른가?(의미0)


### 4.2. [1종 오류와 2종 오류](https://m.blog.naver.com/PostView.nhn?blogId=hjs8419&logNo=220671013205&proxyReferer=https%3A%2F%2Fwww.google.co.kr%2F)

- - -

|||차이|영향력|연관성|효과|
|---|---|---|---|
|${H_0}$||X|X|X|X|
|${H_1}$||O|O|O|O|

|사실 / 결정|H0 채택|H0 기각|
|---|---|---|---|
|${H_0}$ True|옳은 결정|1종오류|
|${H_1}$ False|2종 오류(β)|옳은 결정|


    - 1종 오류(Type1 error): 귀무가설이 참일 때, 귀무가설을 기각하게 되는 오류
    - 2종 오류(Type2 error): 대립가설이 참일 때, 대립가설을 기각하게 되는 오류
    
        - 1종 오류는 사실인 귀무가설을 기각하는 오류를 말하며
        - 2종 오류는 허위인 귀무가설을 채택하는 오류를 말한다.

    - 1종 오류는 귀무가설이 참인데 이를 기각 하는 것이며, 2종 오류는 귀무가설이 거짓인데, 기각에 실패하는 것이다.
        
        - 예를 들어, 1종 오류는 불이 안 났는데 경보 알람이 울리는 것이며, 2종 오류는 불이 났는데 경보 알람을 울리는데 실패하는 것이다.
        
        - 위 두 가지 오류 중에 어떤 오류가 더 심각한 영향을 미칠까?
            - (어떤 지표가 더 중요한지는 분야에 따라 다르기 때문이다) 정답은 없지만 보통은 1종 오류라고 이야기한다.
            - 예를 들어, 법정에서 피고인을 대상으로 판결을 한다면, 무죄인 사람을 유죄로 판결하면 안 되기 때문에 귀무가설로써 피고인은
            무죄라고 가정한다. 하지만 이 참인 귀무가설을 기각하게 되는 오류를 1종 오류라고 부른다. 즉, 무죄를 유죄하라고 오판하는 것이다.
        
        - 알파(alpha), 신뢰수준(significance level) 그리고 검정력(power)은 1종 오류, 2종 오류와 관련하여 설정하는 것들이다.
        - 이 설정에 대한 절대적 기준이 없으며 분석자의 주관에 따라 결정하는 내용이다.
        
        - 1종 오류가 올라가면 2종 오류는 내려가고, 1종 오류가 내려가면 2종 오류가 올라간다. 
        - 보통 1종 오류를 고정시키고, 2종 오류를 줄이는 방법을 생각한다.
            - 2종 오류를 줄이고 싶으면 표본수를 늘리면 된다.


### 4.3. 유의수준/유의확률

- **신뢰수준**
    - 가설을 검정할 때 얼마나 빡빡하게 검정할 것인지를 결정하는 수준을 말한다.
    - 연구활동은 99%, 일반적으로는 95%, 단순설문조사는 90% 정도의 신뢰수준을 사용한다.<br>
    <br>
- **유의수준(significance level, α)** : 1종 오류의 위험성을 부담할 최대 확률
    - 유의수준 = 1 - 신뢰수준
    - 가설을 검정할 때, "이 정도까지 벗어나면 귀무가설이 오류라고 인정하겠다"하는 수준을 말한다.
        - 보통 0.05(5%)로 잡는다(평균과 평균으로부터 상, 하한 구간의 경계선을 95%로 정해 놓는다).
        - 관측치가 이 신뢰구간 안에 포함되는지 본다.<br>
        <br>
- **기각역** : 가설검정에서 귀무가설이 기각되는 검정 통계량의 영역
    - 가설이 통계적으로 맞았는지 틀렸는지 알려주는 기준(값)
    - 확률분포에서 귀무가설을 기각하는 영역을 말한다.
    - 기각역에 검정통계량이 위치하면 귀무가설을 기각한다.
    - 양측검정인 경우 기각역은 유의수준 / 2 이고, 단측검정인 경우 기각역은 유의수준과 같다.<br>
    <br>
<img src = "https://t1.daumcdn.net/cfile/tistory/2376B13458D9C13F29">
- **임계치** : 신뢰구간에서 기각역으로 넘어가는 기준이 되는 x값을 말한다.

<img src = "https://t1.daumcdn.net/cfile/tistory/222B073358D9C2BD09">

#### 검정통계량이 어디에 위치하느냐에 따라 귀무가설을 기각하거나 기각하지 않는다.

- **검정통계량** : 통계적 가설을 검정할 목적으로 사용되는 통계량, 수집된 표본을 통해 귀무가설의 옳고 그름을 판단하는 기준이 되는 값 또는 통계량
    - 실제 데이터(수치)로 얻은 값
    - 가설을 검정하기 위한 기준으로 사용하는 값(t값 등)을 말한다.
    - 검정통계량이 확률분포 상에 어디에 위치하는지에 따라 귀무가설을 기각하거나 기각하지 않는다.
    - ex) 새로 개발한 치킨 100마리의 평균 칼로리값 (표준화를 시켜서 계산을 해야 함)
    
<img src = "https://t1.daumcdn.net/cfile/tistory/217ABA3858D9CB502E"><br>
<br>
- **유의확률(significance probability, p-value)** : 귀무가설이 맞다고 가정할 때 얻은 결과보다 극단적인 결과가 실제로 관측될 확률, 검정통계량을 통해 얻어지는 확률
    - 자유도를 고려했을 때 검정통계량에 대한 확률을 말한다. (귀무가설의 신뢰구간을 벗어나는 확률)
    - 기각역보다 유의확률이 작아야 귀무가설을 기각할 수 있다.
    - 검정에서 쓰이는 분포에서 기각역 이상의 영역이 유의확률
    <br>
<br>
- **자유도**
    - x값이 가질 수 있는 값의 범위를 말한다.
    - 자유도가 주어지지 않는 경우, 자유도= 표본수(n) - 1

#### 결국, 유의수준과 유의확률 밖에 보지 않는다. 그리고 유의수준은 임의(0.05)로 정한다


### 4.4. 가설검정 (0가설 검정)
    - 모든 분석은 '가설검정'을 거친다.
        - H0 : H1 = H2
        - H1 : H1 != H2
    - 달라야지 의미가 있다. 같은 건 의미가 없다.
    
    - 유의수준과 유의확률(p-value)를 이용하여 가설검정을 한다.
    - 설명할 때, "유의수준(알파값)을 0.05로 설정했더니 결과가 이렇게 나왔다."
        - 유의수준 > 유의확률
            - 귀무가설 채택, 대립가설 기각
            - 통계적으로 유의하지 않다.
            
        - 유의수준 < 유의확률
            - 대립가설 채택, 귀무가설 기각
            - 통계적으로 유의하다. 유의한 차이가 있다.
    
    - 귀무가설: 기존에 알고 있던 사실 (통계적으로 균질한 것)
    - 대립가설: 내가 주장하고 싶은 것 (통계적으로 균질하지 않은 것)
        - 유의하다 = 의미가 있다.
        - 내가 주장하는 게 맞으려면 대립가설이 맞아야 함.
    
    - 예시) 올리브영에서 남자 고객을 늘리기 위해 특정 프로모션(마케팅)을 실시했는데 효과를 어떻게 측정할 수 있을까?
        - 연령대로 나누고(20/30대), 성별(남/녀)로 나눠서 T-test로 검정한다(비교 집단이 2개 이상일 경우, Anova 검정)
            - 남 > 여 : O
            - 남 = 여 : X
            - 남 < 여 : XX

#### 귀무가설 채택, 대립가설 기각
<img src = "https://t1.daumcdn.net/cfile/tistory/2363874A58D9E26403">

#### 귀무가설 기각, 대립가설 채택
<img src = "https://t1.daumcdn.net/cfile/tistory/2770224E58D9E5C407">

#### 표본에 따라 귀무가설이 기각되기도 하고 기각되지 않을 수 있으므로 표본은 모집단을 대표할 수 있도록 잘 샘플링 하는 것이 매우 중요하다.


### 4.5. 우리가 이렇게 삽질하는 이유 : 'Random Sampling' 때문이다.
    - Random Sampling을 하면 Error는 필연적으로 생길 수밖에 없다.
    - Random에 의한 우연인지, 실제 효과인지 알 방법이 없다.
        - 그렇기 때문에 검정을 해야 한다.

### 4.6. 정리
- ${H_0}$(귀무가설)
- ${H_1}$(대립가설)

|||차이|영향력|연관성|효과|
|---|---|---|---|
|${H_0}$||X|X|X|X|
|${H_1}$||O|O|O|O|

    - 대립가설과 귀무가설은 목적성과는 별개로 설정되어야 한다.
        - 내가 원하는 주장이라고 해도 (대립가설이 아니라) 귀무가설이 될 수 있다.
        - 쉽게 말하면, 귀무가설은 세상이 생각하는 상식과도 같다.

    - 검정통계량
        - 실제로 관측된 값

    - 기준
        - 유의수준(α) : 일반적으로 0.05(5%)
            - 95%의 신뢰구간

    - 내가 맞다는 걸 주장하고 싶으면, 바로 검증하기 전에 내 반대 주장의 확률을 살펴본다,


### 4-7. 퀴즈
    - 새로 개발한 두통약의 효과 통계적으로 검증하기
        - 두통 완화 효과는 뇌파의 강도로 측정 가능하다고 가정
        - 예산 편성, 평소 두통이 심하다고 검증된 100명, 나이와 성별, 생활 환경 등이 비슷한 환자

    - 1) 구체적으로 어떻게 해야 원하는 결과를 검증할 수 있을까?
        - 우선 효과를 정의해야 한다. 무엇을 효과라고 할 것인가?
            - 뇌파의 측정값이 줄어드는지 검증
            
        - 100명의 data (sampling)
            - 1) Between(집단 간)
                - 랜덤하게 2 집단으로 나눈다.
                - 처치한 집단, 처치하지 않은 집단의 뇌파 평균
                - 평균이 차이가 있는지 0가설 검정 (통계적으로 확인)
                - 0가설(귀무가설) : 두 집단 간의 차이가 없다.
                - 대립가설 : 두 집단 간의 차이가 있다.
                
            - 2) Within(집단 내)
                - 1차 투입
                - 2차 투입
                - 3차 투입
                - 평균, 투약했을 때와 투약하지 않았을 때의 차이를 검증
                - 0가설은 똑같지만, 같은 집단 내에 반복되게 노출시킨다.

    - 2) 이때의 0가설은 무엇인가?
        - 두 집단 간의 차이가 없다.

## 5. 집단간 차이 검증하기 (Z, T, F)
   obj : 집단간 차이는 통계적으로 어떻게 검증하는가?
   
### 5.1. 표준화와 Z분포
#### 5.1.1. 표준화(Standardization)
    - 집단끼리 비교하고 싶은데, 절대적인 수치로는 비교할 수 없다.
    - 왜냐하면 집단에서 의미하는 단위의 의미가 다르기 때문이다. 단위 통일이 필요하다.
           - 그래서 단위를 σ로 맞추는 것이다.
           - 평균으로부터 떨어진 거리
           - 위치에 대한 비교가 가능해진다.

<img src = "https://t1.daumcdn.net/cfile/tistory/25380C3F5430F1B827">

#### 5.1.2. Z분포
    - 상대적인 비교를(확률적으로 이야기하기) 위해서, Z를 쓴다.
    - 모든 수치를 z로 바꾸면, z분포이다.
       - 표준정규분포
           - 확률적으로 평균을 기준으로 분산에 따라 분포
           - 평균(기대값)은 항상 0이고, 분포는 1, 넓이는 1을 갖는다.

    - ex) 우리나라 20대 성인의 평균키는 173cm 이며, 표준편차는 5일 경우. 내 키는 상위 몇%에 속하는지 직접 계산하기.
        - Z = x - μ / σ
            - μ = 173, σ = 5
            - (174-173) / 5 = 0.2

       
#### 5.1.3. 신뢰구간
   
<img src = "https://t1.daumcdn.net/cfile/tistory/2158AE4E546AD9C72C">


#### 5.1.4. 퀴즈
    - 토익 문제집 효과 검증하기
       - 토익 문제지를 새로 만들었는데, 이 문제집이 토익 점수를 올리는데 효과가 있는지 알아보고 싶다.

       - 평가기준
           1. 0가설과 효과에 대한 논의
           2. 샘플링을 어떻게 할 것인가?
           3. 각 방법의 장단점을 어떻게 정의할 것인가?

       - 실험설계
           - 1. 0가설과 효과값 정의
               - 경향성을 논의하기 위해 평균값을 이야기 해야 한다.
               - 귀무가설
                   - H0 = H1
                   - 처치 전후의 평균 차이가 없다.
                   - 새로 만든 토익 문제지는 점수를 올리는데 효과가 없다.

               - 대립가설
                   - H0 != H1
                   - 처치 전후의 평균 차이가 있다.
                   - 새로 만든 토익 문제지는 점수를 올리는데 효과가 있다.

               - 효과값 : 주관적인 부분

           - 2. Sampling
               - 100명 모은다 치자.
                   - 정의하기 쉽게 비슷한 성질로 sampling 한다.
                   - 비슷한 점수, 연령대

           - 3. 분석 방법 정의
               - 집단 내 ... 제약회사, IT회사(A/B Test)
                   - 장점 : 추이(trend)를 볼 수 있다.
                   - 단점 : 학습(learning)효과를 배제할 수 없음(Overfitting)

                       - 천장효과의 문제
                       - n번 마다 결과값이 들쑥날쑥할 수 있음

                   - 같은 집단 내에 반복 노출 시킨다.
                   - 모의고사 평균 점수를 확인한다.

               - 집단 간 ... 실험실
                   - 장점 : 대조군을 쉽게 비교할 수 있다.
                   - 단점 : 통제(Control)가 어렵고, 샘플링의 편향성(bias)이 존재할 수 있다.
                   - 랜덤하게 2집단으로 나눈다.
                       - 새로운 문제지를 푼 집단과 풀지 않은 집단

                   - 모의고사 평균 점수 확인한다.

        - 같은 데이터를 갖고도 분석 방법에 따라 결과가 다르니까 방법을 잘 정의해야한다. 
         
   
### 5.2. T분포
#### 5.2.1. 가설 검정을 반복할 때의 문제, '1종 오류'
    - (가설 검정할 때 하는) 우리의 가정
        - (5%는 현실에서 잘 안 일어나니까) 구간을 95%로 정해놓고 5% 이하일 때만 귀무가설을 기각한다.
        - (실제 우리의 생활에서 5%라는 것은 드물지만) 반드시 일어나는 확률 중 하나이다.
        
        - 즉, 우리는 5%를 우연이라고 치고 귀무가설을 기각 해버렸지만, 실제로는 우연이 아니라 실제로 그럴 수도 있을 가능성이 항상 존재한다.
        
        - 귀무가설을 기각하면 안 되는 경우인데 기각한 오류(또는 확률), 통계학에서는 이것을 1종 오류라고 부른다.
        - 우리가 어떠한 통계적 가설검정을 하면, 우리가 정한 구간에 따라 1종 오류가 자동으로 결정되며, 검증을 반복하면 에러가 누적된다.

#### 5.2.2. Solution 1 : T-test
    - 방금 살펴본 1종 오류 외에도 모집단을 모르는 이유 때문에 z분석은 실생활에서 크게 사용되지 않는다.
    - Sample을 가지고 모집단의 차이를 유추하는, 자유도에 따라 분포 모양이 변화하는 t 분포를 이용하는 분석을 쓴다.
    - T-test는 두 집단의 차이가 있는지 검증할 때 사용한다.

#### 5.2.3. 차이 정의 : 집단 내 vs 집단 간
    - T-test가 가장 많이 쓰이는 곳은 '집단 간'차이 분석할 때이다.
    - ex 1) 새로 개발한 약 테스트
        - 집단 내 설계
        - 병원에서 개발한 시약이 효과가 있는지 확인하기 위해서, 총 10명의 환자에게 3회에 걸쳐 약을 먹이고, 먹고 난 다음에 병세를 체크했다.
        - 약을 복용함에 따라 병세가 호전되었다면, 이것은 효과가 있는 약이라고 얘기할 수 있다.
        
        - 이러한 실험 방법을 '집단 내 설계'라고 부르며, 1개의 동일한 집단에 반복해서 측정한다고 해서, '반복 측정 설계'라고도 부른다.
        - 이때는 반복 측정 T검정이라는 분석 방법을 쓰면 된다.
        
    - ex 2) 새로 만든 토익 문제지 테스트
        - 집단 간 설계
            - 토익 점수가 비슷한 사람 100명을 모집해서, 2개의 그룹으로 나눈다.
            - 첫번째 집단에는 새로 만든 토익문제지를 풀게하고, 두번째 집단은 그냥 원래 하던대로 하게 둔다.
            - 특정 기간이 지난 후에, 각 집단의 평균을 비교했을 때 새로운 문제지로 푼 집단의 토익점수가 더 높으면 이 문제지가 토익 점수를 높이는 효과가 있다고 말할 수 있다.
            
            
    - 2번의 접근 방법은 우리가 상식적으로 생각하는 '실험'에 가장 가깝다.
    - 즉, 뭔가 처치를 하는 <실험군>과 아무 것도 하지 않고 두는 <대조군>을 두고, '처치 전후의 평균값 차이를 비교'하는 것이다.
    - 이러한 설계를 '집단 간 설계'라고 부르며, 이때는 '독립 집단 T검정'을 써야 한다.
        

#### 5.2.4. T-test 해석
    - (분산) 동질성 검정
        - 같은 결과라도 분산이 다르면 분포가 달라진다.
            - 두 집단의 분산이 같은 경우
            - 두 집단의 분산이 다른 경우

        - 똑같은 평균값이라고 해도 T-test 값은 다르다.
            - 집단 간 비교는 분산(분포가 벌어진 정도)을 생각해야 한다.

        - 두 집단의 분산이 어느 정도 동일해야 한다.

        - α(유의수준) < p-value(유의확률)
            - 두 집단간 통계적으로 차이가 없다.
            - 대립가설 기각

        - α > p-value
            - 두 집단간 통계저긍로 차이가 있다.
            - 귀무가설 기각
            
|사실 / 결정| H0 채택|H0 기각|
|---------|----------|------|
|*H0 True*|옳은 결정|1종 오류(α)|
|*H0 False*|2종 오류(β)|옳은결정|

    - 1종 오류(Type1 error): 귀무가설이 참일 때, 귀무가설을 기각하게 되는 오류
        - 2종 오류(Type2 error): 대립가설이 참일 때, 대립가설을 기각하게 되는 오류
            - 1종 오류는 사실인 귀무가설을 기각하는 오류를 말하며
            - 2종 오류는 허위인 귀무가설을 채택하는 오류를 말한다.

    - 표본의 수(n)가 30을 넘으면, 표준정규분포와 동일하다고 본다.
        - 정규화가 되었다고 본다.
        - 편포여도, 샘플 수가 많아지면 정규화가 됨

    - 데이터의 속성부터 파악해야 한다. 알고리즘은 제일 나중이다.


#### 5.2.5. T-test의 한계점
     - 접근 방법이 z분석과 동일하기 때문에 1종 오류를 극복하지 못했다.
     - "두 집단간의 차이가 있는지 통계적으로 검증하시오"
         - 두 집단 간 차이가 있는지 검증하기 위해 귀무가설을 '두 집단 간 차이가 없다'로 가정한 분폴르 본다.
         - 집단간 차이가 있는 관측치가 나올 확률을 계산한다.
         - 해당 확률이 너무 낮으면(통상 5% 이하) 차이가 없다는 귀무가설을 기각하고 대립 가설을 채택한다.   
   
### 5.3. F검정(Anova)
    - 여태까지 집단간 차이를 '평균값'의 차이로 정의하였다.
    - 평균 말고 분포의 특성을 나타내는 수치가 하나 더 있는데 그게 바로 '분산'(분포가 벌어진 정도)이다.
    
    - 집단 간 비교의 끝판왕이라고 생각하면 된다.
    - 세 개 이상의 집단을 비교할 때, 사용하는데 평균으로 비교하는 게 아니라 분산으로 비교한다.
    
    - 수식
        - H0 : A = B = C
        - H1 : A, B, C의 분산 중 하나라도 차이가 있다.

    - F 검증의 한계
        - 집단 간 차이가 있는지 없는지를 알려주지만, 차이가 있다면 어떤 것에서 차이가 있는지 알려주지 않는다.
        
    - F 검정을 통해 유의미한 차이가 있다면, T-test로 하나씩 잡아야 한다.
    
### 5.4. 여러 가정들
    - 1) 독립성
    - 2) 정규성
        - 샘플 수가 늘어나면 자동으로 정규분포가 된다.
        - n이 30개
    - 3) 등분산성
    
    
## 6. 상관과 회귀
- 데이터의 유사성은 어떻게 따지는가?
- 예측은 어떻게 하는가?


### 6.1. Part 1. 행동 패턴 찾기 : 상관
#### 6.1.1. 설명
- 통계에서는
    - 무엇을 하였는지 알고있다. = 데이터의 패턴이나 추이를 알고있다.
    - 데이터의 패턴이나 추이를 알게된다는 것은 그 다음을 예측할수 있다는 뜻이된다.
        - 예를 들어, 시간에 따라 증가하는 패턴이 있고, 특정 단위 시간당 증가량을 수학적으로 알고 있다면?
        - 아마....다음시간 에도 그럴꺼야 라고 추측할 수 있게 된다.
        - 반대로 감소하는 경우에도 마찬가지.
    - 즉, 데이터가 변화하는 패턴을 알 수 있으면, 유사한 정도를 알 수 있게 된다.
    - 더불어 관계성을 알았기 때문에, 앞으로 어떻게 변할 것인지 예측도 가능해짐 <br>
    <br>
- 이렇게 지난 데이터의 패턴을 파악해서, 그 패턴이 계속 유지된다는 가정 하에 미래를 예측하는 분석을 회귀분석이라고 한다.
    - 데이터로 유사성을 알아보는데서 출발했는데 자동으로 예측도 가능해짐.
        - (1) 비슷하다를 정의한다 = 패턴을 본다 = 상관분석(pearson r)
        - (2) 만약 위 (1)에 의하여 집단간 패턴을 알게된다면 앞으로 어떻게 변화할지 예측도 가능! = 회귀분석 <br>
    <br>
- 상관분석
    - 두 데이터 간의 연관성을 따진다.
    - 상관하고 회귀는 떨어질 수 없다.
    - perason r(상관) = (같이 변하는 정도) / (서로 각기 변하는 정도) = (공변량) / (변량) <br>
    <br>
- 공변량(=공분산)
    - (분산, 변량)각자 서로 변화하는 양이 있고, (공분산, 공변량)같이 변하는 패턴이 있다.
    - 그걸 보고 유사한 정도를 알 수 있다.
    - 상관 값은 (최소)-1 ~ 1(최대)에서 존재
    - r = 1이면, 동일하다. y = x

#### 6.1.2. 퀴즈
- 데이터에 따른 상관값
    - 두 집단 X와 Y의 상관을 구하자.
    - 이때, X = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] <br>
    <br>
    - r(xy) = 1 이라면, y의 값은?
    - r(xy) = 0 이라면, y의 값은?
    - r(xy) = -1 이라면, y의 값은? <br>
    <br>
- 상관 관계 파악 및 그래프 그려보기
    - r = -1이면 두 집단 관계성 그래프는 어떤 형태를 띌까?
    - r = -1과 r = 0 중에 두 집단의 유사성이 높은쪽은 어느 쪽 값인가?
- R
    - r에서 +, - 는 방향성일 뿐이다.
    - 0.4 이상, 양의 상관관계 
    - 0.7 이상, 강한 양의 상관관계
- R^2

#### 6.1.3. 상관관계와 인과관계
- [초콜릿과 노벨상](http://www.dt.co.kr/contents.html?article_no=2014111902102251607001)
    - 유사성은 데이터의 패턴만 논한다.
    - 상관관계와 인과관계를 혼동하지 말자<br>
    <br>
- [백신의 효과](http://www.nocutnews.co.kr/news/4389170)
    - 상관값을 가지고, 인과를 논하면 안 된다.
        - 백신의 효과를 검증하려면 인과관계를 봐야한다.
        - 백신의 효과를 상관으로 해석하면 안 된다.<br>
    <br>
- 이 분석을 왜 하는가?
    - 상관분석의 목적은 두 데이터의 유사성을 따지는 것이다.
        - 상관관계는 데이터의 유사성을 보는 것.
        - 유사성은 인과관계를 따지는 게 아니다.<br>
        <br>
- 선형의 관계에서만 사용한다.
    - 사용자 추천
        - 유사도 만들기(계산)
            - 피어슨 상관관계
                - 현실에서는 이 방법을 잘 안쓴다.
                - 이건 선형의 관계에서만 사용할 수 있기에<br>
                <br>
                
### 6.2. Part 2. 예측 : 회귀분석
#### 6.2.1. 설명
- 회귀 : 돌아오다
    - 어디로? : 평균으로 돌아간다.<br>
    <br>
- 통계는 '귀납법'이다.
    - 데이터의 분포를 보고 선을 긋는 것(귀납법)이지,
    - 선을 긋고 데이터를 찾는 건 아니다(연역법).
    
#### 6.2.2. 최적화
- 패턴을 가장 잘 설명하는 녀석을 찾자 : data-fitting, modeling의 의미
    - 회귀분석 = data-fitting = modeling
    - LMS 알고리즘
        - 오차 : 최소자승법(Least Mean Square, Mean Squared Error)

    - RMSE(Root Mean Squared Error)
        - 루트를 씌워줌으로써 값을 작게 만들어줌

#### 6.2.3. 회귀선 검정
- R =  피어슨 R
- sig. = p-value

#### 6.2.4. 단순 회귀 vs. 다중 회귀
- 다중공선성
#### 6.2.5. 선형 회귀 vs. 비선형 회귀 
#### 6.2.6. 로지스틱 회귀
- 특징
    - 결과값이 binary(즉 0또는 1)이 나옴.
    - 즉, 데이터를 분류할 때 사용
        - 남자 vs. 여자 같은 데이터를 주고 어떤 데이터가 들어오면 '남자/여자' 이런 식으로 예측
        - 이러한 분석을 위해 '카이제곱 분포'와 '우도'라는 개념을 이용하
- - -
#### Overshooting
- 데이터의 문제
    - cost가 너무 커서 그렇다.
    - rescaling : mean max scaling, 표준화
#### Machine Learning
- 머신러닝
    - 목적
        - '분류'
        - '예측'
    - 방법
        - 지도학습
            - 현업에서는 잘 못 쓴다. 정답이 없기에.
        - 비지도학습
            - 단점 : 우리의 목적대로 잘 되었느냐? 알 수 없다. 정답이 없으니까. 정답을 모델에 안 알려줬기 때문에. 머신은 벡터 공간만으로 수학적으로 계산할 수 밖에 없다.
            
- 중요한 건
    - 요구 목적 정의
    - 데이터 확인
    - 알고리즘 선택

- - -
    
## 7. 변수척도
### 7.1. Discrete (셀 수 있는)
#### 1) 명목형 변수
    - Category : 성별, 지역, 정당 ...
    - 우위가 없음
    
#### 2) 순서형 변수
    - 서열 : 신용등급, 순위 ...
    - 우위가 있음

### 7.2. Continuous (셀 수 없는)

#### 3) 연속형 변수
    - 구간으로 본다.

### 7.3. 요리와 데이터
- 건강한 요리 : 재료 + 영양소 (파악) ... 조화로운 요리법
- 건강한 분석 : 데이터 + 정보량 (파악) ... 조화로운 분석법
    - 각 변수에 맞는 분석 방법이 있다
        - 변수의 특성(척도)에 따라 분석 방법이 정해진다.
- 명목형 변수 : A
- 순서형 변수 : A + B
- 연속형 변수 : A + B + C
- 연속형 변수에서 순서/명목형 변수로 갈 수 있고, 순서형 변수에서 명목형 변수로 갈 수 있다. 허나 반대는 불가능하다.
    - ABC -> AB or A / AB -> A : O
    - A -> AB or ABC / AB -> ABC : X 
    

### 7.4. Trade-Off
- Trade off란?
    - 
- T-test / Anova / Regression / Logistic
    - ?
    - 차이 : T-test / Anova
    - 관계 : Regression
    - 연관 : 독립성 검정
    - Logistic : 관계를 보는 분석(obj: 분류)


### 7.5. Random Variable (확률변수)
- 확률 실험 : 모든 게 확률이다.
    - Sample Space(표본 공간) : 확률실험에서 나올 수 있는 가능한 모든 결과의 집합이 표본공간
        - ex) 동전던지기 -> '앞/뒤' <br>
    <br>
    - 결과
        - 동전 앞, 뒤 / 주사위 1~6 : Discrete R.V
        - 시속 30km/h : Continuous R.V <br>
        <br>
- ex) 마케팅
    - 메케팅의 효과(y, output) : R.V (0)
        - 종속변수
    - 마케팅 조건(x, input) : R.V (X)
        - 독립변수
        - 인위적으로 조정할 수 있는 변수들
- 확률 분포 -> 정규분포 ?
- Probability Distribution ?
- **데이터(재료)에 따라서 방법론(요리법)이 달라진다.**
    - 확률 변수와 확률 분포에 따라서 분석법이 정해진다.
    - 이항분포 / 다항분포 / 정규분포 ...
        - 동전의 앞,뒤 ... 이항분포
        - 주사위 1~6 ... 다항분포
        - y값에 따라 이항/다항 분포로 나뉜다.
    - 정규분포
        - 평균을 기준으로 데이터가 분포해 있음을 가정함

|X (R.V x)|Y(R.V o)|Test|
|--------|----------|------|
|명목형 변수|연속형 변수|T_test, Anova|
|연속형 변수|연속형 변수|Regression|
|연속형 변수|등급형 변수|Logistic Regression|
|명목형 변수|명목형 변수|Chi-squared test|

- 위에 그래프 해설
    - x는 독립변수(input), y는 종속변수(output, random variable)
    - 1) 명목 / 연속 : T-test, Anova
        - 성별에 따른 매출액의 차이(집단에 따라서 연속형 변수의 차이가 있는지 ... 모든 변수가 들어갈 수 있음)
    - 2) 연속 / 연속 : Regression
        - 마케팅 비용을 쏟아 부었을 때의 효과 측정
    - 3) 연속 / 등급 : Logistic Regression
        - 신용 등급, 암환자 예측
    - 4) 명목 / 명목 : Chi-squared test
        - 특정 지역과 정당이 서로 연관성이 있는지 (지방선거의 지역색, 지역감정을 규명)

- **통계: 규칙을 정하자. vs. 머신러닝: 학습을 해서 규명하자.**
- 변수를 봤을 때, 척도를 보면서 어떤 걸 보면서 분석하면 될 것이다.

- - -

## 8. 기본제약 과정
### 8.1. T-test / Anova / Regression
- Linear Model(선형 모형) : 데이터를 선으로 표현할 수 있느냐?
    - x (독립)변수는 고려할 필요가 없다.
    - 우리의 목적은 **y변수 (random variable, 확률변수)** ... 얘만 생각한다

### 8.2.  세 가지의 기본 원칙
- 전제조건
    - **y변수는 Continuous(연속형)**
    - **모든 통계는 정규분포를 가정하고 시작한다**
    - **추정**
        - Sample을 통해 Population을 추정한다.
        - 추정에는 점추정과 구간추정이 있다.
        - 구간 추정에는 신뢰구간이 있음.<br>
<br>
- 기본적으로 세 가지만 따지게 된다
    - **정규성 / 등분산성 / 독립성**



#### 8.2.1. 정규성
- obj : **구간 추정을 잘 하기 위해서**
- **(continuous) y변수가 정규분포를 따르는가**
    - 모든 통계 모형들이 정규분포를 가정하고 만들었다.
        - why : (결과를 추정하기 어렵기 때문에) 이런 가정을 한 것이다.
        - obj : 통계 분석은 표본을 통해서 모집단을 추정하는 것<br>
        <br>
    - 점추정(point estimation)과 구간추정(interval estimation)
        - **점추정 : 하나의 점(수치)으로 값을 표현**
            - 값을 신뢰하기에는 (모집단에 비해)표본의 수가 적고, 표본에는 항상 오차가 존재한다.
            - 그러므로 점추정은 그 특성상 값을 신뢰하기 어렵다.<br>
            <br>
        - **구간추정 : 점 추정치를 중심으로 일정 구간을 만드는 것**
            - 통계에는 구간 추정이 주를 이루는데, **신뢰구간**이 필요하다.
            - **구간추정이라고 해서 100% 신뢰할 수 있는 것은 아니다.**
            - 경우에 따라서는 구간추정치 안에 모수가 포함되지 않을 가능성도 항상 존재한다.
            - 그리고 구간추정은 점추정에 비해 신뢰도가 확실히 높다고 할 수 있지만, 그렇다고 점추정이 전혀 필요 없는 것은 아니다.
            - 왜냐하면 점추정을 기준으로 구간추정을 하기 때문이다.
            - ex) 지방선거 여론조사 : 표본오차 95%
                - 모집단을 대표할 수 있는지에 대한 내용
                - 표본을 100번 뽑았을 때, 95번은 모집단을 대표한다는 뜻으로 신뢰수준 +- 3.5%는 점 추정 값에서 +- 된다.

#### 8.2.2. 등분산성
- obj : **선형모델의 식이 의미가 있는지(현실을 제대로 반영하고 있는지) 파악**
- 최소제곱법
    - 선과 데이터의 거리는 최소화 되어야 한다?
    - 선형 모형을 만들었을 때, 선이 데이터를 잘 설명할 수 있는가?
    - 결과를 추정하는데 있어 데이터에 특정한 패턴이 있으면 안 된다.
    - (선을 기준으로) 점점 멀어지거나, 떨어지거나 하는 규칙이 있으면 안 된다.
    - 데이터는 무조건 무작위로 찍혀 있어야 한다. 

#### 8.2.3. 독립성
- obj: **y변수가 시간에 따라서 연관이 있는지 없는지(독립적인지 종속적인지) 따지는 것**
    - 과거로부터 영향을 받아왔는지
        - 대표적으로 시계열(Time Seires)인지 보는 것?
        - Ex) 주식, 물류, 날씨<br>
        <br>
    - 이걸 왜 따지느냐?
        - 확률 실험(Random Experiment) 결과가 독립적으로 측정되었는지 판단하기 위해?
        - 확률 실험(random experiment) : 결과를 예측할 수 없는 실험
            - 과거로부터 영향을 받은 거라면 시계열 분석으로 넘어가고,
            - 독립적이면 일반적인 분석방법론을 적용. <br>
            <br>
    - 회귀식의 목적은 : y변수에 대한 독립성을 따지는 것
        - ex) 지나가는 사람들, 무작위 패턴
            - 날씨 : 지금 25도라면 10분 뒤의 온도도 비슷하다. (독립적이지 않고, 종속적이다. Time Series임)
            - 만약에 날씨가 독립적이면 10분 뒤 온도를 예측할 수 없다. (독립적이다)<br>
<br>
- 위배되었을 경우
    - 정규성
        - 적당히 맞춰주었다면 넘어간다.
    - 등분산성
        - 위배되면 의미가 없다. 이럴 때는 분석 방법을 바꿔야 한다.
    - 독립성
        - 과거로부터 영향을 받은 거라면 시계열 분석으로 넘어가고, 아니라면?

### 8.3. 핵심
- 무슨 분석을 할지 미리 정하면 안 된다.
    - 분석은 데이터에 나와 있다.
    - 조심해야할 것들 (정규성, 독립성, 등분산성)을 생각하고 분석에 들어가야 한다.
    - 어떤 목적을 가지고, 해야하는 것과 하지 말아야 할 것을 판단하는 게 핵심이다.<br>
<br>
- 확률 실험을 많이 하면 할수록 정규분포의 모양을 갖는다.
    - **중심극한정리**
        - "N(표집수)가 충분히 많으면, 모든 확률분포는 정규분포로 수렴하며, 평균은 실제 평균에 점점 가까워진다"<br>
<br>
- 이 분석법을 왜 하면 안 되냐?
    - 특정 상황에서 어떤 분석을 써야하고, 안 써야하는지에 대한 기준을 갖는 것.
        - **이렇게 하면 틀린다를 기준으로 분석에 임하자**<br>
        <br>
- 수학과 통계는 비슷하다?
    - 통계는 허수를 다루지 않는다. 확률로 시작해서 확률로 끝나는 학문이다.
    - 애초에 실수값만 다루는 게 통계고, 거기에서 이어지는 통계 가정론은 랜덤으로 시작해서 추정으로 끝난다.
    - 99%라도 100번 중에 1번이 바로 나올 수도 있다. 정답은 없다. 그 누구도 모르는 것이다.
    - ex) 일본의 방사능 쓰나미, 파도 높이 11m는 안 올 것이라고 생각해서 방파제를 10m로 만들었다(10m이상의 파도의 확률이 0.3% 정도... 재수 없게 발생한 것이다).
        - 일본이 오판했던 것은 파도 높이다. 몇 m만 높게 쌓았으면 방지가 되었을 것이다. 일본 방사능 문제는 지진이 아니라 파도 높이 때문이었다.
        - 파도 높이는 확률로 판단했다. 그게 바로 통계다. 장담할 수 없다. 정답이 없다. 수학은 정답이 있지만 통계는 정답이 없다.
    - 반대로 생각하면, 이렇게 하지 말라(실수는 하지 말라)는 식으로 접근할 수 있다.
    - 통계는 성능을 개선 시키는 것이지 정답은 아니다. 실수는 하지 않는다는 것은 확실하다. 그렇게 가는 것이다.
    - 분석이라는 것은 애매하다. 통계는 다 구간추정이다. 80%라는 건 20번 실패할 수 있다는 뜻이다.
    - 틀린 것만 방지해도 중간은 간다. 중간까지 갔으면 거기에서 발전시키면 된다. 첫술에 배부를 수 없다.
    - 통계는 동 떨어져 있는 게 아니라 현실이다.
- - -
- http://kkokkilkon.tistory.com/36



## 15. 기계학습
### 15.1. 머신러닝 정의
    - 머신러닝에 대한 설명은 추후에 자세하게 설명할 예정이니, 머릿 속에 지도를 그릴 수 있을 정도로 간략하게 설명하겠다.

    - 1. Label 유무에 따른 머신러닝
        - 1) Label(정답)이 있으면 지도학습(Supervised Learning)

        - 2) Label(정답)이 없으면 비지도 학습(Unsupervised Learning)
            
    - 2. Label의 종류에 따른 머신러닝 기법
        - 1) Regression (회귀) : 종속 변수(y)가 수치형
            - 종속변수(Y)가 독립변수(X)에 영향을 받을 때, 그 변수들 간의 함수 관계를 규명하기 위하여 이용되는 통계적 방법
            - 회귀 모형이 학습되었을 때, 새로운 독립 변수의 값으로부터 종속 변수의 값을 예측할 수 있다.
            - 종속변수(Y)에 중요한 영향을 주는 주요 독립변수 선별
 

<img src = "https://t1.daumcdn.net/cfile/tistory/9933C13E5B2A0F2427">
 
            - 알고리즘 종류
                - a) 선형 회귀 (Linear Regression)
                    - 단순 선형 회귀 (Simple Linear Regression)
                        - 독립변수가 하나일 때 종속 변수의 값을 예측
                        - 예) 여름철의 기온과 아이스크림의 판매량과의 경향성을 파악하면 미래의 일을 예측할 수 있음
\begin{equation}
y = \beta_0 + \beta_1\chi + \varepsilon
\end{equation}
                        
                        - β0 : y절편 (독립변수가 0일 때, 종속변수의 평균값)
                        - β1 : 기울기 (독립변수가 한 단위 증가함에 따라 발생하게 되는 종속변수 평균치의 증가분)
                        - ε : 랜덤 오차 (random error, εi - yi = ŷ)
                        
                        
                        - 최소제곱법 (Method of Least Squares)
                        - 회귀 모형의 타당성
                        - 상관분석 vs 회귀분석
                        
 
                        
                    - 다중 선형 회귀 (Multiple Linear Regression)
                        - 독립변수가 두 개 이상일 때 종속변수의 값 예측
                        - 예) 여름철의 기온, 아이스크림 가격, 소득이 아이스크림의 판매량에 미치는 영향을 분석 및 예측
                        

\begin{equation}
y = \beta_0 + \beta_1\chi_1 + \beta_2\chi_2 + \beta_3\chi_3 +  ... + \varepsilon
\end{equation}

                    - 다중공선성(Multicollinearity)
                    - 회귀 모형의 타당성
                    - Subset Selection (변수 선택법)
                    - 변수 중요도
                    
                    
                - b) Shrinkage Method
                    - Ridge Regression
                    - Lasso Regression
                        
                - c) k-NN
                
                - d) Regression Tree
                
                - e) ANN (Artificial Neural Network)
                
                - f) SVM (Support Vector Machine)
                
                        
                        


        - 2) Classification (분류) : 종속 변수(y)가 명목형
            - Supervised Learning의 일종으로 다양한 X 변수들과 미리 정의된 class 변수(Y)와의 관계를 밝히는 과정
            - Traning set으로 모델을 학습한 뒤, 새로운 data(Test set)가 주어졌을 때, data의 class를 밝혀내고 정확하게 분류하는 것
            
            - 알고리즘 종류
                - a) k-NN (k-Nearest Neighbors)
                - b) Decision Tree
                - c) ANN (Artificial Neural Network)
                - d) SVM (Support Vector Machine)
                
                - e) Losistic Regerssion
                    - 종속변수가 범주형일 때의 회귀식을 추정하여 분류 문제에 적용하기 위해 사용한다.
                    - 기존의 선형 회귀식

\begin{equation}
y = \beta_0 + \beta_1\chi + \varepsilon
\end{equation}

                    - 예측된 Y값이 0~1사이의 값을 가짐 -> 기존의 선형 회귀식을 사용하기 어려움

<img src = "https://uc2f1cda42c0fe7a8bfbd04480d0.previews.dropboxusercontent.com/p/thumb/AAOzgQbbSFxZUtVy_8yJ63oYbjl5KmMcDlm5jRo4GTr-2LbgbxfvJqW8Ttyp8VUgSsb9EPFvIu06H_3YDstDOncs4YqGazOCDXWWjQvoTYc-fYwQCT1nWWWAcTqUubPK7U0dIVnwH4BN11JzRkuc2jgD5CL-PNqvdROvn09KGjYUq70FmMYf8rqnk5JDPAYgp3HjITSpUISOR9zUmnvZUTtl5_xPDG-cFVRLtkGZ-2vKVA/p.png?size=2048x1536&size_mode=3">
                

                        - 종속 변수의 범위를 [0, 1]에서 [−∞, ∞]로 바꿔주기 위한 작업이 필요
                        - 오즈(Odds) / 로짓(Logit) 변환
                            1. Y값에 대한 확률을 계산
                                - P = P(Y=1) : 어떤 사건이 일어날 확률
                            2. Odds 계산
                                - 사건이 발생할 확률 / 사건이 발생하지 않을 확률
\begin{equation}
odds = \frac p{1-P} = \frac {p(성공)}{1-P(실패)}
\end{equation}

\begin{equation}
0 < Odds < \infty
\end{equation}

                            3. Log Odds 계산
                                - Odds에 Log를 취함


\begin{equation}
log(odds) = logit(P) = In(odds) = ln\left ( \frac{P}{1-P} \right )
\end{equation}

\begin{equation}
-\infty < Odds < \infty
\end{equation}

                    - Log odds를 이용한 회귀식 추정

\begin{equation}
ln\left ( \frac{P}{1-P} \right ) = \beta_0 + \beta_1x
\end{equation}



<img src = "https://www.saedsayad.com/images/LogReg_1.png">


                    - x가 아무리 작아지거나 커지더라도 y는 0또는 1로 수렴
                    
                    - 회귀계수의 해석
                        - 회귀계수가 양수일 때, x값이 증가하면 P(Y = 1)이 증가
                        - 회귀계수가 음수일 때, x값이 증가하면 P(Y = 1)이 감소
                        - x가 한 단위 증가할 때 Odds가 
                        
${\ e^{\beta_i}}$ 만큼 증가
              
                    - Simple linear regression
                        - y = -0.2 + 0.25 hours
                        
                    - Logistic regression
                         
\begin{equation}
ln\left ( \frac{P}{1-P} \right ) = -758.5 + 251.8hours
\end{equation}

\begin{equation}
P = \frac{1}{1+e^-(^-758.5+251.8hours)}
\end{equation}
<img src = "https://uce2c9faf4432d9d2fbf072f743e.previews.dropboxusercontent.com/p/thumb/AAOwtmBYIq6AJ0vqZOUz_hoy3RwJcLdphjuQkJvUjrCP2LG1uiMzagd-raH-geluYTf4OSOqlClyOjlL9IWCMq05QSwtuYEgynFvdme3Ln1p8ZRh-1yiJu8hFTb_k6trqhraBLKqrYQuNv3drBDoBqKYPllIjm2oBtj0SdCf_D4C-ChTsv_CcsRg9FMf1n0HvBJUi1KPBGamwZIxU9HcDORgaBU89YOHAKFUrLL2C1LScA/p.png?size=2048x1536&size_mode=3">

                    - 학생이 공부를 1/3/5 시간 했다면 시험에 pass를 할 확률
                     
\begin{equation}
\hat{p}(hours = 1) = 0
\end{equation}
\begin{equation}
\hat{p}(hours = 3) = 0.045
\end{equation}
\begin{equation}
\hat{p}(hours = 5) = 1
\end{equation}


<img src="https://ucd5d00ff49a428944c62fcd609d.previews.dropboxusercontent.com/p/thumb/AANp-Ir_yqiTR9KJyEpZgDvmuj3dF6IVdrG_L_KzziddVhWNUvdTt1GdRArb8AcFwm1Rg3fNCIglzzsrfoAoargKTnYGd-UF8equVSgXVGvba3s6QE_UFVZZ33Q5ZWjmn5frSKsuzUYKg4rT2jcBBE6m5LZkSooh8z7BXnD4ywfLHA-8gNzIFg3YEuwTXdTiPefGMY8fdKxKQqS7gRZgTlOJCQmFCt3ewC5LV2LdtXAiAQ/p.png?size=2048x1536&size_mode=3">


    - 3. Ensemble Learning(앙상블)
            - Bagging
            - Random Forest
            - Boosting
            - 