{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics for Data Analytics\n",
    "\n",
    "<img align = \"center\" src = \"https://yourlistingexpert.com/wp-content/uploads/2018/01/seo-statistics-1170x659.jpg\">\n",
    "\n",
    "[![HitCount](http://hits.dwyl.io/boys-be-ambitious//Statistics.svg)](http://hits.dwyl.io/boys-be-ambitious//Statistics)\n",
    "\n",
    "\n",
    "## Index\n",
    "## 1. 데이터 분석에 앞서\n",
    "    1.1. 분석의 목적\n",
    "    1.2. 요구 조건 정의\n",
    "    1.3. 신호와 소음\n",
    "    1.4. 데이터 예측, 맛보기\n",
    "\n",
    "## 2. 통계의 기초\n",
    "    2.1. 평균과 표준편차\n",
    "        2.1.1. 대표값\n",
    "        2.1.2. 모집단과 표본\n",
    "        2.1.3. Random Sampling\n",
    "        \n",
    "    2.2. 기술통계 추론통계\n",
    "        2.2.1. 기술통계\n",
    "        2.2.2. 추론통계\n",
    "        \n",
    "    2.3. EDA\n",
    "        2.3.1. Visualization\n",
    "        2.3.2. 중심극한정리\n",
    "\n",
    "    2.4. 점추정과 구간추정\n",
    "        2.4.1. 점추정\n",
    "        2.4.2. 구간추정\n",
    "        \n",
    "    2.5. Outlier (이상치)\n",
    "    \n",
    "    2.6. Missing Valiue (결측치)\n",
    "    \n",
    "    \n",
    "## 3. 분석의 종류\n",
    "\n",
    "    3.1. '차이'를 보는 분석\n",
    "        3.1.1. T-test\n",
    "        3.1.2. Anova\n",
    "\n",
    "    3.2. '관계'를 보는 분석\n",
    "        3.2.1. Regression\n",
    "        \n",
    "    3.3. '연관'을 보는 분석\n",
    "        3.3.1. 독립성 검정\n",
    "        3.3.2. 연관성 분석\n",
    "        \n",
    "## 4. 가설검정\n",
    "    4.1. Hyprothesis\n",
    "    \n",
    "    4.2. 1종 오류와 2종 오류\n",
    "    \n",
    "    4.3. 유의수준/유의확률\n",
    "    \n",
    "    4.4. 가설검정 (0가설검정)\n",
    "    \n",
    "    4.5. 우리가 이렇게 삽질하는 이유\n",
    "    \n",
    "    4.6. 정리\n",
    "    \n",
    "    4.7. 퀴즈\n",
    "    \n",
    "    \n",
    "## 5. 집단간 차이 검증하기 (Z, T, F)\n",
    "    5.1. 표준화와 Z분포\n",
    "        5.1. 표준화 (Standardization)\n",
    "        5.2. Z분포\n",
    "        5.3. 신뢰구간\n",
    "        \n",
    "    5.2. T분포\n",
    "    \n",
    "    5.3. F검정\n",
    "\n",
    "\n",
    "## 6. 상관과 회귀\n",
    "    6.1. 데이터의 유사성은 어떻게 따지는가?\n",
    "    6.2. 예측은 어떻게 하는가?\n",
    "\n",
    "## 7. 변수척도\n",
    "    7.1. Discrete\n",
    "        7.1.1. 명목형 변수\n",
    "        7.1.2. 순서형 변수\n",
    "        \n",
    "    7.2. Continuous\n",
    "        7.2.1. 연속형 변수\n",
    "        \n",
    "    7.3. 요리와 데이터\n",
    "    7.4. Trade-Off\n",
    "    7.5. Random Variable (확률변수)\n",
    "    \n",
    "\n",
    "## 8. 기본 제약 과정\n",
    "    8.1. 목적\n",
    "    8.2. 세 가지의 기본 원칙\n",
    "        8.1.1 정규성\n",
    "        8.1.2. 등분산성\n",
    "        8.1.3. 독립성\n",
    "        \n",
    "## 9. 분포\n",
    "    9.1. Z분포\n",
    "    9.2. T분포\n",
    "    9.3. F검증\n",
    "    9.4. 이산형 확률분포\n",
    "    9.5. 연속형 확률분포\n",
    "    9.6. 지수분포\n",
    "\n",
    "\n",
    "## 10. 정규화와 표준화\n",
    "\n",
    "## 11. 변환의 사다리\n",
    "\n",
    "## 12. 모수적 방법론과 비모수적 방법론\n",
    "    12.1. 모수적 방법론(Parametric Method)\n",
    "    12.2. 비모수적 방법론 (Non-Parametric Method)\n",
    "\n",
    "## 13. MSE\n",
    "\n",
    "## 14. 수집에서의 '적합성', 분석에서의 '타당성'\n",
    "\n",
    "\n",
    "## 15. 기계학습(Machine Learning)\n",
    "    15.1. 머신러닝 정의\n",
    "    \n",
    "    15.2. 머신러닝 분류\n",
    "        15.2.1 Label 유무에 따른 분류\n",
    "            - 지도학습\n",
    "            - 비지도학습\n",
    "            \n",
    "        15.2.2 강화학습\n",
    "\n",
    "    15.3. 머신러닝 알고리즘\n",
    "        15.3.1 Regression(회귀)\n",
    "\n",
    "            15.3.1.1 Linear Regression (선형 회귀)\n",
    "                15.3.1.1.1 단순 선형 회귀 (Simple Linear Regression)\n",
    "                \n",
    "                15.3.1.1.2. 다중 선형 회귀 (Multiple Linear Regression)\n",
    "                    15.3.1.1.2.1. 다중공선성(Multicollinearity)\n",
    "                    15.3.1.1.2.2. 회귀 모형의 타당성\n",
    "                    15.3.1.1.2.3. Subset Selection (변수 선택법)\n",
    "                    15.3.1.1.2.4. 변수 중요도\n",
    "\n",
    "\n",
    "            15.3.1.2 Shrinkage Method\n",
    "                15.3.1.2.1. Ridge Regression\n",
    "                15.3.1.2.2. Lasso Regression\n",
    "\n",
    "            15.3.1.3. k-NN (k-Nearest Neighbors)\n",
    "\n",
    "            15.3.1.4. Regression Tree\n",
    "\n",
    "            15.3.1.5. ANN (Artificial Neural Network)\n",
    "\n",
    "            15.3.1.6. SVM (Support Vector Machine)\n",
    "\n",
    "\n",
    "        15.3.2. Classification (분류)\n",
    "            15.3.2.1. k-NN (k-Nearest Neighbors)\n",
    "            15.3.2.2. Decision Tree\n",
    "            15.3.2.3. ANN (Artificial Neural Network)\n",
    "            15.3.2.4. SVM (Support Vector Machine)       \n",
    "            15.3.2.5. Losistic Regerssion\n",
    "\n",
    "        15.3.3. Ensemble\n",
    "\n",
    "- - -\n",
    "\n",
    "# Contents\n",
    "## 1. 데이터 분석에 앞서\n",
    "### 1.1. 분석의 목적\n",
    "    비즈니스적인 관점에서 보면 조직의 목표를 효율적(최소비용 최대효과, 선택과 집중)으로 달성하기 위해 데이터 분석을 한다.\n",
    "    즉, '이익(Profit)'을 위해서 분석을 한다. 조금 더 상세한 내용은 아래와 같다.\n",
    "\n",
    "    - 1) 매출 증대\n",
    "        - 규모의 경제 (시장의 파이는 한정되어 있고, 경쟁자는 많기)때문에 매출 증대에는 한계가 있다.\n",
    "    \n",
    "    - 2) 비용 감소\n",
    "        - 인건비, 재료비, 마케팅 비용 등 회사에서 나가는 모든 비용을 효율적으로 관리할 수 있다\n",
    "        \n",
    "### 1.2. 분석 전에 생각해봐야 할 것들\n",
    "    - 1) 분석의 목적\n",
    "    - 2) 요구 조건 정의\n",
    "        - 통계와 분석에 대한 이해가 낮은 상사는 목표를 추상적으로 던져주는 경우가 많다(난감 그 자체).\n",
    "        - 이해관계자와 커뮤니케이션을 통해 구체적으로 쪼개고 쪼개서 요구 조건(KPI)을 상세하게 정의한다(눈물이...).\n",
    "    \n",
    "### 1.3. 신호와 소음\n",
    "    - Garbage in garbage out.\n",
    "        - 품질이 좋지 않은 (input)데이터로 분석을 하면, 분석 결과(output)의 질이 좋지 않다.\n",
    "        - '노이즈'를 제거해야 한다(데이터 정합성).\n",
    "            - Noise : Outlier(이상치), Missing value(결측치), Dupliceted values(중복값)\n",
    "\n",
    "### 1.4. (예측 프로세스) 맛보기 - 분류 알고리즘을 머릿 속으로 만들어 보기\n",
    "#### 1.4.1. 개와 고양이 구분하기\n",
    "    - 가정\n",
    "        - 1. 개와 고양이 사진이 500장씩 있다.\n",
    "        - 2. 어린 아이는 틀렸다와 맞았는 걸 알고 있다.\n",
    "        - 3. 틀린 횟수를 줄이려고 끊잆없이 노력한다.\n",
    "\n",
    "    - 이러한 문제는 이진 분류(남/녀, 개/고양이)의 대표적인 케이스이다.\n",
    "    - 기존에는 규칙을 기반으로 feature를 넣었다. 허나 이러한 접근 방법은 문제가 많다(경우의 수가 무한대이기 때문에, 인간의 손으로 발전 시키기엔 한계가 존재).\n",
    "    \n",
    "    - 해결 방안\n",
    "        - 1. 활용하는 알고리즘에 따라 data를 2~3등분(train/test or train/validation/test) 한다.\n",
    "            - 3등분할 경우의 비율 : 60:20:20, 50:25:25\n",
    "            - 2등분할 경우의 비율 : 70:30, 80:20, 90:10\n",
    "            \n",
    "        - 2. Training\n",
    "            - 피드백을 준다.\n",
    "            \n",
    "        - 3. Validation\n",
    "            - 피드백을 준다.\n",
    "            \n",
    "        - 4. Test\n",
    "            - 피드백을 주지 않는다.\n",
    "            \n",
    "    - 주의할 점\n",
    "        - 분류하려는 label 데이터의 비율을 맞춰야 한다.\n",
    "            - 1,000장의 사진으로 학습한다면 고양이 500장, 개 500장으로 맞춰줘야 한다.\n",
    "            - 학습하는 데이터의 양이 드라마틱하게 차이난다면, 알고리즘에서 내리는 정답은 극단 값으로 갈 수밖에 없다.\n",
    "                - ex) 구글의 이미지 인식 프로그램이 '흑인' 사진을 보고, '고릴라'로 분류한 게 대표적인 케이스\n",
    "                \n",
    "\n",
    "#### 1.4.2. 영상 추천하기\n",
    "    - 가정\n",
    "        - 1. 영상 URL, 각 사용자들이 특정 영상을 조회한 횟수, 조회를 한 시점(시각), 사용자 기본 정보(id, 성별, 나이)\n",
    "        - 2. 성능: 속도, 비용 무제한 -> 오로지 '정확도 높은 추천'에 관심\n",
    "\n",
    "    - 추천 알고리즘\n",
    "        - 1. CF\n",
    "            - Item-based\n",
    "            - User-based\n",
    "                - 사용자 기반 Matrix\n",
    "                - 패턴 : 영상을 본 순서 (본 순서대로 사용자의 패턴을 정의하고 추천)\n",
    "                - 장점 : 아이템 속성의 한계를 뛰어 넘었다.\n",
    "                - 예) 철수가 0 -> 3 -> 4를 보았는데, 영희가 0 -> 3을 보았다면, 그 다음의 영상으로 4번을 추천함\n",
    "                - 단점 : Cost가 많이 든다.\n",
    "\n",
    "            - 2. Contents-based\n",
    "                - 단점\n",
    "                    - Item(Contents) 속성의 한계에서 벗어날 수 없다.\n",
    "                    - 즉, 소비한 콘텐츠의 한계에서 벗언라 수 없다.\n",
    "                    \n",
    "    - Cold start\n",
    "        - 선호에 대한 정보가 없는 경우\n",
    "            - 방법이 없다. 그렇기 때문에 Facebook에서 개인 정보 수집에 열을 올리는 것이다.\n",
    "            - Watcha나 Netflix도 처음 가입한 사람에게 선호도를 물어본다.\n",
    "            - 순서대로 한 사람씩 매치한다.\n",
    "        \n",
    "    - 우리 주변에서 볼 수 있는 인공지능\n",
    "        - 페이스북의 친구 추천\n",
    "        - 월마트 맥주와 기저귀 사례(장바구니 분석)\n",
    "            - 금요일 저녁, 부인이 남편한테 기저귀 부탁 + 남편이 맥주를 사지 않았을까 하는 추측\n",
    "        - 넷플릭스 영화 추천\n",
    "        - 유투브 영상 추천\n",
    "- [CF Algorithm](http://khanrc.tistory.com/entry/%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9CRecommendation-System)\n",
    "\n",
    "\n",
    "## 2. 통계의 기초\n",
    "### 2.1. 평균과 표준편차\n",
    "#### 2.1.1. 대표값\n",
    "    - 평균값(Mean), 중앙값(Median), 최빈값(Mode)\n",
    "    - 최소값, 최대값\n",
    "    \n",
    "#### 2.1.2. 모집단과 표본\n",
    "    - 모집단(Population)\n",
    "        - 우리가 알고 싶은 것\n",
    "- 모평균 : <img src=\"http://latex.codecogs.com/gif.latex?\\mu\" border=\"0\"/>\n",
    "- 모표준편차 : <img src=\"http://latex.codecogs.com/gif.latex?\\\\sigma^2\" border=\"0\"/>\n",
    "- 표준편차 : <img src=\"http://latex.codecogs.com/gif.latex?\\sigma\" border=\"0\"/>,\n",
    "<img src=\"http://latex.codecogs.com/gif.latex?\\\\sqrt{\\sigma^2}\" border=\"0\"/>\n",
    "        - 허나, 모집단은 (현실적으로)측정할 수 없다.\n",
    "\n",
    "    - 표본 (Sample)\n",
    "        - 그래서 Samplig(표본 추출)하는 것이다.\n",
    "        - 고려할 수 있는 부분(성별, 지역, 연령 등)을 다 고려해서 Random Sampling(무작위 추출)을 해야한다.\n",
    "        - Bias(편향)를 고려하고 Sampling해야 한다. Bias된 데이터는 오염되었다.\n",
    "        - 허나, 100% 완벽한 통계는 없다.\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?\\Large&space;x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\" title=\"\\Large x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\" />\n",
    "\n",
    "\\begin{equation} \n",
    "표본 평균 : \\overline{x} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "표본 분산 : s^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "표본 표준 편차 : s, \\sqrt{s^2}\n",
    "\\end{equation}\n",
    "\n",
    "### 2.2. 기술통계와 추론통계\n",
    "#### 2.2.1. 기술통계\n",
    "    - 공식으로 나올 수 있는 통계\n",
    "    - 모집단을 알고 있을 경우\n",
    "\n",
    "#### 2.2.2. 추론통계\n",
    "    - 표본으로 모집단을 추론\n",
    "\n",
    "### 2.3. EDA(탐색적 데이터 분석, Exploratory Data Analysis)\n",
    "    - 목적\n",
    "        - 현황 파악(분석)을 하기 위해 진행한다.\n",
    "\n",
    "    - 기술 통계\n",
    "        - 평균, 중앙값, 최빈값, 최소값, 최대값, 편차, 분산, 표준편차가 있다.\n",
    "#### 2.3.1. Visualization\n",
    "    - 데이터가 분포된 모양을 파악하고 결정\n",
    "        - Boxplot, Scatter Plot, Histogram, Barplot\n",
    "\n",
    "#### 2.3.2. 중심극한정리\n",
    "    - 표본의 수가 충분히 많으면 모든 확률 분포는 정규분포에 수렴하며, 평균은 실제 평균에 점점 가까워진다.\n",
    "        - 그래서 (질 좋은)'Big' data가 중요하다.\n",
    "    - 통계에서는 정규분포를 따른다고 가정하고 문제를 푼다.\n",
    "    \n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/26096850584796AC02\">\n",
    "\n",
    "- 출처 : [나부랭이 수학 블로그](http://math7.tistory.com/16)\n",
    "\n",
    "### 2.4. 점추정과 구간추정\n",
    "    - 추정에는 두 가지 방법이 있다.\n",
    "    \n",
    "#### 2.4.1. 점추정\n",
    "    - point to point(표본 <-> 모집단)\n",
    "    - 표본에서 얻은 값을 모집단 값이라고 추정한다.\n",
    "    \n",
    "#### 2.4.2. 구간추정\n",
    "    - 점추정을 기반으로 한다.\n",
    "    - 평균이 어떠한 구간 사이에 있다고 추정한다.\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/2265A54B54CB52C50B\">\n",
    "\n",
    "- 이미지 출처 : [나부랭이 수학 블로그](http://math7.tistory.com/120)\n",
    "\n",
    "### 2.5. Outlier (이상치)\n",
    "    - Boxplot을 통해 살펴본다.\n",
    "    - 이상치를 포함하여 분석할 경우 결과를 왜곡하기 때문에 처리 후에 분석한다.\n",
    "    \n",
    "    - 이상치 처리 방법\n",
    "        - A. 정상 범위를 넘어가는 이상치를 결측 처리 후 제거 후 분석\n",
    "        - B. 정상 범위를 넘어가는 이상치를 최소/최대값으로 변환 후 분석 \n",
    "\n",
    "    - 처리 기준\n",
    "\n",
    "|종류|예시|해결 방법|\n",
    "|---|---|---|\n",
    "|존재할 수 없는 값|성별 변수에 3|결측처리|\n",
    "|극단적인 값|몸무게 변수에 200|정상 범위 기준 정해서 결측 처리|\n",
    "    \n",
    "\n",
    "    - 정상범위 기준\n",
    "        - 1Q - (1.5 * IQR) ~ 3Q + (1.5 * IQR)\n",
    "\n",
    "            \n",
    "    - 고민\n",
    "        - (실수로 입력된 이상치는 제거하는 게 맞지만 그게 아닌) 이상치는 이상치가 아닐 수 있다.\n",
    "        \n",
    "            - 현실은 이상치에 주목하는데 그걸 날려버릴 필요가 있을까?\n",
    "            - 통계분석을 하지 않는 이상 굳이 할 필요가 있을까?\n",
    "            - Logistic Regression을 시행할 때는 필요\n",
    "             \n",
    "    \n",
    "### 2.6. Missing value (결측치)\n",
    "    - 언어별 분석 방법\n",
    "        - Python\n",
    "            - missing no : 결측치를 시각화해서 보여주는 라이브러리\n",
    "            - data.isnull().sum() : 결측치를 계산해서 보여주는 함수\n",
    "        - R\n",
    "            - VIM : 결측치를 시각화해서 보여주는 라이브러리\n",
    "            - colSums(is.na(data)) : 결측치를 계산해서 보여주는 함수\n",
    "            \n",
    "    - 해결 방안\n",
    "        - 1) Deletion (삭제)\n",
    "            - 결측치가 들어간 Row(데이터) 제거\n",
    "            - 60% 이상의 결측치가 존재한다면 해당 Column(변수) 제거\n",
    "\n",
    "        - 2) Imputation (대체)\n",
    "            - a) knnout\n",
    "            - b) 대표값\n",
    "                - 최빈값\n",
    "                - 평균값\n",
    "\n",
    "\n",
    "## 3. 분석의 종류\n",
    "### 3.1. '차이'를 보는 분석\n",
    "#### 3.1.1. T-test\n",
    "    - 두 집단의 (평균) 차이 비교\n",
    "\n",
    "#### 3.1.2. Anova\n",
    "    - 두 집단 이상의 그룹에 대한 (분산)차이 비교\n",
    "\n",
    "### 3.2. '관계'를 보는 분석\n",
    "#### 3.2.1. Regression (회귀)\n",
    "    - 예측\n",
    "\n",
    "### 3.3. '연관'을 보는 분석\n",
    "#### 3.3.1. 독립성 검정\n",
    "    - ex) 지방선거 : 명목형 변수(지역, 성별)끼리 연관이 있는지 확인\n",
    "    \n",
    "#### 3.3.2. 연관성 분석\n",
    "    - Correlation Analysis\n",
    "        - 변수들끼리의 상관관계가 있는지 분석\n",
    "    - ex) Correlation Matrix, Association Analysis(연관성 분석, 장바구니 분석)\n",
    "\n",
    "\n",
    "## 4. 가설검정\n",
    "### 4.1. Hypothesis\n",
    "    - 귀무가설 (Null Hypothesis, H0)\n",
    "        - 기존에 연구나 조사가 되어진 사실, 알려진 사실\n",
    "        - key point : 같은가?(의미x)\n",
    "        \n",
    "    - 대립가설 (Alternative Hypothesis, H1)\n",
    "        - 연구자가 새롭게 주장하고 싶은 가설, 알고 싶은 것\n",
    "        - key point : 다른가?(의미0)\n",
    "\n",
    "\n",
    "### 4.2. [1종 오류와 2종 오류](https://m.blog.naver.com/PostView.nhn?blogId=hjs8419&logNo=220671013205&proxyReferer=https%3A%2F%2Fwww.google.co.kr%2F)\n",
    "\n",
    "- - -\n",
    "|||차이|영향력|연관성|효과|\n",
    "|---|---|---|---|\n",
    "|${H_0}$||X|X|X|X|\n",
    "|${H_1}$||O|O|O|O|\n",
    "\n",
    "|사실 / 결정|H0 채택|H0 기각|\n",
    "|---|---|---|---|\n",
    "|${H_0}$ True|옳은 결정|1종오류|\n",
    "|${H_1}$ False|2종 오류(β)|옳은 결정|\n",
    "\n",
    "\n",
    "    - 1종 오류(Type1 error): 귀무가설이 참일 때, 귀무가설을 기각하게 되는 오류\n",
    "    - 2종 오류(Type2 error): 대립가설이 참일 때, 대립가설을 기각하게 되는 오류\n",
    "    \n",
    "        - 1종 오류는 사실인 귀무가설을 기각하는 오류를 말하며\n",
    "        - 2종 오류는 허위인 귀무가설을 채택하는 오류를 말한다.\n",
    "\n",
    "    - 1종 오류는 귀무가설이 참인데 이를 기각 하는 것이며, 2종 오류는 귀무가설이 거짓인데, 기각에 실패하는 것이다.\n",
    "        \n",
    "        - 예를 들어, 1종 오류는 불이 안 났는데 경보 알람이 울리는 것이며, 2종 오류는 불이 났는데 경보 알람을 울리는데 실패하는 것이다.\n",
    "        \n",
    "        - 위 두 가지 오류 중에 어떤 오류가 더 심각한 영향을 미칠까?\n",
    "            - (어떤 지표가 더 중요한지는 분야에 따라 다르기 때문이다) 정답은 없지만 보통은 1종 오류라고 이야기한다.\n",
    "            - 예를 들어, 법정에서 피고인을 대상으로 판결을 한다면, 무죄인 사람을 유죄로 판결하면 안 되기 때문에 귀무가설로써 피고인은\n",
    "            무죄라고 가정한다. 하지만 이 참인 귀무가설을 기각하게 되는 오류를 1종 오류라고 부른다. 즉, 무죄를 유죄하라고 오판하는 것이다.\n",
    "        \n",
    "        - 알파(alpha), 신뢰수준(significance level) 그리고 검정력(power)은 1종 오류, 2종 오류와 관련하여 설정하는 것들이다.\n",
    "        - 이 설정에 대한 절대적 기준이 없으며 분석자의 주관에 따라 결정하는 내용이다.\n",
    "        \n",
    "        - 1종 오류가 올라가면 2종 오류는 내려가고, 1종 오류가 내려가면 2종 오류가 올라간다. \n",
    "        - 보통 1종 오류를 고정시키고, 2종 오류를 줄이는 방법을 생각한다.\n",
    "            - 2종 오류를 줄이고 싶으면 표본수를 늘리면 된다.\n",
    "\n",
    "\n",
    "### 4.3. 유의수준/유의확률\n",
    "\n",
    "- __신뢰수준__\n",
    "    - 가설을 검정할 때 얼마나 빡빡하게 검정할 것인지를 결정하는 수준을 말한다.\n",
    "    - 연구활동은 99%, 일반적으로는 95%, 단순설문조사는 90% 정도의 신뢰수준을 사용한다.<br>\n",
    "    <br>\n",
    "- __유의수준(significance level, α)__ : 1종 오류의 위험성을 부담할 최대 확률\n",
    "    - 유의수준 = 1 - 신뢰수준\n",
    "    - 가설을 검정할 때, \"이 정도까지 벗어나면 귀무가설이 오류라고 인정하겠다\"하는 수준을 말한다.\n",
    "        - 보통 0.05(5%)로 잡는다(평균과 평균으로부터 상, 하한 구간의 경계선을 95%로 정해 놓는다).\n",
    "        - 관측치가 이 신뢰구간 안에 포함되는지 본다.<br>\n",
    "        <br>\n",
    "- __기각역__ : 가설검정에서 귀무가설이 기각되는 검정 통계량의 영역\n",
    "    - 가설이 통계적으로 맞았는지 틀렸는지 알려주는 기준(값)\n",
    "    - 확률분포에서 귀무가설을 기각하는 영역을 말한다.\n",
    "    - 기각역에 검정통계량이 위치하면 귀무가설을 기각한다.\n",
    "    - 양측검정인 경우 기각역은 유의수준 / 2 이고, 단측검정인 경우 기각역은 유의수준과 같다.<br>\n",
    "    <br>\n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/2376B13458D9C13F29\">\n",
    "- __임계치__ : 신뢰구간에서 기각역으로 넘어가는 기준이 되는 x값을 말한다.\n",
    "\n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/222B073358D9C2BD09\">\n",
    "\n",
    "#### 검정통계량이 어디에 위치하느냐에 따라 귀무가설을 기각하거나 기각하지 않는다.\n",
    "\n",
    "- __검정통계량__ : 통계적 가설을 검정할 목적으로 사용되는 통계량, 수집된 표본을 통해 귀무가설의 옳고 그름을 판단하는 기준이 되는 값 또는 통계량\n",
    "    - 실제 데이터(수치)로 얻은 값\n",
    "    - 가설을 검정하기 위한 기준으로 사용하는 값(t값 등)을 말한다.\n",
    "    - 검정통계량이 확률분포 상에 어디에 위치하는지에 따라 귀무가설을 기각하거나 기각하지 않는다.\n",
    "    - ex) 새로 개발한 치킨 100마리의 평균 칼로리값 (표준화를 시켜서 계산을 해야 함)\n",
    "    \n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/217ABA3858D9CB502E\"><br>\n",
    "<br>\n",
    "- __유의확률(significance probability, p-value)__ : 귀무가설이 맞다고 가정할 때 얻은 결과보다 극단적인 결과가 실제로 관측될 확률, 검정통계량을 통해 얻어지는 확률\n",
    "    - 자유도를 고려했을 때 검정통계량에 대한 확률을 말한다. (귀무가설의 신뢰구간을 벗어나는 확률)\n",
    "    - 기각역보다 유의확률이 작아야 귀무가설을 기각할 수 있다.\n",
    "    - 검정에서 쓰이는 분포에서 기각역 이상의 영역이 유의확률\n",
    "    <br>\n",
    "<br>\n",
    "- __자유도__\n",
    "    - x값이 가질 수 있는 값의 범위를 말한다.\n",
    "    - 자유도가 주어지지 않는 경우, 자유도= 표본수(n) - 1\n",
    "\n",
    "#### 결국, 유의수준과 유의확률 밖에 보지 않는다. 그리고 유의수준은 임의(0.05)로 정한다\n",
    "\n",
    "\n",
    "### 4.4. 가설검정 (0가설 검정)\n",
    "    - 모든 분석은 '가설검정'을 거친다.\n",
    "        - H0 : H1 = H2\n",
    "        - H1 : H1 != H2\n",
    "    - 달라야지 의미가 있다. 같은 건 의미가 없다.\n",
    "    \n",
    "    - 유의수준과 유의확률(p-value)를 이용하여 가설검정을 한다.\n",
    "    - 설명할 때, \"유의수준(알파값)을 0.05로 설정했더니 결과가 이렇게 나왔다.\"\n",
    "        - 유의수준 > 유의확률\n",
    "            - 귀무가설 채택, 대립가설 기각\n",
    "            - 통계적으로 유의하지 않다.\n",
    "            \n",
    "        - 유의수준 < 유의확률\n",
    "            - 대립가설 채택, 귀무가설 기각\n",
    "            - 통계적으로 유의하다. 유의한 차이가 있다.\n",
    "    \n",
    "    - 귀무가설: 기존에 알고 있던 사실 (통계적으로 균질한 것)\n",
    "    - 대립가설: 내가 주장하고 싶은 것 (통계적으로 균질하지 않은 것)\n",
    "        - 유의하다 = 의미가 있다.\n",
    "        - 내가 주장하는 게 맞으려면 대립가설이 맞아야 함.\n",
    "    \n",
    "    - 예시) 올리브영에서 남자 고객을 늘리기 위해 특정 프로모션(마케팅)을 실시했는데 효과를 어떻게 측정할 수 있을까?\n",
    "        - 연령대로 나누고(20/30대), 성별(남/녀)로 나눠서 T-test로 검정한다(비교 집단이 2개 이상일 경우, Anova 검정)\n",
    "            - 남 > 여 : O\n",
    "            - 남 = 여 : X\n",
    "            - 남 < 여 : XX\n",
    "\n",
    "#### 귀무가설 채택, 대립가설 기각\n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/2363874A58D9E26403\">\n",
    "\n",
    "#### 귀무가설 기각, 대립가설 채택\n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/2770224E58D9E5C407\">\n",
    "\n",
    "#### 표본에 따라 귀무가설이 기각되기도 하고 기각되지 않을 수 있으므로 표본은 모집단을 대표할 수 있도록 잘 샘플링 하는 것이 매우 중요하다.\n",
    "\n",
    "\n",
    "### 4.5. 우리가 이렇게 삽질하는 이유 : 'Random Sampling' 때문이다.\n",
    "    - Random Sampling을 하면 Error는 필연적으로 생길 수밖에 없다.\n",
    "    - Random에 의한 우연인지, 실제 효과인지 알 방법이 없다.\n",
    "        - 그렇기 때문에 검정을 해야 한다.\n",
    "\n",
    "### 4.6. 정리\n",
    "- ${H_0}$(귀무가설)\n",
    "- ${H_1}$(대립가설)\n",
    "\n",
    "|||차이|영향력|연관성|효과|\n",
    "|---|---|---|---|\n",
    "|${H_0}$||X|X|X|X|\n",
    "|${H_1}$||O|O|O|O|\n",
    "\n",
    "    - 대립가설과 귀무가설은 목적성과는 별개로 설정되어야 한다.\n",
    "        - 내가 원하는 주장이라고 해도 (대립가설이 아니라) 귀무가설이 될 수 있다.\n",
    "        - 쉽게 말하면, 귀무가설은 세상이 생각하는 상식과도 같다.\n",
    "\n",
    "    - 검정통계량\n",
    "        - 실제로 관측된 값\n",
    "\n",
    "    - 기준\n",
    "        - 유의수준(α) : 일반적으로 0.05(5%)\n",
    "            - 95%의 신뢰구간\n",
    "\n",
    "    - 내가 맞다는 걸 주장하고 싶으면, 바로 검증하기 전에 내 반대 주장의 확률을 살펴본다,\n",
    "\n",
    "\n",
    "### 4-7. 퀴즈\n",
    "    - 새로 개발한 두통약의 효과 통계적으로 검증하기\n",
    "        - 두통 완화 효과는 뇌파의 강도로 측정 가능하다고 가정\n",
    "        - 예산 편성, 평소 두통이 심하다고 검증된 100명, 나이와 성별, 생활 환경 등이 비슷한 환자\n",
    "\n",
    "    - 1) 구체적으로 어떻게 해야 원하는 결과를 검증할 수 있을까?\n",
    "        - 우선 효과를 정의해야 한다. 무엇을 효과라고 할 것인가?\n",
    "            - 뇌파의 측정값이 줄어드는지 검증\n",
    "            \n",
    "        - 100명의 data (sampling)\n",
    "            - 1) Between(집단 간)\n",
    "                - 랜덤하게 2 집단으로 나눈다.\n",
    "                - 처치한 집단, 처치하지 않은 집단의 뇌파 평균\n",
    "                - 평균이 차이가 있는지 0가설 검정 (통계적으로 확인)\n",
    "                - 0가설(귀무가설) : 두 집단 간의 차이가 없다.\n",
    "                - 대립가설 : 두 집단 간의 차이가 있다.\n",
    "                \n",
    "            - 2) Within(집단 내)\n",
    "                - 1차 투입\n",
    "                - 2차 투입\n",
    "                - 3차 투입\n",
    "                - 평균, 투약했을 때와 투약하지 않았을 때의 차이를 검증\n",
    "                - 0가설은 똑같지만, 같은 집단 내에 반복되게 노출시킨다.\n",
    "\n",
    "    - 2) 이때의 0가설은 무엇인가?\n",
    "        - 두 집단 간의 차이가 없다.\n",
    "\n",
    "## 5. 집단간 차이 검증하기 (Z, T, F)\n",
    "   obj : 집단간 차이는 통계적으로 어떻게 검증하는가?\n",
    "   \n",
    "### 5.1. 표준화와 Z분포\n",
    "#### 5.1.1. 표준화(Standardization)\n",
    "    - 집단끼리 비교하고 싶은데, 절대적인 수치로는 비교할 수 없다.\n",
    "    - 왜냐하면 집단에서 의미하는 단위의 의미가 다르기 때문이다. 단위 통일이 필요하다.\n",
    "           - 그래서 단위를 σ로 맞추는 것이다.\n",
    "           - 평균으로부터 떨어진 거리\n",
    "           - 위치에 대한 비교가 가능해진다.\n",
    "\n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/25380C3F5430F1B827\">\n",
    "\n",
    "#### 5.1.2. Z분포\n",
    "    - 상대적인 비교를(확률적으로 이야기하기) 위해서, Z를 쓴다.\n",
    "    - 모든 수치를 z로 바꾸면, z분포이다.\n",
    "       - 표준정규분포\n",
    "           - 확률적으로 평균을 기준으로 분산에 따라 분포\n",
    "           - 평균(기대값)은 항상 0이고, 분포는 1, 넓이는 1을 갖는다.\n",
    "\n",
    "    - ex) 우리나라 20대 성인의 평균키는 173cm 이며, 표준편차는 5일 경우. 내 키는 상위 몇%에 속하는지 직접 계산하기.\n",
    "        - Z = x - μ / σ\n",
    "            - μ = 173, σ = 5\n",
    "            - (174-173) / 5 = 0.2\n",
    "\n",
    "       \n",
    "#### 5.1.3. 신뢰구간\n",
    "   \n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/2158AE4E546AD9C72C\">\n",
    "\n",
    "\n",
    "#### 5.1.4. 퀴즈\n",
    "    - 토익 문제집 효과 검증하기\n",
    "       - 토익 문제지를 새로 만들었는데, 이 문제집이 토익 점수를 올리는데 효과가 있는지 알아보고 싶다.\n",
    "\n",
    "       - 평가기준\n",
    "           1. 0가설과 효과에 대한 논의\n",
    "           2. 샘플링을 어떻게 할 것인가?\n",
    "           3. 각 방법의 장단점을 어떻게 정의할 것인가?\n",
    "\n",
    "       - 실험설계\n",
    "           - 1. 0가설과 효과값 정의\n",
    "               - 경향성을 논의하기 위해 평균값을 이야기 해야 한다.\n",
    "               - 귀무가설\n",
    "                   - H0 = H1\n",
    "                   - 처치 전후의 평균 차이가 없다.\n",
    "                   - 새로 만든 토익 문제지는 점수를 올리는데 효과가 없다.\n",
    "\n",
    "               - 대립가설\n",
    "                   - H0 != H1\n",
    "                   - 처치 전후의 평균 차이가 있다.\n",
    "                   - 새로 만든 토익 문제지는 점수를 올리는데 효과가 있다.\n",
    "\n",
    "               - 효과값 : 주관적인 부분\n",
    "\n",
    "           - 2. Sampling\n",
    "               - 100명 모은다 치자.\n",
    "                   - 정의하기 쉽게 비슷한 성질로 sampling 한다.\n",
    "                   - 비슷한 점수, 연령대\n",
    "\n",
    "           - 3. 분석 방법 정의\n",
    "               - 집단 내 ... 제약회사, IT회사(A/B Test)\n",
    "                   - 장점 : 추이(trend)를 볼 수 있다.\n",
    "                   - 단점 : 학습(learning)효과를 배제할 수 없음(Overfitting)\n",
    "\n",
    "                       - 천장효과의 문제\n",
    "                       - n번 마다 결과값이 들쑥날쑥할 수 있음\n",
    "\n",
    "                   - 같은 집단 내에 반복 노출 시킨다.\n",
    "                   - 모의고사 평균 점수를 확인한다.\n",
    "\n",
    "               - 집단 간 ... 실험실\n",
    "                   - 장점 : 대조군을 쉽게 비교할 수 있다.\n",
    "                   - 단점 : 통제(Control)가 어렵고, 샘플링의 편향성(bias)이 존재할 수 있다.\n",
    "                   - 랜덤하게 2집단으로 나눈다.\n",
    "                       - 새로운 문제지를 푼 집단과 풀지 않은 집단\n",
    "\n",
    "                   - 모의고사 평균 점수 확인한다.\n",
    "\n",
    "        - 같은 데이터를 갖고도 분석 방법에 따라 결과가 다르니까 방법을 잘 정의해야한다. \n",
    "         \n",
    "   \n",
    "### 5.2. T분포\n",
    "#### 5.2.1. 가설 검정을 반복할 때의 문제, '1종 오류'\n",
    "    - (가설 검정할 때 하는) 우리의 가정\n",
    "        - (5%는 현실에서 잘 안 일어나니까) 구간을 95%로 정해놓고 5% 이하일 때만 귀무가설을 기각한다.\n",
    "        - (실제 우리의 생활에서 5%라는 것은 드물지만) 반드시 일어나는 확률 중 하나이다.\n",
    "        \n",
    "        - 즉, 우리는 5%를 우연이라고 치고 귀무가설을 기각 해버렸지만, 실제로는 우연이 아니라 실제로 그럴 수도 있을 가능성이 항상 존재한다.\n",
    "        \n",
    "        - 귀무가설을 기각하면 안 되는 경우인데 기각한 오류(또는 확률), 통계학에서는 이것을 1종 오류라고 부른다.\n",
    "        - 우리가 어떠한 통계적 가설검정을 하면, 우리가 정한 구간에 따라 1종 오류가 자동으로 결정되며, 검증을 반복하면 에러가 누적된다.\n",
    "#### 5.2.2. Solution 1 : T-test\n",
    "    - 방금 살펴본 1종 오류 외에도 모집단을 모르는 이유 때문에 z분석은 실생활에서 크게 사용되지 않는다.\n",
    "    - Sample을 가지고 모집단의 차이를 유추하는, 자유도에 따라 분포 모양이 변화하는 t 분포를 이용하는 분석을 쓴다.\n",
    "    - T-test는 두 집단의 차이가 있는지 검증할 때 사용한다.\n",
    "\n",
    "#### 5.2.3. 차이 정의 : 집단 내 vs 집단 간\n",
    "    - T-test가 가장 많이 쓰이는 곳은 '집단 간'차이 분석할 때이다.\n",
    "    - ex 1) 새로 개발한 약 테스트\n",
    "        - 집단 내 설계\n",
    "        - 병원에서 개발한 시약이 효과가 있는지 확인하기 위해서, 총 10명의 환자에게 3회에 걸쳐 약을 먹이고, 먹고 난 다음에 병세를 체크했다.\n",
    "        - 약을 복용함에 따라 병세가 호전되었다면, 이것은 효과가 있는 약이라고 얘기할 수 있다.\n",
    "        \n",
    "        - 이러한 실험 방법을 '집단 내 설계'라고 부르며, 1개의 동일한 집단에 반복해서 측정한다고 해서, '반복 측정 설계'라고도 부른다.\n",
    "        - 이때는 반복 측정 T검정이라는 분석 방법을 쓰면 된다.\n",
    "        \n",
    "    - ex 2) 새로 만든 토익 문제지 테스트\n",
    "        - 집단 간 설계\n",
    "            - 토익 점수가 비슷한 사람 100명을 모집해서, 2개의 그룹으로 나눈다.\n",
    "            - 첫번째 집단에는 새로 만든 토익문제지를 풀게하고, 두번째 집단은 그냥 원래 하던대로 하게 둔다.\n",
    "            - 특정 기간이 지난 후에, 각 집단의 평균을 비교했을 때 새로운 문제지로 푼 집단의 토익점수가 더 높으면 이 문제지가 토익 점수를 높이는 효과가 있다고 말할 수 있다.\n",
    "            \n",
    "            \n",
    "    - 2번의 접근 방법은 우리가 상식적으로 생각하는 '실험'에 가장 가깝다.\n",
    "    - 즉, 뭔가 처치를 하는 <실험군>과 아무 것도 하지 않고 두는 <대조군>을 두고, '처치 전후의 평균값 차이를 비교'하는 것이다.\n",
    "    - 이러한 설계를 '집단 간 설계'라고 부르며, 이때는 '독립 집단 T검정'을 써야 한다.\n",
    "        \n",
    "\n",
    "#### 5.2.4. T-test 해석\n",
    "\n",
    "    - (분산) 동질성 검정\n",
    "        - 같은 결과라도 분산이 다르면 분포가 달라진다.\n",
    "            - 두 집단의 분산이 같은 경우\n",
    "            - 두 집단의 분산이 다른 경우\n",
    "\n",
    "        - 똑같은 평균값이라고 해도 T-test 값은 다르다.\n",
    "            - 집단 간 비교는 분산(분포가 벌어진 정도)을 생각해야 한다.\n",
    "\n",
    "        - 두 집단의 분산이 어느 정도 동일해야 한다.\n",
    "\n",
    "        - α(유의수준) < p-value(유의확률)\n",
    "            - 두 집단간 통계적으로 차이가 없다.\n",
    "            - 대립가설 기각\n",
    "\n",
    "        - α > p-value\n",
    "            - 두 집단간 통계저긍로 차이가 있다.\n",
    "            - 귀무가설 기각\n",
    "            \n",
    "|사실 / 결정| H0 채택|H0 기각|\n",
    "|---------|----------|------|\n",
    "|*H0 True*|옳은 결정|1종 오류(α)|\n",
    "|*H0 False*|2종 오류(β)|옳은결정|\n",
    "\n",
    "    - 1종 오류(Type1 error): 귀무가설이 참일 때, 귀무가설을 기각하게 되는 오류\n",
    "        - 2종 오류(Type2 error): 대립가설이 참일 때, 대립가설을 기각하게 되는 오류\n",
    "            - 1종 오류는 사실인 귀무가설을 기각하는 오류를 말하며\n",
    "            - 2종 오류는 허위인 귀무가설을 채택하는 오류를 말한다.\n",
    "\n",
    "    - 표본의 수(n)가 30을 넘으면, 표준정규분포와 동일하다고 본다.\n",
    "        - 정규화가 되었다고 본다.\n",
    "        - 편포여도, 샘플 수가 많아지면 정규화가 됨\n",
    "\n",
    "    - 데이터의 속성부터 파악해야 한다. 알고리즘은 제일 나중이다.\n",
    "\n",
    "\n",
    "#### 5.2.5. T-test의 한계점\n",
    "     - 접근 방법이 z분석과 동일하기 때문에 1종 오류를 극복하지 못했다.\n",
    "     - \"두 집단간의 차이가 있는지 통계적으로 검증하시오\"\n",
    "         - 두 집단 간 차이가 있는지 검증하기 위해 귀무가설을 '두 집단 간 차이가 없다'로 가정한 분폴르 본다.\n",
    "         - 집단간 차이가 있는 관측치가 나올 확률을 계산한다.\n",
    "         - 해당 확률이 너무 낮으면(통상 5% 이하) 차이가 없다는 귀무가설을 기각하고 대립 가설을 채택한다.   \n",
    "   \n",
    "### 5.3. F검정(Anova)\n",
    "    - 여태까지 집단간 차이를 '평균값'의 차이로 정의하였다.\n",
    "    - 평균 말고 분포의 특성을 나타내는 수치가 하나 더 있는데 그게 바로 '분산'(분포가 벌어진 정도)이다.\n",
    "    \n",
    "    - 집단 간 비교의 끝판왕이라고 생각하면 된다.\n",
    "    - 세 개 이상의 집단을 비교할 때, 사용하는데 평균으로 비교하는 게 아니라 분산으로 비교한다.\n",
    "    \n",
    "    - 수식\n",
    "        - H0 : A = B = C\n",
    "        - H1 : A, B, C의 분산 중 하나라도 차이가 있다.\n",
    "\n",
    "    - F 검증의 한계\n",
    "        - 집단 간 차이가 있는지 없는지를 알려주지만, 차이가 있다면 어떤 것에서 차이가 있는지 알려주지 않는다.\n",
    "        \n",
    "    - F 검정을 통해 유의미한 차이가 있다면, T-test로 하나씩 잡아야 한다.\n",
    "    \n",
    "### 5.4. 여러 가정들\n",
    "    - 1) 독립성\n",
    "    - 2) 정규성\n",
    "        - 샘플 수가 늘어나면 자동으로 정규분포가 된다.\n",
    "        - n이 30개\n",
    "    - 3) 등분산성\n",
    "    \n",
    "    \n",
    "## 6. 상관과 회귀\n",
    "- 데이터의 유사성은 어떻게 따지는가?\n",
    "- 예측은 어떻게 하는가?\n",
    "\n",
    "\n",
    "### 6.1. Part 1. 행동 패턴 찾기 : 상관\n",
    "#### 6.1.1. 설명\n",
    "- 통계에서는\n",
    "    - 무엇을 하였는지 알고있다. = 데이터의 패턴이나 추이를 알고있다.\n",
    "    - 데이터의 패턴이나 추이를 알게된다는 것은 그 다음을 예측할수 있다는 뜻이된다.\n",
    "        - 예를 들어, 시간에 따라 증가하는 패턴이 있고, 특정 단위 시간당 증가량을 수학적으로 알고 있다면?\n",
    "        - 아마....다음시간 에도 그럴꺼야 라고 추측할 수 있게 된다.\n",
    "        - 반대로 감소하는 경우에도 마찬가지.\n",
    "    - 즉, 데이터가 변화하는 패턴을 알 수 있으면, 유사한 정도를 알 수 있게 된다.\n",
    "    - 더불어 관계성을 알았기 때문에, 앞으로 어떻게 변할 것인지 예측도 가능해짐 <br>\n",
    "    <br>\n",
    "- 이렇게 지난 데이터의 패턴을 파악해서, 그 패턴이 계속 유지된다는 가정 하에 미래를 예측하는 분석을 회귀분석이라고 한다.\n",
    "    - 데이터로 유사성을 알아보는데서 출발했는데 자동으로 예측도 가능해짐.\n",
    "        - (1) 비슷하다를 정의한다 = 패턴을 본다 = 상관분석(pearson r)\n",
    "        - (2) 만약 위 (1)에 의하여 집단간 패턴을 알게된다면 앞으로 어떻게 변화할지 예측도 가능! = 회귀분석 <br>\n",
    "    <br>\n",
    "- 상관분석\n",
    "    - 두 데이터 간의 연관성을 따진다.\n",
    "    - 상관하고 회귀는 떨어질 수 없다.\n",
    "    - perason r(상관) = (같이 변하는 정도) / (서로 각기 변하는 정도) = (공변량) / (변량) <br>\n",
    "    <br>\n",
    "- 공변량(=공분산)\n",
    "    - (분산, 변량)각자 서로 변화하는 양이 있고, (공분산, 공변량)같이 변하는 패턴이 있다.\n",
    "    - 그걸 보고 유사한 정도를 알 수 있다.\n",
    "    - 상관 값은 (최소)-1 ~ 1(최대)에서 존재\n",
    "    - r = 1이면, 동일하다. y = x\n",
    "\n",
    "#### 6.1.2. 퀴즈\n",
    "- 데이터에 따른 상관값\n",
    "    - 두 집단 X와 Y의 상관을 구하자.\n",
    "    - 이때, X = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] <br>\n",
    "    <br>\n",
    "    - r(xy) = 1 이라면, y의 값은?\n",
    "    - r(xy) = 0 이라면, y의 값은?\n",
    "    - r(xy) = -1 이라면, y의 값은? <br>\n",
    "    <br>\n",
    "- 상관 관계 파악 및 그래프 그려보기\n",
    "    - r = -1이면 두 집단 관계성 그래프는 어떤 형태를 띌까?\n",
    "    - r = -1과 r = 0 중에 두 집단의 유사성이 높은쪽은 어느 쪽 값인가?\n",
    "- R\n",
    "    - r에서 +, - 는 방향성일 뿐이다.\n",
    "    - 0.4 이상, 양의 상관관계 \n",
    "    - 0.7 이상, 강한 양의 상관관계\n",
    "- R^2\n",
    "\n",
    "#### 6.1.3. 상관관계와 인과관계\n",
    "- [초콜릿과 노벨상](http://www.dt.co.kr/contents.html?article_no=2014111902102251607001)\n",
    "    - 유사성은 데이터의 패턴만 논한다.\n",
    "    - 상관관계와 인과관계를 혼동하지 말자<br>\n",
    "    <br>\n",
    "- [백신의 효과](http://www.nocutnews.co.kr/news/4389170)\n",
    "    - 상관값을 가지고, 인과를 논하면 안 된다.\n",
    "        - 백신의 효과를 검증하려면 인과관계를 봐야한다.\n",
    "        - 백신의 효과를 상관으로 해석하면 안 된다.<br>\n",
    "    <br>\n",
    "- 이 분석을 왜 하는가?\n",
    "    - 상관분석의 목적은 두 데이터의 유사성을 따지는 것이다.\n",
    "        - 상관관계는 데이터의 유사성을 보는 것.\n",
    "        - 유사성은 인과관계를 따지는 게 아니다.<br>\n",
    "        <br>\n",
    "- 선형의 관계에서만 사용한다.\n",
    "    - 사용자 추천\n",
    "        - 유사도 만들기(계산)\n",
    "            - 피어슨 상관관계\n",
    "                - 현실에서는 이 방법을 잘 안쓴다.\n",
    "                - 이건 선형의 관계에서만 사용할 수 있기에<br>\n",
    "                <br>\n",
    "                \n",
    "### 6.2. Part 2. 예측 : 회귀분석\n",
    "#### 6.2.1. 설명\n",
    "- 회귀 : 돌아오다\n",
    "    - 어디로? : 평균으로 돌아간다.<br>\n",
    "    <br>\n",
    "- 통계는 '귀납법'이다.\n",
    "    - 데이터의 분포를 보고 선을 긋는 것(귀납법)이지,\n",
    "    - 선을 긋고 데이터를 찾는 건 아니다(연역법).\n",
    "    \n",
    "#### 6.2.2. 최적화\n",
    "- 패턴을 가장 잘 설명하는 녀석을 찾자 : data-fitting, modeling의 의미\n",
    "    - 회귀분석 = data-fitting = modeling\n",
    "    - LMS 알고리즘\n",
    "        - 오차 : 최소자승법(Least Mean Square, Mean Squared Error)\n",
    "\n",
    "    - RMSE(Root Mean Squared Error)\n",
    "        - 루트를 씌워줌으로써 값을 작게 만들어줌\n",
    "\n",
    "#### 6.2.3. 회귀선 검정\n",
    "- R =  피어슨 R\n",
    "- sig. = p-value\n",
    "\n",
    "#### 6.2.4. 단순 회귀 vs. 다중 회귀\n",
    "- 다중공선성\n",
    "#### 6.2.5. 선형 회귀 vs. 비선형 회귀 \n",
    "#### 6.2.6. 로지스틱 회귀\n",
    "- 특징\n",
    "    - 결과값이 binary(즉 0또는 1)이 나옴.\n",
    "    - 즉, 데이터를 분류할 때 사용\n",
    "        - 남자 vs. 여자 같은 데이터를 주고 어떤 데이터가 들어오면 '남자/여자' 이런 식으로 예측\n",
    "        - 이러한 분석을 위해 '카이제곱 분포'와 '우도'라는 개념을 이용하\n",
    "- - -\n",
    "#### Overshooting\n",
    "- 데이터의 문제\n",
    "    - cost가 너무 커서 그렇다.\n",
    "    - rescaling : mean max scaling, 표준화\n",
    "#### Machine Learning\n",
    "- 머신러닝\n",
    "    - 목적\n",
    "        - '분류'\n",
    "        - '예측'\n",
    "    - 방법\n",
    "        - 지도학습\n",
    "            - 현업에서는 잘 못 쓴다. 정답이 없기에.\n",
    "        - 비지도학습\n",
    "            - 단점 : 우리의 목적대로 잘 되었느냐? 알 수 없다. 정답이 없으니까. 정답을 모델에 안 알려줬기 때문에. 머신은 벡터 공간만으로 수학적으로 계산할 수 밖에 없다.\n",
    "            \n",
    "- 중요한 건\n",
    "    - 요구 목적 정의\n",
    "    - 데이터 확인\n",
    "    - 알고리즘 선택\n",
    "\n",
    "- - -\n",
    "    \n",
    "## 7. 변수척도\n",
    "### 7.1. Discrete (셀 수 있는)\n",
    "#### 1) 명목형 변수\n",
    "    - Category : 성별, 지역, 정당 ...\n",
    "    - 우위가 없음\n",
    "    \n",
    "#### 2) 순서형 변수\n",
    "    - 서열 : 신용등급, 순위 ...\n",
    "    - 우위가 있음\n",
    "\n",
    "### 7.2. Continuous (셀 수 없는)\n",
    "\n",
    "#### 3) 연속형 변수\n",
    "    - 구간으로 본다.\n",
    "\n",
    "### 7.3. 요리와 데이터\n",
    "- 건강한 요리 : 재료 + 영양소 (파악) ... 조화로운 요리법\n",
    "- 건강한 분석 : 데이터 + 정보량 (파악) ... 조화로운 분석법\n",
    "    - 각 변수에 맞는 분석 방법이 있다\n",
    "        - 변수의 특성(척도)에 따라 분석 방법이 정해진다.\n",
    "- 명목형 변수 : A\n",
    "- 순서형 변수 : A + B\n",
    "- 연속형 변수 : A + B + C\n",
    "- 연속형 변수에서 순서/명목형 변수로 갈 수 있고, 순서형 변수에서 명목형 변수로 갈 수 있다. 허나 반대는 불가능하다.\n",
    "    - ABC -> AB or A / AB -> A : O\n",
    "    - A -> AB or ABC / AB -> ABC : X \n",
    "    \n",
    "\n",
    "### 7.4. Trade-Off\n",
    "- Trade off란?\n",
    "    - \n",
    "- T-test / Anova / Regression / Logistic\n",
    "    - ?\n",
    "    - 차이 : T-test / Anova\n",
    "    - 관계 : Regression\n",
    "    - 연관 : 독립성 검정\n",
    "    - Logistic : 관계를 보는 분석(obj: 분류)\n",
    "\n",
    "\n",
    "### 7.5. Random Variable (확률변수)\n",
    "- 확률 실험 : 모든 게 확률이다.\n",
    "    - Sample Space(표본 공간) : 확률실험에서 나올 수 있는 가능한 모든 결과의 집합이 표본공간\n",
    "        - ex) 동전던지기 -> '앞/뒤' <br>\n",
    "    <br>\n",
    "    - 결과\n",
    "        - 동전 앞, 뒤 / 주사위 1~6 : Discrete R.V\n",
    "        - 시속 30km/h : Continuous R.V <br>\n",
    "        <br>\n",
    "- ex) 마케팅\n",
    "    - 메케팅의 효과(y, output) : R.V (0)\n",
    "        - 종속변수\n",
    "    - 마케팅 조건(x, input) : R.V (X)\n",
    "        - 독립변수\n",
    "        - 인위적으로 조정할 수 있는 변수들\n",
    "- 확률 분포 -> 정규분포 ?\n",
    "- Probability Distribution ?\n",
    "- **데이터(재료)에 따라서 방법론(요리법)이 달라진다.**\n",
    "    - 확률 변수와 확률 분포에 따라서 분석법이 정해진다.\n",
    "    - 이항분포 / 다항분포 / 정규분포 ...\n",
    "        - 동전의 앞,뒤 ... 이항분포\n",
    "        - 주사위 1~6 ... 다항분포\n",
    "        - y값에 따라 이항/다항 분포로 나뉜다.\n",
    "    - 정규분포\n",
    "        - 평균을 기준으로 데이터가 분포해 있음을 가정함\n",
    "\n",
    "|X (R.V x)|Y(R.V o)|Test|\n",
    "|--------|----------|------|\n",
    "|명목형 변수|연속형 변수|T_test, Anova|\n",
    "|연속형 변수|연속형 변수|Regression|\n",
    "|연속형 변수|등급형 변수|Logistic Regression|\n",
    "|명목형 변수|명목형 변수|Chi-squared test|\n",
    "\n",
    "- 위에 그래프 해설\n",
    "    - x는 독립변수(input), y는 종속변수(output, random variable)\n",
    "    - 1) 명목 / 연속 : T-test, Anova\n",
    "        - 성별에 따른 매출액의 차이(집단에 따라서 연속형 변수의 차이가 있는지 ... 모든 변수가 들어갈 수 있음)\n",
    "    - 2) 연속 / 연속 : Regression\n",
    "        - 마케팅 비용을 쏟아 부었을 때의 효과 측정\n",
    "    - 3) 연속 / 등급 : Logistic Regression\n",
    "        - 신용 등급, 암환자 예측\n",
    "    - 4) 명목 / 명목 : Chi-squared test\n",
    "        - 특정 지역과 정당이 서로 연관성이 있는지 (지방선거의 지역색, 지역감정을 규명)\n",
    "\n",
    "- **통계: 규칙을 정하자. vs. 머신러닝: 학습을 해서 규명하자.**\n",
    "- 변수를 봤을 때, 척도를 보면서 어떤 걸 보면서 분석하면 될 것이다.\n",
    "\n",
    "- - -\n",
    "\n",
    "## 8. 기본제약 과정\n",
    "### 8.1. T-test / Anova / Regression\n",
    "- Linear Model(선형 모형) : 데이터를 선으로 표현할 수 있느냐?\n",
    "    - x (독립)변수는 고려할 필요가 없다.\n",
    "    - 우리의 목적은 __y변수 (random variable, 확률변수)__ ... 얘만 생각한다\n",
    "\n",
    "### 8.2.  세 가지의 기본 원칙\n",
    "- 전제조건\n",
    "    - __y변수는 Continuous(연속형)__\n",
    "    - __모든 통계는 정규분포를 가정하고 시작한다__\n",
    "    - __추정__\n",
    "        - Sample을 통해 Population을 추정한다.\n",
    "        - 추정에는 점추정과 구간추정이 있다.\n",
    "        - 구간 추정에는 신뢰구간이 있음.<br>\n",
    "<br>\n",
    "- 기본적으로 세 가지만 따지게 된다\n",
    "    - __정규성 / 등분산성 / 독립성__\n",
    "\n",
    "\n",
    "\n",
    "#### 8.2.1. 정규성\n",
    "- obj : __구간 추정을 잘 하기 위해서__\n",
    "- __(continuous) y변수가 정규분포를 따르는가__\n",
    "    - 모든 통계 모형들이 정규분포를 가정하고 만들었다.\n",
    "        - why : (결과를 추정하기 어렵기 때문에) 이런 가정을 한 것이다.\n",
    "        - obj : 통계 분석은 표본을 통해서 모집단을 추정하는 것<br>\n",
    "        <br>\n",
    "    - 점추정(point estimation)과 구간추정(interval estimation)\n",
    "        - __점추정 : 하나의 점(수치)으로 값을 표현__\n",
    "            - 값을 신뢰하기에는 (모집단에 비해)표본의 수가 적고, 표본에는 항상 오차가 존재한다.\n",
    "            - 그러므로 점추정은 그 특성상 값을 신뢰하기 어렵다.<br>\n",
    "            <br>\n",
    "        - __구간추정 : 점 추정치를 중심으로 일정 구간을 만드는 것__\n",
    "            - 통계에는 구간 추정이 주를 이루는데, __신뢰구간__이 필요하다.\n",
    "            - __구간추정이라고 해서 100% 신뢰할 수 있는 것은 아니다.__\n",
    "            - 경우에 따라서는 구간추정치 안에 모수가 포함되지 않을 가능성도 항상 존재한다.\n",
    "            - 그리고 구간추정은 점추정에 비해 신뢰도가 확실히 높다고 할 수 있지만, 그렇다고 점추정이 전혀 필요 없는 것은 아니다.\n",
    "            - 왜냐하면 점추정을 기준으로 구간추정을 하기 때문이다.\n",
    "            - ex) 지방선거 여론조사 : 표본오차 95%\n",
    "                - 모집단을 대표할 수 있는지에 대한 내용\n",
    "                - 표본을 100번 뽑았을 때, 95번은 모집단을 대표한다는 뜻으로 신뢰수준 +- 3.5%는 점 추정 값에서 +- 된다.\n",
    "\n",
    "#### 8.2.2. 등분산성\n",
    "- obj : __선형모델의 식이 의미가 있는지(현실을 제대로 반영하고 있는지) 파악__\n",
    "- 최소제곱법\n",
    "    - 선과 데이터의 거리는 최소화 되어야 한다?\n",
    "    - 선형 모형을 만들었을 때, 선이 데이터를 잘 설명할 수 있는가?\n",
    "    - 결과를 추정하는데 있어 데이터에 특정한 패턴이 있으면 안 된다.\n",
    "    - (선을 기준으로) 점점 멀어지거나, 떨어지거나 하는 규칙이 있으면 안 된다.\n",
    "    - 데이터는 무조건 무작위로 찍혀 있어야 한다. \n",
    "\n",
    "#### 8.2.3. 독립성\n",
    "- obj: __y변수가 시간에 따라서 연관이 있는지 없는지(독립적인지 종속적인지) 따지는 것__\n",
    "    - 과거로부터 영향을 받아왔는지\n",
    "        - 대표적으로 시계열(Time Seires)인지 보는 것?\n",
    "        - Ex) 주식, 물류, 날씨<br>\n",
    "        <br>\n",
    "    - 이걸 왜 따지느냐?\n",
    "        - 확률 실험(Random Experiment) 결과가 독립적으로 측정되었는지 판단하기 위해?\n",
    "        - 확률 실험(random experiment) : 결과를 예측할 수 없는 실험\n",
    "            - 과거로부터 영향을 받은 거라면 시계열 분석으로 넘어가고,\n",
    "            - 독립적이면 일반적인 분석방법론을 적용. <br>\n",
    "            <br>\n",
    "    - 회귀식의 목적은 : y변수에 대한 독립성을 따지는 것\n",
    "        - ex) 지나가는 사람들, 무작위 패턴\n",
    "            - 날씨 : 지금 25도라면 10분 뒤의 온도도 비슷하다. (독립적이지 않고, 종속적이다. Time Series임)\n",
    "            - 만약에 날씨가 독립적이면 10분 뒤 온도를 예측할 수 없다. (독립적이다)<br>\n",
    "<br>\n",
    "- 위배되었을 경우\n",
    "    - 정규성\n",
    "        - 적당히 맞춰주었다면 넘어간다.\n",
    "    - 등분산성\n",
    "        - 위배되면 의미가 없다. 이럴 때는 분석 방법을 바꿔야 한다.\n",
    "    - 독립성\n",
    "        - 과거로부터 영향을 받은 거라면 시계열 분석으로 넘어가고, 아니라면?\n",
    "\n",
    "### 8.3. 핵심\n",
    "- 무슨 분석을 할지 미리 정하면 안 된다.\n",
    "    - 분석은 데이터에 나와 있다.\n",
    "    - 조심해야할 것들 (정규성, 독립성, 등분산성)을 생각하고 분석에 들어가야 한다.\n",
    "    - 어떤 목적을 가지고, 해야하는 것과 하지 말아야 할 것을 판단하는 게 핵심이다.<br>\n",
    "<br>\n",
    "- 확률 실험을 많이 하면 할수록 정규분포의 모양을 갖는다.\n",
    "    - __중심극한정리__\n",
    "        - \"N(표집수)가 충분히 많으면, 모든 확률분포는 정규분포로 수렴하며, 평균은 실제 평균에 점점 가까워진다\"<br>\n",
    "<br>\n",
    "- 이 분석법을 왜 하면 안 되냐?\n",
    "    - 특정 상황에서 어떤 분석을 써야하고, 안 써야하는지에 대한 기준을 갖는 것.\n",
    "        - __이렇게 하면 틀린다를 기준으로 분석에 임하자__<br>\n",
    "        <br>\n",
    "- 수학과 통계는 비슷하다?\n",
    "    - 통계는 허수를 다루지 않는다. 확률로 시작해서 확률로 끝나는 학문이다.\n",
    "    - 애초에 실수값만 다루는 게 통계고, 거기에서 이어지는 통계 가정론은 랜덤으로 시작해서 추정으로 끝난다.\n",
    "    - 99%라도 100번 중에 1번이 바로 나올 수도 있다. 정답은 없다. 그 누구도 모르는 것이다.\n",
    "    - ex) 일본의 방사능 쓰나미, 파도 높이 11m는 안 올 것이라고 생각해서 방파제를 10m로 만들었다(10m이상의 파도의 확률이 0.3% 정도... 재수 없게 발생한 것이다).\n",
    "        - 일본이 오판했던 것은 파도 높이다. 몇 m만 높게 쌓았으면 방지가 되었을 것이다. 일본 방사능 문제는 지진이 아니라 파도 높이 때문이었다.\n",
    "        - 파도 높이는 확률로 판단했다. 그게 바로 통계다. 장담할 수 없다. 정답이 없다. 수학은 정답이 있지만 통계는 정답이 없다.\n",
    "    - 반대로 생각하면, 이렇게 하지 말라(실수는 하지 말라)는 식으로 접근할 수 있다.\n",
    "    - 통계는 성능을 개선 시키는 것이지 정답은 아니다. 실수는 하지 않는다는 것은 확실하다. 그렇게 가는 것이다.\n",
    "    - 분석이라는 것은 애매하다. 통계는 다 구간추정이다. 80%라는 건 20번 실패할 수 있다는 뜻이다.\n",
    "    - 틀린 것만 방지해도 중간은 간다. 중간까지 갔으면 거기에서 발전시키면 된다. 첫술에 배부를 수 없다.\n",
    "    - 통계는 동 떨어져 있는 게 아니라 현실이다.\n",
    "- - -\n",
    "- http://kkokkilkon.tistory.com/36\n",
    "\n",
    "\n",
    "\n",
    "## 15. 기계학습\n",
    "### 15.1. 머신러닝 정의\n",
    "    - 머신러닝에 대한 설명은 추후에 자세하게 설명할 예정이니, 머릿 속에 지도를 그릴 수 있을 정도로 간략하게 설명하겠다.\n",
    "\n",
    "    - 1. Label 유무에 따른 머신러닝\n",
    "        - 1) Label(정답)이 있으면 지도학습(Supervised Learning)\n",
    "\n",
    "        - 2) Label(정답)이 없으면 비지도 학습(Unsupervised Learning)\n",
    "            \n",
    "    - 2. Label의 종류에 따른 머신러닝 기법\n",
    "        - 1) Regression (회귀) : 종속 변수(y)가 수치형\n",
    "            - 종속변수(Y)가 독립변수(X)에 영향을 받을 때, 그 변수들 간의 함수 관계를 규명하기 위하여 이용되는 통계적 방법\n",
    "            - 회귀 모형이 학습되었을 때, 새로운 독립 변수의 값으로부터 종속 변수의 값을 예측할 수 있다.\n",
    "            - 종속변수(Y)에 중요한 영향을 주는 주요 독립변수 선별\n",
    " \n",
    "\n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/9933C13E5B2A0F2427\">\n",
    " \n",
    "            - 알고리즘 종류\n",
    "                - a) 선형 회귀 (Linear Regression)\n",
    "                    - 단순 선형 회귀 (Simple Linear Regression)\n",
    "                        - 독립변수가 하나일 때 종속 변수의 값을 예측\n",
    "                        - 예) 여름철의 기온과 아이스크림의 판매량과의 경향성을 파악하면 미래의 일을 예측할 수 있음\n",
    "\\begin{equation}\n",
    "y = \\beta_0 + \\beta_1\\chi + \\varepsilon\n",
    "\\end{equation}\n",
    "                        \n",
    "                        - β0 : y절편 (독립변수가 0일 때, 종속변수의 평균값)\n",
    "                        - β1 : 기울기 (독립변수가 한 단위 증가함에 따라 발생하게 되는 종속변수 평균치의 증가분)\n",
    "                        - ε : 랜덤 오차 (random error, εi - yi = ŷ)\n",
    "                        \n",
    "                        \n",
    "                        - 최소제곱법 (Method of Least Squares)\n",
    "                        - 회귀 모형의 타당성\n",
    "                        - 상관분석 vs 회귀분석\n",
    "                        \n",
    " \n",
    "                        \n",
    "                    - 다중 선형 회귀 (Multiple Linear Regression)\n",
    "                        - 독립변수가 두 개 이상일 때 종속변수의 값 예측\n",
    "                        - 예) 여름철의 기온, 아이스크림 가격, 소득이 아이스크림의 판매량에 미치는 영향을 분석 및 예측\n",
    "                        \n",
    "\n",
    "\\begin{equation}\n",
    "y = \\beta_0 + \\beta_1\\chi_1 + \\beta_2\\chi_2 + \\beta_3\\chi_3 +  ... + \\varepsilon\n",
    "\\end{equation}\n",
    "\n",
    "                    - 다중공선성(Multicollinearity)\n",
    "                    - 회귀 모형의 타당성\n",
    "                    - Subset Selection (변수 선택법)\n",
    "                    - 변수 중요도\n",
    "                    \n",
    "                    \n",
    "                - b) Shrinkage Method\n",
    "                    - Ridge Regression\n",
    "                    - Lasso Regression\n",
    "                        \n",
    "                - c) k-NN\n",
    "                \n",
    "                - d) Regression Tree\n",
    "                \n",
    "                - e) ANN (Artificial Neural Network)\n",
    "                \n",
    "                - f) SVM (Support Vector Machine)\n",
    "                \n",
    "                        \n",
    "                        \n",
    "\n",
    "\n",
    "        - 2) Classification (분류) : 종속 변수(y)가 명목형\n",
    "            - Supervised Learning의 일종으로 다양한 X 변수들과 미리 정의된 class 변수(Y)와의 관계를 밝히는 과정\n",
    "            - Traning set으로 모델을 학습한 뒤, 새로운 data(Test set)가 주어졌을 때, data의 class를 밝혀내고 정확하게 분류하는 것\n",
    "            \n",
    "            - 알고리즘 종류\n",
    "                - a) k-NN (k-Nearest Neighbors)\n",
    "                - b) Decision Tree\n",
    "                - c) ANN (Artificial Neural Network)\n",
    "                - d) SVM (Support Vector Machine)\n",
    "                \n",
    "                - e) Losistic Regerssion\n",
    "                    - 종속변수가 범주형일 때의 회귀식을 추정하여 분류 문제에 적용하기 위해 사용한다.\n",
    "                    - 기존의 선형 회귀식\n",
    "\n",
    "\\begin{equation}\n",
    "y = \\beta_0 + \\beta_1\\chi + \\varepsilon\n",
    "\\end{equation}\n",
    "\n",
    "                    - 예측된 Y값이 0~1사이의 값을 가짐 -> 기존의 선형 회귀식을 사용하기 어려움\n",
    "\n",
    "<img src = \"https://uc2f1cda42c0fe7a8bfbd04480d0.previews.dropboxusercontent.com/p/thumb/AAOzgQbbSFxZUtVy_8yJ63oYbjl5KmMcDlm5jRo4GTr-2LbgbxfvJqW8Ttyp8VUgSsb9EPFvIu06H_3YDstDOncs4YqGazOCDXWWjQvoTYc-fYwQCT1nWWWAcTqUubPK7U0dIVnwH4BN11JzRkuc2jgD5CL-PNqvdROvn09KGjYUq70FmMYf8rqnk5JDPAYgp3HjITSpUISOR9zUmnvZUTtl5_xPDG-cFVRLtkGZ-2vKVA/p.png?size=2048x1536&size_mode=3\">\n",
    "                \n",
    "\n",
    "                        - 종속 변수의 범위를 [0, 1]에서 [−∞, ∞]로 바꿔주기 위한 작업이 필요\n",
    "                        - 오즈(Odds) / 로짓(Logit) 변환\n",
    "                            1. Y값에 대한 확률을 계산\n",
    "                                - P = P(Y=1) : 어떤 사건이 일어날 확률\n",
    "                            2. Odds 계산\n",
    "                                - 사건이 발생할 확률 / 사건이 발생하지 않을 확률\n",
    "\\begin{equation}\n",
    "odds = \\frac p{1-P} = \\frac {p(성공)}{1-P(실패)}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "0 < Odds < \\infty\n",
    "\\end{equation}\n",
    "\n",
    "                            3. Log Odds 계산\n",
    "                                - Odds에 Log를 취함\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "log(odds) = logit(P) = In(odds) = ln\\left ( \\frac{P}{1-P} \\right )\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "-\\infty < Odds < \\infty\n",
    "\\end{equation}\n",
    "\n",
    "                    - Log odds를 이용한 회귀식 추정\n",
    "\n",
    "\\begin{equation}\n",
    "ln\\left ( \\frac{P}{1-P} \\right ) = \\beta_0 + \\beta_1x\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "<img src = \"https://www.saedsayad.com/images/LogReg_1.png\">\n",
    "\n",
    "\n",
    "                    - x가 아무리 작아지거나 커지더라도 y는 0또는 1로 수렴\n",
    "                    \n",
    "                    - 회귀계수의 해석\n",
    "                        - 회귀계수가 양수일 때, x값이 증가하면 P(Y = 1)이 증가\n",
    "                        - 회귀계수가 음수일 때, x값이 증가하면 P(Y = 1)이 감소\n",
    "                        - x가 한 단위 증가할 때 Odds가 \n",
    "                        \n",
    "${\\ e^{\\beta_i}}$ 만큼 증가\n",
    "              \n",
    "                    - Simple linear regression\n",
    "                        - y = -0.2 + 0.25 hours\n",
    "                        \n",
    "                    - Logistic regression\n",
    "                         \n",
    "\\begin{equation}\n",
    "ln\\left ( \\frac{P}{1-P} \\right ) = -758.5 + 251.8hours\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P = \\frac{1}{1+e^-(^-758.5+251.8hours)}\n",
    "\\end{equation}\n",
    "<img src = \"https://uce2c9faf4432d9d2fbf072f743e.previews.dropboxusercontent.com/p/thumb/AAOwtmBYIq6AJ0vqZOUz_hoy3RwJcLdphjuQkJvUjrCP2LG1uiMzagd-raH-geluYTf4OSOqlClyOjlL9IWCMq05QSwtuYEgynFvdme3Ln1p8ZRh-1yiJu8hFTb_k6trqhraBLKqrYQuNv3drBDoBqKYPllIjm2oBtj0SdCf_D4C-ChTsv_CcsRg9FMf1n0HvBJUi1KPBGamwZIxU9HcDORgaBU89YOHAKFUrLL2C1LScA/p.png?size=2048x1536&size_mode=3\">\n",
    "\n",
    "                    - 학생이 공부를 1/3/5 시간 했다면 시험에 pass를 할 확률\n",
    "                     \n",
    "\\begin{equation}\n",
    "\\hat{p}(hours = 1) = 0\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\hat{p}(hours = 3) = 0.045\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\hat{p}(hours = 5) = 1\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "<img src=\"https://ucd5d00ff49a428944c62fcd609d.previews.dropboxusercontent.com/p/thumb/AANp-Ir_yqiTR9KJyEpZgDvmuj3dF6IVdrG_L_KzziddVhWNUvdTt1GdRArb8AcFwm1Rg3fNCIglzzsrfoAoargKTnYGd-UF8equVSgXVGvba3s6QE_UFVZZ33Q5ZWjmn5frSKsuzUYKg4rT2jcBBE6m5LZkSooh8z7BXnD4ywfLHA-8gNzIFg3YEuwTXdTiPefGMY8fdKxKQqS7gRZgTlOJCQmFCt3ewC5LV2LdtXAiAQ/p.png?size=2048x1536&size_mode=3\">\n",
    "\n",
    "\n",
    "    - 3. Ensemble Learning(앙상블)\n",
    "            - Bagging\n",
    "            - Random Forest\n",
    "            - Boosting\n",
    "            - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['\\mu', '\\sigma^2', '\\sigma', '\\sqrt{\\sigma^2}', '\\overline{x} ', 's^2',  's', '\\sqrt{s^2}', '{H_0}', '{H_1}']\n",
    "base_url = \"http://latex.codecogs.com/svg.latex?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\mu\n",
      "http://latex.codecogs.com/svg.latex?\\mu\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?\\mu\" border=\"0\"/>\n",
      "================================================================================\n",
      "\\sigma^2\n",
      "http://latex.codecogs.com/svg.latex?\\sigma^2\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?\\sigma^2\" border=\"0\"/>\n",
      "================================================================================\n",
      "\\sigma\n",
      "http://latex.codecogs.com/svg.latex?\\sigma\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?\\sigma\" border=\"0\"/>\n",
      "================================================================================\n",
      "\\sqrt{\\sigma^2}\n",
      "http://latex.codecogs.com/svg.latex?\\sqrt{\\sigma^2}\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?\\sqrt{\\sigma^2}\" border=\"0\"/>\n",
      "================================================================================\n",
      "\\overline{x} \n",
      "http://latex.codecogs.com/svg.latex?\\overline{x} \n",
      "<img src=\"http://latex.codecogs.com/svg.latex?\\overline{x} \" border=\"0\"/>\n",
      "================================================================================\n",
      "s^2\n",
      "http://latex.codecogs.com/svg.latex?s^2\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?s^2\" border=\"0\"/>\n",
      "================================================================================\n",
      "s\n",
      "http://latex.codecogs.com/svg.latex?s\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?s\" border=\"0\"/>\n",
      "================================================================================\n",
      "\\sqrt{s^2}\n",
      "http://latex.codecogs.com/svg.latex?\\sqrt{s^2}\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?\\sqrt{s^2}\" border=\"0\"/>\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for p in params:\n",
    "    print(p)\n",
    "    url = base_url + p\n",
    "    print(url)\n",
    "    res = '<img src=\"'+url+'\"'+' border=\"0\"/>'\n",
    "    print(res)\n",
    "    result.append(res)\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://latex.codecogs.com/svg.latex?\\sqrt{s^2}\" border=\"0\"/>\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?\\Large&space;x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\" title=\"\\Large x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<img src=\"http://latex.codecogs.com/svg.latex?\\\\mu\" border=\"0\"/>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y=\\beta_0+\\beta_1\\chi+\\varepsilon$\n",
    "\n",
    "<img src=\"http://latex.codecogs.com/gif.latex?y=\\beta_0+\\beta_1\\chi+\\varepsilon\" border=\"0\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=\\beta_0+\\beta_1\\chi+\\varepsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['y=\\\\beta_0+\\\\beta_1\\chi+\\\\varepsilon',\n",
    "          'odds=\\\\fracp{1-P}=\\\\frac{p(성공)}{1-P(실패)}',\n",
    "          '0<Odds<\\infty',\n",
    "          'log(odds)=logit(P)=In(odds)=ln\\left\\\\frac{P}{1-P}\\\\right)',\n",
    "          '-\\infty<Odds<\\infty',\n",
    "          'ln\\left(\\\\frac{P}{1-P}\\\\right)=\\beta_0+\\beta_1x',\n",
    "          \n",
    "          '{\\e^{\\beta_i}}',\n",
    "          'ln\\left(\\\\frac{P}{1-P}\\\\right)=-758.+251.8hours',\n",
    "          'P=\\\\frac{1}{1+e^-(^-758.5+251.8hours)}',\n",
    "          '\\hat{p}(hours=1)=0',\n",
    "          '\\hat{p}(hours=3)=0.045',\n",
    "          '\\hat{p}(hours=5)=1'\n",
    "         ]\n",
    "base_url = \"http://latex.codecogs.com/svg.latex?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_latex(elements):\n",
    "    result = []\n",
    "    \n",
    "    for el in elements:\n",
    "        print(el)\n",
    "        url = base_url + el\n",
    "        print(url)\n",
    "        res = '<img src=\"' + url + '\"' + ' border=\"0\"/>'\n",
    "        print(res)\n",
    "        result.append(res)\n",
    "        print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=\\beta_0+\\beta_1\\chi+\\varepsilon\n",
      "http://latex.codecogs.com/svg.latex?y=\\beta_0+\\beta_1\\chi+\\varepsilon\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?y=\\beta_0+\\beta_1\\chi+\\varepsilon\" border=\"0\"/>\n",
      "================================================================================\n",
      "odds=\\fracp{1-P}=\\frac{p(성공)}{1-P(실패)}\n",
      "http://latex.codecogs.com/svg.latex?odds=\\fracp{1-P}=\\frac{p(성공)}{1-P(실패)}\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?odds=\\fracp{1-P}=\\frac{p(성공)}{1-P(실패)}\" border=\"0\"/>\n",
      "================================================================================\n",
      "0<Odds<\\infty\n",
      "http://latex.codecogs.com/svg.latex?0<Odds<\\infty\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?0<Odds<\\infty\" border=\"0\"/>\n",
      "================================================================================\n",
      "log(odds)=logit(P)=In(odds)=ln\\left\\frac{P}{1-P}\\right)\n",
      "http://latex.codecogs.com/svg.latex?log(odds)=logit(P)=In(odds)=ln\\left\\frac{P}{1-P}\\right)\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?log(odds)=logit(P)=In(odds)=ln\\left\\frac{P}{1-P}\\right)\" border=\"0\"/>\n",
      "================================================================================\n",
      "-\\infty<Odds<\\infty\n",
      "http://latex.codecogs.com/svg.latex?-\\infty<Odds<\\infty\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?-\\infty<Odds<\\infty\" border=\"0\"/>\n",
      "================================================================================\n",
      "ln\\left(\\frac{P}{1-P}\\right)=\beta_0+\beta_1x\n",
      "http://latex.codecogs.com/svg.latex?ln\\left(\\frac{P}{1-P}\\right)=\beta_0+\beta_1x\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?ln\\left(\\frac{P}{1-P}\\right)=\beta_0+\beta_1x\" border=\"0\"/>\n",
      "================================================================================\n",
      "{\\e^{\beta_i}}\n",
      "http://latex.codecogs.com/svg.latex?{\\e^{\beta_i}}\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?{\\e^{\beta_i}}\" border=\"0\"/>\n",
      "================================================================================\n",
      "ln\\left(\\frac{P}{1-P}\\right)=-758.+251.8hours\n",
      "http://latex.codecogs.com/svg.latex?ln\\left(\\frac{P}{1-P}\\right)=-758.+251.8hours\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?ln\\left(\\frac{P}{1-P}\\right)=-758.+251.8hours\" border=\"0\"/>\n",
      "================================================================================\n",
      "P=\\frac{1}{1+e^-(^-758.5+251.8hours)}\n",
      "http://latex.codecogs.com/svg.latex?P=\\frac{1}{1+e^-(^-758.5+251.8hours)}\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?P=\\frac{1}{1+e^-(^-758.5+251.8hours)}\" border=\"0\"/>\n",
      "================================================================================\n",
      "\\hat{p}(hours=1)=0\n",
      "http://latex.codecogs.com/svg.latex?\\hat{p}(hours=1)=0\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?\\hat{p}(hours=1)=0\" border=\"0\"/>\n",
      "================================================================================\n",
      "\\hat{p}(hours=3)=0.045\n",
      "http://latex.codecogs.com/svg.latex?\\hat{p}(hours=3)=0.045\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?\\hat{p}(hours=3)=0.045\" border=\"0\"/>\n",
      "================================================================================\n",
      "\\hat{p}(hours=5)=1\n",
      "http://latex.codecogs.com/svg.latex?\\hat{p}(hours=5)=1\n",
      "<img src=\"http://latex.codecogs.com/svg.latex?\\hat{p}(hours=5)=1\" border=\"0\"/>\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "change_latex(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://latex.codecogs.com/svg.latex?ln\\left(\\frac{P}{1-P}\\right)=\\beta_0+\\beta_1x\" border=\"0\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "ln\\left ( \\frac{P}{1-P} \\right ) = \\beta_0 + \\beta_1x\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "log(odds)=logit(P)=In(odds)=ln\\left(\\frac{P}{1-P}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://latex.codecogs.com/svg.latex?log(odds)=logit(P)=In(odds)=ln\\left(\\frac{P}{1-P}\\right)\" border=\"0\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://latex.codecogs.com/svg.latex?odds=\\frac{p}{1-P}=\\frac{p(성공)}{1-P(실패)}\" border=\"0\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
